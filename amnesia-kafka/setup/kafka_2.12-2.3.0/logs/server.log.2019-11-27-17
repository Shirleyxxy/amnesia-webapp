[2019-11-27 17:01:12,681] WARN Session 0x10002cd5ba10000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2019-11-27 17:01:13,921] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:13,921] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:14,729] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:01:14,734] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:01:14,736] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-11-27 17:01:15,457] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:15,458] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:15,565] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:01:17,487] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:17,488] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:19,169] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:19,170] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:20,497] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:20,498] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:22,326] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:22,326] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:24,032] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:24,034] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:25,523] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:25,524] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:26,651] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:26,651] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:28,022] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:28,023] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:29,193] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:01:30,080] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:30,080] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:32,135] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:32,136] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:33,241] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:01:34,222] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:34,222] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:35,406] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:35,407] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:36,689] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:36,689] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:37,873] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:37,873] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:39,098] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:39,099] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:41,098] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:41,100] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:42,343] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:42,343] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:43,717] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:43,718] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:45,768] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:45,768] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:47,417] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:47,418] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:48,439] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:01:49,237] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:49,242] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:50,356] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:50,356] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:52,118] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:52,120] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:54,193] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:54,194] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:56,054] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:56,059] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:57,271] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:57,271] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:59,180] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:01:59,181] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:00,849] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:00,850] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:02,039] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:02,039] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:02,748] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:02:02,757] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:02:02,758] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:02:02,758] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:02:02,758] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:02:02,797] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:02:02,798] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:02:02,822] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:02:02,835] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,835] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,835] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,835] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,835] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,836] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,838] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,851] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,851] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,851] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:02,870] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:02:02,893] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:02:03,723] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:02:03,723] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:02:03,724] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:02:03,748] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:03,755] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,755] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,755] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,756] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,756] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,756] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,756] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,757] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,758] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:03,777] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:03,778] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:03,799] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:03,799] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50915 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:02:03,806] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50915 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:03,807] INFO Creating new log file: log.1ae (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:02:03,815] INFO Established session 0x1000339a4750000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50915 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:03,817] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000339a4750000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:03,821] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:03,886] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x1 zxid:0x1af txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,910] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x2 zxid:0x1b0 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,914] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x3 zxid:0x1b1 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,919] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x4 zxid:0x1b2 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,931] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x5 zxid:0x1b3 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,934] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x6 zxid:0x1b4 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,937] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x7 zxid:0x1b5 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,939] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x8 zxid:0x1b6 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,941] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0x9 zxid:0x1b7 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,948] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0xa zxid:0x1b8 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,956] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0xb zxid:0x1b9 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,958] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0xc zxid:0x1ba txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:03,960] INFO Got user-level KeeperException when processing sessionid:0x1000339a4750000 type:create cxid:0xd zxid:0x1bb txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:04,111] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:04,113] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:04,113] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50916 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:02:04,116] INFO Client attempting to renew session 0x10002cd5ba10000 at /0:0:0:0:0:0:0:1:50916 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:04,117] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10002cd5ba10000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:04,117] INFO Established session 0x10002cd5ba10000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50916 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:04,117] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:04,150] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-11-27 17:02:04,165] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:02:04,167] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:02:04,167] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:02:04,168] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:02:04,187] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:02:04,189] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:02:04,193] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:02:04,197] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-11-27 17:02:04,198] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,295] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,295] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,299] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:02:04,300] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 8000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:02:04,301] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-11-27 17:02:04,301] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:02:04,301] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:02:04,301] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:02:04,302] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:02:04,303] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:02:04,303] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,399] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:02:04,496] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,496] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,497] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,600] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:02:04,620] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:02:04,674] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:04,676] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:04,681] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:04,700] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,700] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,701] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:02:04,704] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-27 17:02:04,706] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:02:04,708] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:02:04,708] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:02:04,711] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:02:04,714] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:02:04,715] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:02:04,716] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:02:04,716] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,781] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-27 17:02:04,785] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:02:04,795] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:04,797] INFO Processed session termination for sessionid: 0x1000339a4750000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:04,799] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50915 which had sessionid 0x1000339a4750000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:02:04,798] INFO Session: 0x1000339a4750000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:04,801] INFO EventThread shut down for session: 0x1000339a4750000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:04,807] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:04,808] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:04,904] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,905] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,908] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,975] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,976] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:04,979] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:05,107] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:05,107] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:05,108] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:05,175] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:05,175] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:02:05,176] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-27 17:02:05,177] INFO Shutting down. (kafka.log.LogManager)
[2019-11-27 17:02:05,215] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,503] INFO [ProducerStateManager partition=temp-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,599] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,607] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,659] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,680] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:05,680] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:05,680] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:05,688] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,793] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:05,909] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:02:06,053] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-27 17:02:06,073] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:06,075] INFO Processed session termination for sessionid: 0x10002cd5ba10000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:02:06,078] INFO Session: 0x10002cd5ba10000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:02:06,079] INFO EventThread shut down for session: 0x10002cd5ba10000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:02:06,079] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50916 which had sessionid 0x10002cd5ba10000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:02:06,080] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:02:06,081] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,476] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,476] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,477] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,683] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,683] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,684] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,687] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,687] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:06,694] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:02:06,694] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-27 17:02:06,696] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:02:07,479] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:07,479] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:07,479] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:08,479] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:08,480] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:02:08,485] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-27 17:02:08,597] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-27 17:02:08,630] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:02:32,886] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:02:32,892] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:02:32,892] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:02:32,892] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:02:32,892] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:02:32,927] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:02:32,931] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:02:33,022] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,023] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,023] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,023] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,023] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,023] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,028] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,029] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,029] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,047] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,047] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,047] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,048] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,048] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,048] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,099] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,099] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,099] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:02:33,131] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:02:33,159] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:03:35,861] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:03:35,871] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:03:35,871] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:03:35,871] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:03:35,871] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:03:35,918] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:03:35,920] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:03:35,965] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,965] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,966] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,966] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,967] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,967] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,973] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,973] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,973] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,973] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,974] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,974] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,974] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,974] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,974] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,997] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,998] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:35,998] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:36,031] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:03:36,111] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:03:40,827] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:03:41,610] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:03:41,612] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:03:41,614] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:03:41,689] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:03:41,705] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,705] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,706] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,706] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,706] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,707] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,721] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,723] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,723] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,723] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,724] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,724] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,724] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,724] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,725] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,747] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:03:41,804] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:03:41,816] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:03:41,834] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50946 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:03:41,835] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:03:41,847] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50946 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:41,849] INFO Creating new log file: log.1be (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:03:41,863] INFO Established session 0x100033b0f630000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50946 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:03:41,869] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100033b0f630000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:03:41,878] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:03:42,013] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x1 zxid:0x1bf txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,037] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x2 zxid:0x1c0 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,041] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x3 zxid:0x1c1 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,048] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x4 zxid:0x1c2 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,051] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x5 zxid:0x1c3 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,053] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x6 zxid:0x1c4 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,055] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x7 zxid:0x1c5 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,071] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x8 zxid:0x1c6 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,077] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0x9 zxid:0x1c7 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,083] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0xa zxid:0x1c8 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,086] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0xb zxid:0x1c9 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,087] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0xc zxid:0x1ca txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,089] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:create cxid:0xd zxid:0x1cb txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:42,375] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:03:42,518] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:03:42,589] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:03:42,714] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:03:42,714] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:03:42,718] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:03:42,837] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:03:42,980] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:42,992] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 85 ms (kafka.log.Log)
[2019-11-27 17:03:43,017] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,017] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:03:43,071] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,072] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2019-11-27 17:03:43,104] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,104] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-27 17:03:43,141] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,142] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:03:43,216] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,235] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:43,291] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 146 ms (kafka.log.Log)
[2019-11-27 17:03:43,314] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,315] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-27 17:03:43,346] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,347] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-27 17:03:43,390] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,390] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-27 17:03:43,441] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,443] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:43,473] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-11-27 17:03:43,491] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,491] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-27 17:03:43,533] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,535] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:43,563] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 59 ms (kafka.log.Log)
[2019-11-27 17:03:43,574] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,574] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-27 17:03:43,619] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,621] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:03:43,666] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,667] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:03:43,701] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,702] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-27 17:03:43,739] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,739] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:03:43,782] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,782] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:03:43,821] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,821] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:03:43,858] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,858] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:03:43,905] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,905] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:03:43,944] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,944] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:03:43,984] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:43,985] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,020] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 74 ms (kafka.log.Log)
[2019-11-27 17:03:44,031] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,032] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:03:44,070] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,071] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:03:44,109] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,110] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:03:44,153] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,154] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-11-27 17:03:44,290] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,290] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 129 ms (kafka.log.Log)
[2019-11-27 17:03:44,327] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,328] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:03:44,368] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,369] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,406] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 76 ms (kafka.log.Log)
[2019-11-27 17:03:44,425] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,426] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-27 17:03:44,471] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,472] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,508] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-11-27 17:03:44,538] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,540] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,566] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 55 ms (kafka.log.Log)
[2019-11-27 17:03:44,575] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,576] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-27 17:03:44,627] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,627] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-11-27 17:03:44,670] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,670] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:03:44,753] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 164 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,755] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000164.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,785] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 164 in 113 ms (kafka.log.Log)
[2019-11-27 17:03:44,798] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,798] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:03:44,851] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,852] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,883] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-11-27 17:03:44,897] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,901] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-27 17:03:44,939] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,940] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:03:44,973] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 71 ms (kafka.log.Log)
[2019-11-27 17:03:44,981] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:44,982] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-27 17:03:45,021] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,021] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:03:45,068] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,068] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-11-27 17:03:45,101] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,102] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-27 17:03:45,141] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,142] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:03:45,180] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,181] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:03:45,222] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,223] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:03:45,261] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,261] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:03:45,301] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,301] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:03:45,342] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,343] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:03:45,385] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,385] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-27 17:03:45,428] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:03:45,429] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:03:45,436] INFO Logs loading complete in 2599 ms. (kafka.log.LogManager)
[2019-11-27 17:03:45,461] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-27 17:03:45,465] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-27 17:03:45,991] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-27 17:03:46,070] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-27 17:03:46,072] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-27 17:03:46,122] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,125] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,132] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,133] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,174] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:03:46,318] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-27 17:03:46,389] INFO Stat of the created znode at /brokers/ids/0 is: 460,460,1574903026371,1574903026371,1,0,0,72061146234028032,186,0,460
 (kafka.zk.KafkaZkClient)
[2019-11-27 17:03:46,391] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(10.0.0.4,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 460 (kafka.zk.KafkaZkClient)
[2019-11-27 17:03:46,490] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,497] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,504] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:03:46,583] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:03:46,585] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:03:46,597] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:46,633] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:03:46,698] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:03:46,701] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:03:46,701] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:03:46,819] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:03:46,894] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-27 17:03:46,936] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:03:46,936] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:03:46,992] INFO Kafka startTimeMs: 1574903026921 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:03:47,013] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-27 17:03:47,050] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:03:47,062] INFO Got user-level KeeperException when processing sessionid:0x100033b0f630000 type:multi cxid:0x6f zxid:0x1cf txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:03:47,085] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,091] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,172] INFO Replica loaded for partition temp-0 with initial high watermark 7 (kafka.cluster.Replica)
[2019-11-27 17:03:47,172] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,177] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,177] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,196] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,197] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,206] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,226] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,249] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,249] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,271] INFO Replica loaded for partition interactions-0 with initial high watermark 24 (kafka.cluster.Replica)
[2019-11-27 17:03:47,273] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 24. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,281] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,282] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,289] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,290] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,303] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,303] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,307] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,308] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,314] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,315] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,320] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,321] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,325] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,326] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,331] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,335] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,351] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,351] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,358] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,360] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,373] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,374] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,402] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,402] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,407] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,407] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,414] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,414] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,420] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,421] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,429] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,431] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,438] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,438] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,443] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,445] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,458] INFO Replica loaded for partition changes-0 with initial high watermark 164 (kafka.cluster.Replica)
[2019-11-27 17:03:47,461] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 164. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,482] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,483] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,492] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,493] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,506] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,507] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,522] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,524] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,530] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,531] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,538] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,538] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,544] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,545] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,561] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,562] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,569] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,570] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,577] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,578] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,589] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,589] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,597] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,599] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,609] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,609] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,623] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,624] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,645] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,646] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,654] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,655] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,665] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,666] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,673] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,673] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,688] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,688] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,699] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,700] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,706] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,707] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,713] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,714] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,724] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,725] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,730] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,730] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,742] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,748] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,756] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:03:47,756] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,759] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:03:47,760] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:03:47,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,810] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,811] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,832] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 39 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,836] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,837] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,837] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,837] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,842] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,848] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,852] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,852] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,872] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,873] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,879] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,882] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,884] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,884] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,887] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,887] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,888] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,888] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,890] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,889] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,890] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,890] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,890] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,890] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,893] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,897] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,897] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,898] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,898] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,909] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,915] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,919] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,920] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,920] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,920] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,922] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 45 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,936] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,937] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,937] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,938] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,938] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,938] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,950] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,951] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,951] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,959] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,960] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,960] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,961] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,961] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,961] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,971] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,985] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,992] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,992] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:03:47,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:04:09,792] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-30602 in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-1-baf534aa-0087-4723-b8d5-4e0a76af3fb9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:04:09,814] INFO [GroupCoordinator 0]: Stabilized group console-consumer-30602 generation 1 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:04:09,858] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-30602 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:16,686] INFO [GroupCoordinator 0]: Member consumer-1-baf534aa-0087-4723-b8d5-4e0a76af3fb9 in group console-consumer-30602 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:16,691] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-30602 in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-1-baf534aa-0087-4723-b8d5-4e0a76af3fb9 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:16,693] INFO [GroupCoordinator 0]: Group console-consumer-30602 with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:21,901] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:05:21,913] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:05:21,915] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-11-27 17:05:21,992] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-11-27 17:05:22,002] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:05:22,005] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:05:22,006] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:05:22,007] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:05:22,032] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:05:22,033] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:05:22,036] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:05:22,040] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-11-27 17:05:22,042] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,153] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,153] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,158] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:05:22,161] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 9000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:05:22,165] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-11-27 17:05:22,165] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:05:22,166] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:05:22,166] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:05:22,167] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:05:22,168] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:22,169] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,172] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,172] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,173] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,297] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,298] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,320] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:22,322] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-27 17:05:22,323] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:05:22,325] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:05:22,325] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:05:22,326] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:05:22,329] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:05:22,330] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:05:22,331] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:05:22,331] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,487] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,487] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,488] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,554] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,554] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,554] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,692] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,692] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,693] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,882] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,882] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:22,884] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-27 17:05:22,885] INFO Shutting down. (kafka.log.LogManager)
[2019-11-27 17:05:22,901] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:05:23,035] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 27 (kafka.log.ProducerStateManager)
[2019-11-27 17:05:23,092] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 197 (kafka.log.ProducerStateManager)
[2019-11-27 17:05:23,181] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-27 17:05:23,207] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:05:23,216] INFO Processed session termination for sessionid: 0x100033b0f630000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:23,221] INFO Session: 0x100033b0f630000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:23,223] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:05:23,224] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:23,224] INFO EventThread shut down for session: 0x100033b0f630000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:05:23,228] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50946 which had sessionid 0x100033b0f630000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:05:23,992] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:23,992] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:23,993] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:24,997] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:24,997] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:24,997] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:26,001] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:26,001] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:26,003] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-27 17:05:26,040] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-27 17:05:26,046] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:05:48,344] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:05:48,357] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:05:48,357] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:05:48,357] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:05:48,357] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:05:48,391] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:05:48,393] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:05:48,433] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,434] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,434] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,434] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,434] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,434] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,436] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,437] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,437] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,437] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,437] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,437] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,437] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,438] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,438] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,453] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,453] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,453] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:48,478] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:05:48,508] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:05:51,173] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:05:52,596] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:05:52,597] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:05:52,598] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:05:52,641] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:05:52,649] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,649] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,650] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,650] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,650] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,650] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,653] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,654] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,654] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,656] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:05:52,676] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:05:52,678] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:05:52,703] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:05:52,704] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50991 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:05:52,714] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50991 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:52,715] INFO Creating new log file: log.1d1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:05:52,727] INFO Established session 0x100033d13fc0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50991 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:05:52,730] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100033d13fc0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:05:52,736] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:05:52,821] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x1 zxid:0x1d2 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,878] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x2 zxid:0x1d3 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,879] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x3 zxid:0x1d4 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,888] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x4 zxid:0x1d5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,891] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x5 zxid:0x1d6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,893] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x6 zxid:0x1d7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,895] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x7 zxid:0x1d8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,896] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x8 zxid:0x1d9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,900] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0x9 zxid:0x1da txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,905] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0xa zxid:0x1db txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,907] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0xb zxid:0x1dc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,910] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0xc zxid:0x1dd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:52,928] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:create cxid:0xd zxid:0x1de txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:53,663] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:05:53,882] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:05:53,933] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:05:53,995] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:53,995] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:53,996] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:05:54,096] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:05:54,332] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,357] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 200 ms (kafka.log.Log)
[2019-11-27 17:05:54,394] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,394] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-27 17:05:54,429] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,430] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-27 17:05:54,467] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,467] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-27 17:05:54,509] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,509] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:05:54,609] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,628] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:54,765] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 253 ms (kafka.log.Log)
[2019-11-27 17:05:54,812] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,813] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:05:54,833] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,834] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-27 17:05:54,866] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,866] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-27 17:05:54,911] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,912] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:54,943] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 67 ms (kafka.log.Log)
[2019-11-27 17:05:54,949] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:54,950] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-27 17:05:55,003] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,006] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:55,074] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 119 ms (kafka.log.Log)
[2019-11-27 17:05:55,093] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,093] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-27 17:05:55,160] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,161] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-11-27 17:05:55,344] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,344] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 149 ms (kafka.log.Log)
[2019-11-27 17:05:55,358] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,358] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:05:55,426] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,426] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-27 17:05:55,450] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,450] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-27 17:05:55,488] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,488] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:05:55,527] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,527] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:05:55,571] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,572] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:55,573] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-11-27 17:05:55,608] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,609] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:05:55,661] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 27 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,662] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000027.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:55,663] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 27 in 52 ms (kafka.log.Log)
[2019-11-27 17:05:55,690] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,690] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-27 17:05:55,729] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,729] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:05:55,781] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,781] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-11-27 17:05:55,815] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,816] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-27 17:05:55,850] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,850] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-27 17:05:55,901] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,902] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-11-27 17:05:55,934] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,935] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:55,967] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 63 ms (kafka.log.Log)
[2019-11-27 17:05:55,974] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:55,974] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-27 17:05:56,018] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,019] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:56,051] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 75 ms (kafka.log.Log)
[2019-11-27 17:05:56,062] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,063] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:56,065] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-11-27 17:05:56,110] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,111] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:05:56,146] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,146] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:05:56,186] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,186] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:05:56,243] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 197 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,244] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000197.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:56,246] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 197 in 58 ms (kafka.log.Log)
[2019-11-27 17:05:56,292] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,292] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-27 17:05:56,319] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,320] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:56,349] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 55 ms (kafka.log.Log)
[2019-11-27 17:05:56,356] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,356] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-27 17:05:56,401] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,402] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:05:56,433] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-11-27 17:05:56,439] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,439] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-27 17:05:56,484] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,484] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-27 17:05:56,520] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,520] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:05:56,560] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,560] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:05:56,601] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,601] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:05:56,642] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,642] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:05:56,683] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,684] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:05:56,724] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,724] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:05:56,763] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,764] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:05:56,804] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,804] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:05:56,845] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,846] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:05:56,886] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:05:56,886] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:05:56,891] INFO Logs loading complete in 2794 ms. (kafka.log.LogManager)
[2019-11-27 17:05:56,912] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-27 17:05:56,913] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-27 17:05:57,420] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-27 17:05:57,472] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-27 17:05:57,474] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-27 17:05:57,571] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,573] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,574] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,575] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,601] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:05:57,717] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-27 17:05:57,746] INFO Stat of the created znode at /brokers/ids/0 is: 479,479,1574903157734,1574903157734,1,0,0,72061154901098496,186,0,479
 (kafka.zk.KafkaZkClient)
[2019-11-27 17:05:57,748] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(10.0.0.4,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 479 (kafka.zk.KafkaZkClient)
[2019-11-27 17:05:57,832] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,840] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,842] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:05:57,948] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:57,957] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:05:57,962] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:05:58,058] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:05:58,087] INFO Got user-level KeeperException when processing sessionid:0x100033d13fc0000 type:multi cxid:0x65 zxid:0x1e2 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:05:58,113] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:05:58,116] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:05:58,116] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:05:58,224] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:05:58,333] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-27 17:05:58,350] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:05:58,351] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:05:58,351] INFO Kafka startTimeMs: 1574903158335 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:05:58,354] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-27 17:05:58,431] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:05:58,530] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,536] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,556] INFO Replica loaded for partition temp-0 with initial high watermark 7 (kafka.cluster.Replica)
[2019-11-27 17:05:58,557] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,562] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,563] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,568] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,568] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,574] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,575] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,583] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,583] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,589] INFO Replica loaded for partition interactions-0 with initial high watermark 27 (kafka.cluster.Replica)
[2019-11-27 17:05:58,589] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 27. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,593] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,594] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,599] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,599] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,604] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:05:58,604] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,608] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,608] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,612] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,612] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,617] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,617] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,624] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,625] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,629] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:05:58,630] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,634] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,635] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,639] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,639] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,644] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,644] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,649] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:05:58,649] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,662] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,662] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,677] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,678] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,684] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:05:58,685] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,692] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,692] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,698] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,699] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,709] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,709] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,714] INFO Replica loaded for partition changes-0 with initial high watermark 197 (kafka.cluster.Replica)
[2019-11-27 17:05:58,715] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 197. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,719] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,719] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,724] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,724] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,734] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,735] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,744] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,744] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,755] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,756] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,760] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,761] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,765] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,765] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,770] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,771] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,776] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,776] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,786] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,786] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,792] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:05:58,793] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:05:58,809] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:09:16,654] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:09:16,664] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:09:16,664] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:09:16,664] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:09:16,665] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:09:16,687] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:09:16,687] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:09:16,713] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,713] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,714] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,714] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,714] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,714] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,714] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,715] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,723] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,723] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,723] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:16,737] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:09:16,752] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:09:20,949] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:09:22,117] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:09:22,118] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:09:22,119] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:09:22,230] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:09:22,248] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,249] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,249] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,249] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,249] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,250] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,250] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,250] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,251] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,255] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:09:22,331] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:09:22,371] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:09:22,371] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51062 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:09:22,385] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51062 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:22,386] INFO Creating new log file: log.1e3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:09:22,389] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:09:22,399] INFO Established session 0x100034040ea0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51062 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:22,402] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100034040ea0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:09:22,420] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:09:22,541] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x1 zxid:0x1e4 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,561] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x2 zxid:0x1e5 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,563] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x3 zxid:0x1e6 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,565] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x4 zxid:0x1e7 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,566] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x5 zxid:0x1e8 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,569] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x6 zxid:0x1e9 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,571] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x7 zxid:0x1ea txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,574] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x8 zxid:0x1eb txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,576] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0x9 zxid:0x1ec txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,582] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0xa zxid:0x1ed txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,584] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0xb zxid:0x1ee txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,588] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0xc zxid:0x1ef txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,590] INFO Got user-level KeeperException when processing sessionid:0x100034040ea0000 type:create cxid:0xd zxid:0x1f0 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:22,836] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:09:22,937] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:09:22,950] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:09:22,980] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:09:22,980] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:09:22,981] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:09:23,036] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:09:23,116] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,120] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,178] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,180] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 107 ms (kafka.log.Log)
[2019-11-27 17:09:23,195] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,195] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,210] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,211] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-27 17:09:23,234] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,234] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,243] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,243] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-11-27 17:09:23,274] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,274] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,280] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,281] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:09:23,286] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,287] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,293] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,294] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:09:23,325] INFO Expiring session 0x100033d13fc0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:09:23,326] INFO Processed session termination for sessionid: 0x100033d13fc0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:09:23,331] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,331] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,380] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,396] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,398] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,415] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 119 ms (kafka.log.Log)
[2019-11-27 17:09:23,421] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,421] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,428] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,429] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:09:23,435] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,435] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,442] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,443] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:09:23,475] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,475] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,482] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,483] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:09:23,515] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,515] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,523] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,529] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,530] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,531] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-11-27 17:09:23,565] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,565] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,572] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,573] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:09:23,606] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,607] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,614] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,617] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,618] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,620] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 45 ms (kafka.log.Log)
[2019-11-27 17:09:23,646] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,646] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,653] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,654] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-27 17:09:23,688] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,688] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,695] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,696] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:09:23,727] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,727] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,735] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,736] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:09:23,767] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,767] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,774] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,774] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:09:23,808] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,808] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,815] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,816] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:09:23,849] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,849] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,855] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,856] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:09:23,861] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,861] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,868] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,869] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:09:23,902] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,902] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,908] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,909] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:09:23,915] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,915] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,921] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,924] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,925] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:23,926] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 15 ms (kafka.log.Log)
[2019-11-27 17:09:23,963] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:23,963] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,970] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:23,971] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-27 17:09:24,003] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,004] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,011] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 27 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,015] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 27 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,016] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000027.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,017] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 27 in 44 ms (kafka.log.Log)
[2019-11-27 17:09:24,053] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,053] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,060] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,061] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:09:24,065] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,065] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,071] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,071] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:09:24,075] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,076] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,090] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,091] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-27 17:09:24,116] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,116] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,123] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,123] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-27 17:09:24,156] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,156] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,162] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,163] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:09:24,166] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,167] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,173] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,173] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:09:24,177] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,177] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,220] INFO [ProducerStateManager partition=temp-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,223] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,224] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,224] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 49 ms (kafka.log.Log)
[2019-11-27 17:09:24,261] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,262] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,268] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,269] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:09:24,302] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,302] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,309] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,311] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,312] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,313] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-11-27 17:09:24,350] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,351] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,357] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,360] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,361] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,362] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-11-27 17:09:24,398] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,398] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,404] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,405] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:09:24,438] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,438] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,444] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,445] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:09:24,478] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,478] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,484] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,485] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:09:24,518] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,518] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,611] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 197 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,616] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 197 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,617] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000197.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,619] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 197 in 132 ms (kafka.log.Log)
[2019-11-27 17:09:24,674] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,675] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,684] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,685] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-27 17:09:24,696] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,696] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,734] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,736] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,737] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,738] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 52 ms (kafka.log.Log)
[2019-11-27 17:09:24,774] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,774] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,796] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,797] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-27 17:09:24,815] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,815] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,861] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,864] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,865] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:09:24,866] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 68 ms (kafka.log.Log)
[2019-11-27 17:09:24,902] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,902] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,909] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,910] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:09:24,942] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,942] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,952] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,952] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:09:24,982] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:24,982] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,994] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:24,994] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:09:25,022] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,022] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,030] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,031] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:09:25,062] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,062] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,070] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,072] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:09:25,103] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,104] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,120] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,121] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-11-27 17:09:25,126] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,126] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,134] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,134] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:09:25,166] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,166] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,172] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,172] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-27 17:09:25,176] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,177] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,183] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,184] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:09:25,225] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,225] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,240] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,241] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-11-27 17:09:25,261] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:09:25,261] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,305] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:09:25,306] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-11-27 17:09:25,312] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:46,431] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:10:46,473] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:10:46,491] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:10:46,491] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:10:46,491] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:10:46,491] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:10:46,519] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:10:46,520] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:10:46,547] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,547] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,547] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,547] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,547] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,547] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,548] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,549] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,549] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,557] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,557] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,557] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:46,572] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:10:46,589] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:10:47,669] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:10:47,670] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:10:47,671] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:10:47,694] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:10:47,701] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,701] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,701] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,701] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,701] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,702] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,702] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,702] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,702] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,702] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,702] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,703] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,703] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,703] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,703] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,704] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:10:47,724] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:10:47,725] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:10:47,753] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:10:47,753] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51159 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:10:47,762] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51159 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:47,763] INFO Creating new log file: log.1f2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:10:47,771] INFO Established session 0x1000341a0320000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51159 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:47,773] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000341a0320000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:10:47,777] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:10:47,917] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x1 zxid:0x1f3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,942] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x2 zxid:0x1f4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,944] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x3 zxid:0x1f5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,951] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x4 zxid:0x1f6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,953] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x5 zxid:0x1f7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,954] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x6 zxid:0x1f8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,956] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x7 zxid:0x1f9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,958] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x8 zxid:0x1fa txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,961] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0x9 zxid:0x1fb txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,966] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0xa zxid:0x1fc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,967] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0xb zxid:0x1fd txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,969] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0xc zxid:0x1fe txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:47,971] INFO Got user-level KeeperException when processing sessionid:0x1000341a0320000 type:create cxid:0xd zxid:0x1ff txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:10:48,218] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:10:48,357] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:10:48,376] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:10:48,421] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:10:48,422] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:10:48,424] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:10:48,493] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:10:48,577] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,582] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,650] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,652] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 113 ms (kafka.log.Log)
[2019-11-27 17:10:48,668] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,668] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,674] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,675] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:10:48,682] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,682] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,689] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,690] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-27 17:10:48,694] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,695] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,704] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,705] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-27 17:10:48,710] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,710] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,721] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,722] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-27 17:10:48,728] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,728] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,747] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:48,766] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,767] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:48,779] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 55 ms (kafka.log.Log)
[2019-11-27 17:10:48,789] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,789] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,796] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,797] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-27 17:10:48,831] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,833] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,840] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,841] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:10:48,846] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,846] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,854] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,854] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:10:48,859] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,860] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,868] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:48,874] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,875] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:48,876] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 19 ms (kafka.log.Log)
[2019-11-27 17:10:48,910] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,911] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,920] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,921] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-11-27 17:10:48,956] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:48,956] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,981] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:48,990] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:48,992] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,006] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-11-27 17:10:49,054] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,055] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,122] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,124] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 111 ms (kafka.log.Log)
[2019-11-27 17:10:49,145] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,146] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,171] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,172] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-27 17:10:49,203] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,204] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,250] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,252] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-11-27 17:10:49,267] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,268] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,281] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,282] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-27 17:10:49,293] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,293] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,303] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,304] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-27 17:10:49,310] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,310] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,320] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,321] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-27 17:10:49,325] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,325] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,335] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,336] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-27 17:10:49,344] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,345] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,352] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,353] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-27 17:10:49,359] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,359] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,412] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,415] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,416] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,417] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 62 ms (kafka.log.Log)
[2019-11-27 17:10:49,462] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,463] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,470] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,470] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2019-11-27 17:10:49,477] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,477] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,489] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 27 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,494] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 27 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,495] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000027.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,497] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 27 in 25 ms (kafka.log.Log)
[2019-11-27 17:10:49,531] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,531] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,537] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,537] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:10:49,541] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,542] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,549] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,549] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:10:49,554] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,554] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,560] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,560] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:10:49,568] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,569] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,577] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,578] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-27 17:10:49,583] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,583] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,590] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,591] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:10:49,595] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,595] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,601] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,602] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:10:49,606] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,606] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,614] INFO [ProducerStateManager partition=temp-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,617] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,617] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,618] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 15 ms (kafka.log.Log)
[2019-11-27 17:10:49,655] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,655] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,661] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,662] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:10:49,666] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,667] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,674] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,678] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,679] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,681] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 18 ms (kafka.log.Log)
[2019-11-27 17:10:49,707] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,707] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,767] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,805] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,806] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:49,842] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 156 ms (kafka.log.Log)
[2019-11-27 17:10:49,890] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,890] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,911] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,913] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-27 17:10:49,927] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,927] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,955] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,956] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:10:49,972] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,973] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,984] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:49,985] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-27 17:10:49,993] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:49,993] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,029] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 197 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:50,033] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 197 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,033] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000197.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:50,034] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 197 in 45 ms (kafka.log.Log)
[2019-11-27 17:10:50,046] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,046] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,091] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,092] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-27 17:10:50,097] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,097] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,104] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:50,106] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,107] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:50,108] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-11-27 17:10:50,145] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,145] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,151] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,151] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:10:50,156] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,156] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,164] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:10:50,166] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,167] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:10:50,168] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-11-27 17:10:50,206] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,206] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,213] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,214] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-11-27 17:10:50,219] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,219] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,226] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,227] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:10:50,235] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,235] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,243] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,244] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-27 17:10:50,248] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,248] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,254] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,254] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:10:50,258] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,258] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,265] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,266] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:10:50,269] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,269] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,275] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,276] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:10:50,280] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,280] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,287] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,287] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:10:50,291] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,291] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,297] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,298] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:10:50,302] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,302] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,319] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,320] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-27 17:10:50,326] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,326] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,359] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,360] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:10:50,372] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:50,373] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,378] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:10:50,380] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-27 17:10:50,404] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:10:53,337] INFO Expiring session 0x100034040ea0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:10:53,337] INFO Processed session termination for sessionid: 0x100034040ea0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:11,302] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:15:11,310] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:15:11,310] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:15:11,311] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:15:11,311] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:15:11,335] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:15:11,341] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:15:11,379] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,380] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,380] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,380] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,380] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,380] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,383] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,383] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,384] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,384] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,384] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,384] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,384] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,384] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,390] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,413] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,413] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,413] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:11,435] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:15:11,473] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:15:14,515] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:15:15,217] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:15:15,218] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:15:15,220] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:15:15,253] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:15,267] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,267] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,267] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,268] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,268] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,268] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,274] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,276] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,276] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,276] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,277] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,277] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,278] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,278] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,278] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,284] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:15,332] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:15,332] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:15,370] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:15,371] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51517 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:15:15,384] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51517 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:15,385] INFO Creating new log file: log.201 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:15:15,400] INFO Established session 0x1000345aaa10000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51517 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:15,405] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000345aaa10000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:15,412] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:15,507] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x1 zxid:0x202 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,532] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x2 zxid:0x203 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,539] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x3 zxid:0x204 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,550] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x4 zxid:0x205 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,583] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x5 zxid:0x206 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,589] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x6 zxid:0x207 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,603] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x7 zxid:0x208 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,607] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x8 zxid:0x209 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,612] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0x9 zxid:0x20a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,616] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0xa zxid:0x20b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,628] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0xb zxid:0x20c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,631] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0xc zxid:0x20d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,649] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10000 type:create cxid:0xd zxid:0x20e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:15,895] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:15:16,020] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:15:16,075] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:15:16,146] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:16,146] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:16,149] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:16,222] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-27 17:15:16,227] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:15:16,232] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:16,234] INFO Processed session termination for sessionid: 0x1000345aaa10000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:16,236] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51517 which had sessionid 0x1000345aaa10000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:15:16,237] INFO Session: 0x1000345aaa10000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:16,238] INFO EventThread shut down for session: 0x1000345aaa10000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:16,251] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:16,265] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:17,149] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:17,149] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:17,150] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:18,151] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:18,151] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:18,152] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:18,156] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:18,156] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:18,166] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:15:18,167] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-27 17:15:18,180] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:15:20,345] INFO Expiring session 0x1000341a0320000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:20,346] INFO Processed session termination for sessionid: 0x1000341a0320000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:27,889] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:15:28,630] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:15:28,631] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:15:28,632] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:15:28,672] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:28,684] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,684] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,685] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,685] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,685] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,685] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,687] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,691] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,691] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,693] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,695] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,695] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,695] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,695] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,695] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,697] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:28,735] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:28,739] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:28,770] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51534 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:15:28,777] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:28,784] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51534 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:28,786] INFO Established session 0x1000345aaa10001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51534 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:15:28,789] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000345aaa10001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:28,799] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:28,884] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x1 zxid:0x212 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,903] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x2 zxid:0x213 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,905] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x3 zxid:0x214 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,908] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x4 zxid:0x215 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,912] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x5 zxid:0x216 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,914] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x6 zxid:0x217 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,927] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x7 zxid:0x218 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,934] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x8 zxid:0x219 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,941] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0x9 zxid:0x21a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,944] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0xa zxid:0x21b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,945] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0xb zxid:0x21c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,947] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0xc zxid:0x21d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:28,949] INFO Got user-level KeeperException when processing sessionid:0x1000345aaa10001 type:create cxid:0xd zxid:0x21e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:29,160] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:15:29,272] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:15:29,303] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:15:29,361] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:29,361] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:29,363] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:29,420] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-27 17:15:29,423] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:15:29,428] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:29,430] INFO Processed session termination for sessionid: 0x1000345aaa10001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:15:29,433] INFO Session: 0x1000345aaa10001 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:15:29,437] INFO EventThread shut down for session: 0x1000345aaa10001 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:15:29,438] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:15:29,439] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:29,440] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51534 which had sessionid 0x1000345aaa10001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:15:30,366] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:30,366] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:30,366] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:31,368] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:31,368] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:31,368] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:32,371] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:32,371] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:15:32,382] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:15:32,383] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-27 17:15:32,390] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:17:13,163] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:17:13,167] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:17:13,167] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:17:13,167] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:17:13,167] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:17:13,192] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:17:13,193] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:17:13,225] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,226] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,226] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,226] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,226] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,226] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,227] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,227] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,227] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,228] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,228] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,228] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,228] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,228] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,228] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,241] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,241] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,241] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:13,264] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:17:13,287] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:17:24,330] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:17:25,192] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:17:25,193] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:17:25,194] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:17:25,223] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:17:25,237] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,239] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,241] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,241] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,241] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,241] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,245] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,250] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:17:25,297] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:17:25,298] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:17:25,343] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:17:25,343] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51590 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:17:25,472] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51590 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:25,473] INFO Creating new log file: log.220 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:17:25,482] INFO Established session 0x100034786510000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51590 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:17:25,485] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100034786510000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:17:25,489] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:17:25,608] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x1 zxid:0x221 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,656] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x2 zxid:0x222 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,659] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x3 zxid:0x223 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,661] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x4 zxid:0x224 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,664] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x5 zxid:0x225 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,671] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x6 zxid:0x226 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,674] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x7 zxid:0x227 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,677] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x8 zxid:0x228 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,679] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0x9 zxid:0x229 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,680] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0xa zxid:0x22a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,682] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0xb zxid:0x22b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,683] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0xc zxid:0x22c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,684] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:create cxid:0xd zxid:0x22d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:25,962] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:17:26,098] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:17:26,107] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:17:26,156] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:17:26,156] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:17:26,158] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:17:26,217] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:17:26,375] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:26,377] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,480] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,484] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 189 ms (kafka.log.Log)
[2019-11-27 17:17:26,523] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:26,523] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,587] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,588] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-11-27 17:17:26,595] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:26,595] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,645] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,647] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-11-27 17:17:26,696] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:26,696] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,715] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,716] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-27 17:17:26,808] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:26,808] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,814] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:26,815] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-11-27 17:17:26,823] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:26,824] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,054] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:27,106] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,110] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:27,173] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 355 ms (kafka.log.Log)
[2019-11-27 17:17:27,238] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,238] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,318] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,319] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 138 ms (kafka.log.Log)
[2019-11-27 17:17:27,325] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,326] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,371] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,376] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-11-27 17:17:27,385] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,385] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,451] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,452] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-27 17:17:27,492] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,493] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,573] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:27,579] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,580] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:27,581] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 127 ms (kafka.log.Log)
[2019-11-27 17:17:27,614] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,614] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,659] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,659] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-11-27 17:17:27,706] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,706] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,755] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:27,758] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,759] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:27,760] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 99 ms (kafka.log.Log)
[2019-11-27 17:17:27,797] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,797] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,806] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,807] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-11-27 17:17:27,886] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:27,886] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,948] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:27,950] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 141 ms (kafka.log.Log)
[2019-11-27 17:17:28,007] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,007] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,032] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,033] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-27 17:17:28,062] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,063] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,082] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,092] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-11-27 17:17:28,111] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,112] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,181] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,185] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-11-27 17:17:28,207] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,207] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,255] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,257] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-27 17:17:28,267] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,267] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,289] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,301] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:17:28,306] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,306] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,319] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,321] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-27 17:17:28,327] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,327] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,336] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,342] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,342] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,344] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 21 ms (kafka.log.Log)
[2019-11-27 17:17:28,369] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,370] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,377] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,378] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-27 17:17:28,384] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,387] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,462] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 27 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,466] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 27 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,467] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000027.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,468] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 27 in 88 ms (kafka.log.Log)
[2019-11-27 17:17:28,511] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,512] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,556] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,557] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 88 ms (kafka.log.Log)
[2019-11-27 17:17:28,561] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,561] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,571] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,572] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-27 17:17:28,576] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,576] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,619] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,620] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-11-27 17:17:28,627] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,627] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,635] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,635] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-27 17:17:28,639] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,639] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,646] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,647] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:17:28,651] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,651] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,663] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,664] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-27 17:17:28,674] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,674] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,799] INFO [ProducerStateManager partition=temp-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,802] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,803] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,804] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 135 ms (kafka.log.Log)
[2019-11-27 17:17:28,840] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,840] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,846] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,847] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:17:28,855] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,855] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,862] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,865] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,865] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,867] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 19 ms (kafka.log.Log)
[2019-11-27 17:17:28,904] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,904] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,943] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,946] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:28,947] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:28,948] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-11-27 17:17:28,994] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:28,994] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,000] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,001] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2019-11-27 17:17:29,004] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,005] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,011] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,011] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:17:29,015] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,016] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,021] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,022] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:17:29,025] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,026] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,088] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 197 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:29,092] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 197 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,092] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000197.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:29,093] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 197 in 70 ms (kafka.log.Log)
[2019-11-27 17:17:29,146] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,146] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,153] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,153] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-27 17:17:29,158] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,158] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,165] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:29,168] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,168] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:29,169] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-11-27 17:17:29,197] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,198] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,207] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,208] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:17:29,213] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,213] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,226] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:17:29,229] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,230] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:17:29,231] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 21 ms (kafka.log.Log)
[2019-11-27 17:17:29,266] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,267] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,272] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,273] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:17:29,276] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,277] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,282] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,283] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:17:29,287] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,287] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,293] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,294] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:17:29,297] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,297] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,304] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,304] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-27 17:17:29,308] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,308] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,315] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,316] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:17:29,323] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,323] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,330] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,331] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-27 17:17:29,335] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,336] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,344] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,345] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-27 17:17:29,350] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,350] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,393] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,394] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-11-27 17:17:29,399] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,400] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,407] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,408] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-27 17:17:29,411] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,412] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,418] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,419] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:17:29,422] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,422] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,430] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,431] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-27 17:17:29,436] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:17:29,437] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,447] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:17:29,448] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-27 17:17:29,451] INFO Logs loading complete in 3233 ms. (kafka.log.LogManager)
[2019-11-27 17:17:29,469] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-27 17:17:29,470] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-27 17:17:29,973] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-27 17:17:30,028] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-27 17:17:30,030] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-27 17:17:30,102] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,103] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,104] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,104] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,121] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:17:30,189] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-27 17:17:30,213] INFO Stat of the created znode at /brokers/ids/0 is: 558,558,1574903850205,1574903850205,1,0,0,72061199768944640,186,0,558
 (kafka.zk.KafkaZkClient)
[2019-11-27 17:17:30,213] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(10.0.0.4,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 558 (kafka.zk.KafkaZkClient)
[2019-11-27 17:17:30,295] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,300] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,302] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:17:30,367] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:17:30,377] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:30,391] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:17:30,465] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:17:30,551] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:17:30,553] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:17:30,554] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:17:30,578] INFO Got user-level KeeperException when processing sessionid:0x100034786510000 type:multi cxid:0x65 zxid:0x231 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:17:30,649] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:17:30,689] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-27 17:17:30,699] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:17:30,699] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:17:30,699] INFO Kafka startTimeMs: 1574903850690 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:17:30,713] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-27 17:17:30,802] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:17:30,818] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,822] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,846] INFO Replica loaded for partition temp-0 with initial high watermark 7 (kafka.cluster.Replica)
[2019-11-27 17:17:30,847] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,850] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,851] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,858] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,859] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,867] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,867] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,873] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,874] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,879] INFO Replica loaded for partition interactions-0 with initial high watermark 27 (kafka.cluster.Replica)
[2019-11-27 17:17:30,879] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 27. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,888] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,888] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,893] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,893] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,897] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:30,898] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,908] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,908] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,913] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,913] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,918] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,918] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,924] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,924] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,945] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:30,945] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,956] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,957] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,981] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,981] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:30,998] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:30,999] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,004] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:31,005] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,008] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,009] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,023] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,023] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,033] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:31,033] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,041] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,042] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,047] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,047] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,052] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,053] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,064] INFO Replica loaded for partition changes-0 with initial high watermark 197 (kafka.cluster.Replica)
[2019-11-27 17:17:31,064] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 197. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,071] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,072] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,077] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,078] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,082] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,083] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,087] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,088] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,092] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,093] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,097] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,097] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,103] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,104] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,107] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,108] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,112] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,113] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,127] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,127] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,131] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,132] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,136] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,137] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,144] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,144] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,148] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,149] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,158] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,159] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,165] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,165] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,171] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:31,172] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,177] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,178] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,184] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,184] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,192] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,192] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,196] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,196] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,200] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:31,200] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,202] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-27 17:17:31,203] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,207] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,207] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,211] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,212] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,217] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:17:31,218] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,224] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:17:31,225] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:17:31,261] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,276] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,276] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,277] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,278] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,278] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,293] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,299] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,299] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,302] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,303] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,304] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,306] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,306] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,309] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,309] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,310] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,310] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,310] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,310] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,311] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,312] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,312] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,312] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,313] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,313] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,313] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,313] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,314] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,314] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,314] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,314] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,316] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,316] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,358] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30602 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:17:31,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 86 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,364] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,364] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,364] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,370] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,371] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,371] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,371] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,371] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,371] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,371] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,372] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,372] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,372] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,372] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,373] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,373] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,373] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,379] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,379] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,379] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,385] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,386] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,386] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,386] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,386] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,386] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,386] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,387] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,387] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,393] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,399] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,400] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,408] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,414] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,415] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:17:31,415] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:18:28,310] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-15597 in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member consumer-1-c1a8669b-f0a7-4973-8535-2d86796fa6ef with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:18:28,341] INFO [GroupCoordinator 0]: Stabilized group console-consumer-15597 generation 1 (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:18:28,403] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-15597 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:19:24,978] INFO [GroupCoordinator 0]: Member consumer-1-c1a8669b-f0a7-4973-8535-2d86796fa6ef in group console-consumer-15597 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:19:24,979] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-15597 in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: removing member consumer-1-c1a8669b-f0a7-4973-8535-2d86796fa6ef on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:19:24,981] INFO [GroupCoordinator 0]: Group console-consumer-15597 with generation 2 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:19:27,654] WARN Session 0x100034786510000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2019-11-27 17:19:29,526] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:29,527] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:30,905] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:19:30,907] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:19:30,909] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-11-27 17:19:30,975] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:30,976] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:31,081] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:19:32,520] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:32,521] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:34,429] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:34,430] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:34,640] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:19:36,429] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:36,430] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:36,573] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:19:37,661] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:37,662] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:39,696] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:39,697] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:41,588] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:41,588] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:42,744] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:42,745] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:44,685] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:44,685] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:46,052] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:46,055] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:47,701] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:47,702] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:49,522] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:49,523] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:51,400] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:51,401] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:52,613] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:52,614] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:53,899] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:53,900] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:55,654] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:55,655] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:57,510] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:57,510] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:59,427] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:19:59,427] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:00,615] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:00,615] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:01,828] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:01,829] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:03,236] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:03,236] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:04,803] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:04,804] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:06,214] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:06,214] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:07,405] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:07,405] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:08,582] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:08,583] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:10,458] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:10,458] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:12,508] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:12,509] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:13,977] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:13,977] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:15,782] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:15,783] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:17,378] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:17,379] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:18,612] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:18,612] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:19,905] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:19,905] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:21,380] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:21,380] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:23,289] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:23,290] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:24,737] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:24,738] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:26,806] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:26,807] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:28,169] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:28,170] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:29,422] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:29,423] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:31,269] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:31,269] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:32,679] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:32,679] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:34,718] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:34,719] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:36,084] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:36,085] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:37,325] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:37,327] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:39,028] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:39,028] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:40,651] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:40,652] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:42,682] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:42,682] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:44,710] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:44,711] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:46,236] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:46,237] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:47,604] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:47,604] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:49,148] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:49,149] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:50,756] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:50,757] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:52,714] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:52,715] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:54,725] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:54,725] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:55,855] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:55,856] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:57,458] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:57,459] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:59,320] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:20:59,322] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:00,655] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:00,656] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:02,723] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:02,724] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:04,763] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:04,763] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:06,358] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:06,366] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:08,128] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:08,129] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:10,042] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:10,044] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:12,059] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:12,059] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:13,435] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:13,437] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:15,400] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:15,400] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:17,310] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:17,311] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:19,326] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:19,327] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:21,015] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:21,016] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:22,614] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:22,616] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:24,565] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:24,566] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:26,628] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:26,628] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:28,142] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:28,142] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:29,457] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:29,458] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:31,106] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:31,107] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:33,061] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:33,062] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:35,081] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:35,083] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:36,469] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:36,471] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:38,411] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:38,412] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:39,683] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:39,684] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:40,905] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:40,905] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:42,313] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:42,313] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:43,446] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:43,447] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:45,401] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:45,401] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:47,161] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:47,161] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:49,062] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:49,063] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:50,572] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:50,572] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:51,819] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:51,819] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:53,500] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:53,501] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:54,673] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:54,673] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:56,092] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:56,092] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:58,017] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:58,018] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:59,893] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:21:59,893] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:01,130] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:01,130] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:02,971] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:02,972] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:04,392] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:04,392] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:05,620] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:05,620] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:07,204] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:07,205] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:09,266] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:09,266] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:10,872] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:10,878] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:12,188] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:12,189] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:14,092] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:14,093] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:15,455] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:15,455] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:17,363] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:17,363] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:19,055] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:19,056] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:21,023] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:21,024] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:22,773] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:22,773] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:24,861] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:24,861] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:26,525] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:26,525] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:28,357] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:28,358] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:30,040] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:30,041] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:31,704] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:31,704] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:33,274] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:33,276] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:34,510] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:34,510] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:35,909] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:35,910] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:37,715] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:37,716] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:39,133] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:39,134] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:41,216] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:41,216] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:42,562] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:42,563] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:44,406] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:44,406] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:46,377] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:46,377] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:47,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:47,876] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:49,631] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:49,631] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:50,926] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:50,926] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:52,362] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:52,363] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:53,689] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:53,690] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:55,696] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:55,696] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:57,312] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:57,313] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:58,864] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:58,865] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:59,971] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:22:59,972] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:01,841] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:01,841] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:03,859] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:03,859] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:05,395] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:05,396] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:07,024] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:07,025] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:08,565] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:08,566] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:10,094] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:10,094] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:12,075] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:12,076] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:14,081] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:14,081] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:15,854] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:15,855] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:17,804] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:17,804] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:19,532] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:19,533] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:21,329] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:21,329] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:22,524] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:22,525] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:24,106] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:24,107] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:25,416] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:25,417] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:26,284] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:23:26,287] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:23:26,287] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:23:26,287] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:23:26,287] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:23:26,309] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:23:26,310] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:23:26,338] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,338] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,338] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,338] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,338] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,339] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,340] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,341] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,349] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,349] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,349] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:26,363] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:23:26,378] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:23:27,482] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:27,482] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:27,486] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51845 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:23:27,549] INFO Client attempting to renew session 0x100034786510000 at /0:0:0:0:0:0:0:1:51845 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:27,553] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100034786510000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:27,553] INFO Established session 0x100034786510000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51845 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:27,554] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:23:27,577] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-11-27 17:23:27,587] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:23:27,593] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:23:27,595] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:23:27,596] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:23:27,617] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:23:27,619] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:23:27,622] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:23:27,625] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-11-27 17:23:27,627] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,774] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,774] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,778] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:23:27,779] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 11000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:23:27,780] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-11-27 17:23:27,780] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:23:27,781] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:23:27,781] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:23:27,782] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:23:27,784] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:23:27,784] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,881] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,881] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,882] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,974] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,974] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:27,975] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:23:27,976] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-27 17:23:27,976] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:23:27,976] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:23:27,976] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:23:27,977] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:23:27,979] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:23:27,979] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:23:27,979] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:23:27,980] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,175] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,175] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,175] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,376] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,376] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,377] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,580] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,580] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,580] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,782] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,782] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:23:28,785] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-27 17:23:28,785] INFO Shutting down. (kafka.log.LogManager)
[2019-11-27 17:23:28,827] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:23:28,939] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-11-27 17:23:28,988] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 246 (kafka.log.ProducerStateManager)
[2019-11-27 17:23:29,058] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-27 17:23:29,073] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:23:29,075] INFO Processed session termination for sessionid: 0x100034786510000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:23:29,076] INFO Creating new log file: log.232 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:23:29,085] INFO Session: 0x100034786510000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:23:29,086] INFO EventThread shut down for session: 0x100034786510000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:23:29,087] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:23:29,086] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51845 which had sessionid 0x100034786510000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:23:29,087] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:29,302] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:29,302] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:29,302] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:30,305] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:30,306] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:30,308] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:31,311] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:31,311] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:23:31,312] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-27 17:23:31,337] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-27 17:23:31,349] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:23:50,677] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51851 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:23:50,686] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51851 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:50,687] INFO Established session 0x100034d37a90000 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:51851 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:23:50,762] INFO Processed session termination for sessionid: 0x100034d37a90000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:23:50,768] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51851 which had sessionid 0x100034d37a90000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:24:08,709] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:24:09,455] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:24:09,456] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:24:09,457] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:24:09,480] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:24:09,486] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,486] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,487] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,487] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,487] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,487] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,488] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,489] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,489] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,491] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:09,511] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:24:09,512] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:09,540] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:10,651] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:10,652] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:11,757] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:11,758] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:12,861] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:12,861] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:13,965] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:13,966] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:15,075] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:15,076] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:15,515] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:24:16,180] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:16,286] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:24:16,286] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:24:16,288] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:24:16,293] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient.$anonfun$waitUntilConnected$3(ZooKeeperClient.scala:258)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1826)
	at kafka.server.KafkaServer.createZkClient$1(KafkaServer.scala:364)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-27 17:24:16,297] INFO shutting down (kafka.server.KafkaServer)
[2019-11-27 17:24:16,315] INFO shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:24:16,317] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-27 17:24:16,329] INFO shutting down (kafka.server.KafkaServer)
[2019-11-27 17:26:58,025] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:26:58,030] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:26:58,030] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:26:58,030] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:26:58,030] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:26:58,058] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:26:58,058] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:26:58,089] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,089] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,090] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,090] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,090] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,090] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,091] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,092] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,106] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,106] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,106] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:26:58,129] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:26:58,153] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:28:04,038] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:28:04,864] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:28:04,866] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:28:04,867] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:28:04,901] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:28:04,912] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,912] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,912] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,913] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,913] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,913] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,914] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,914] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,914] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,914] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,914] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,914] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,915] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,915] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,915] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,917] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:04,937] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:28:04,940] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:04,984] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:06,091] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:06,092] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:07,200] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:07,201] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:08,310] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:08,311] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:09,416] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:09,416] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:10,522] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:10,522] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:10,941] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:28:11,626] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:11,730] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:28:11,730] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:28:11,733] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:28:11,742] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient.$anonfun$waitUntilConnected$3(ZooKeeperClient.scala:258)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1826)
	at kafka.server.KafkaServer.createZkClient$1(KafkaServer.scala:364)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-27 17:28:11,748] INFO shutting down (kafka.server.KafkaServer)
[2019-11-27 17:28:11,756] INFO shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:28:11,758] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-27 17:28:11,762] INFO shutting down (kafka.server.KafkaServer)
[2019-11-27 17:29:42,258] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:29:42,266] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:29:42,266] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:29:42,266] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:29:42,266] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:29:42,291] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:29:42,291] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:29:42,325] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,325] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,325] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,325] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,325] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,325] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,328] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,343] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,343] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,343] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:29:42,370] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:29:42,396] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:31:24,555] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:31:24,568] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:31:24,568] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:31:24,568] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:31:24,568] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:31:24,595] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:31:24,596] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:31:24,610] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:31:24,626] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,627] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,627] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,627] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,627] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,627] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,628] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,640] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,640] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,640] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:24,660] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:31:24,682] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:31:25,746] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:31:25,748] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:31:25,749] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:31:25,786] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:31:25,796] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,796] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,796] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,796] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,796] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,796] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,797] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,797] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,798] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,800] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:31:25,821] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:31:25,823] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:31:25,846] INFO Accepted socket connection from /127.0.0.1:52088 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:31:25,848] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:31:25,863] INFO Client attempting to establish new session at /127.0.0.1:52088 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:25,864] INFO Creating new log file: log.235 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:31:25,873] INFO Established session 0x100035483d90000 with negotiated timeout 6000 for client /127.0.0.1:52088 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:31:25,875] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100035483d90000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:31:25,879] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:31:26,118] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x1 zxid:0x236 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,138] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x2 zxid:0x237 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,140] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x3 zxid:0x238 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,141] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x4 zxid:0x239 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,142] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x5 zxid:0x23a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,144] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x6 zxid:0x23b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,148] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x7 zxid:0x23c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,149] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x8 zxid:0x23d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,151] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0x9 zxid:0x23e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,152] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0xa zxid:0x23f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,154] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0xb zxid:0x240 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,156] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0xc zxid:0x241 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,157] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:create cxid:0xd zxid:0x242 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:26,481] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:31:26,686] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:31:26,698] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:31:26,735] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:31:26,735] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:31:26,736] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:31:26,797] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:31:26,996] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,012] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-11-27 17:31:27,036] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,036] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-27 17:31:27,077] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,078] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:31:27,118] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,118] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-27 17:31:27,158] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,158] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:31:27,254] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,263] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:27,336] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 175 ms (kafka.log.Log)
[2019-11-27 17:31:27,361] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,361] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-27 17:31:27,401] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,402] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:27,516] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,516] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-8/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:27,535] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 131 ms (kafka.log.Log)
[2019-11-27 17:31:27,579] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,582] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:27,618] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-27 17:31:27,632] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,632] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:31:27,694] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,695] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:27,720] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-11-27 17:31:27,726] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,727] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-27 17:31:27,774] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,775] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-11-27 17:31:27,827] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,827] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-11-27 17:31:27,877] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,877] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-11-27 17:31:27,917] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,917] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:31:27,968] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:27,968] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-11-27 17:31:28,010] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,010] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:31:28,054] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,054] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-11-27 17:31:28,093] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,094] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:28,133] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 77 ms (kafka.log.Log)
[2019-11-27 17:31:28,151] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,151] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-27 17:31:28,244] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,249] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000031.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:28,272] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 31 in 118 ms (kafka.log.Log)
[2019-11-27 17:31:28,290] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,290] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-27 17:31:28,319] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,319] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-27 17:31:28,359] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,360] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:31:28,407] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,407] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-11-27 17:31:28,457] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,457] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-11-27 17:31:28,490] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,490] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-27 17:31:28,569] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,570] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:28,604] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 113 ms (kafka.log.Log)
[2019-11-27 17:31:28,610] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,610] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-27 17:31:28,692] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,692] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:28,733] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 121 ms (kafka.log.Log)
[2019-11-27 17:31:28,747] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,748] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:28,779] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 45 ms (kafka.log.Log)
[2019-11-27 17:31:28,787] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,787] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-27 17:31:28,828] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,828] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:28,872] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,873] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:31:28,915] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 246 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,916] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000246.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:28,952] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 246 in 78 ms (kafka.log.Log)
[2019-11-27 17:31:28,960] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:28,960] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-27 17:31:29,002] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,003] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:29,036] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 74 ms (kafka.log.Log)
[2019-11-27 17:31:29,042] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,042] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-27 17:31:29,084] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,085] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:31:29,120] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 77 ms (kafka.log.Log)
[2019-11-27 17:31:29,125] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,125] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-27 17:31:29,169] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,169] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:31:29,210] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,210] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:29,250] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,250] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:29,296] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,296] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-11-27 17:31:29,303] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,303] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-27 17:31:29,343] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,343] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:29,393] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,393] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-11-27 17:31:29,433] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,434] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:31:29,473] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,474] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:29,514] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,514] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-27 17:31:29,558] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:31:29,558] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-11-27 17:31:29,561] INFO Logs loading complete in 2764 ms. (kafka.log.LogManager)
[2019-11-27 17:31:29,577] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-27 17:31:29,578] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-27 17:31:30,164] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-27 17:31:30,202] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-27 17:31:30,213] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-27 17:31:30,263] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,264] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,265] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,266] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,293] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:31:30,361] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-27 17:31:30,385] INFO Stat of the created znode at /brokers/ids/0 is: 579,579,1574904690378,1574904690378,1,0,0,72061255562100736,186,0,579
 (kafka.zk.KafkaZkClient)
[2019-11-27 17:31:30,386] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(10.0.0.4,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 579 (kafka.zk.KafkaZkClient)
[2019-11-27 17:31:30,455] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,460] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,460] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:31:30,543] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:31:30,545] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:31:30,553] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:31:30,578] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:12000,blockEndProducerId:12999) by writing to Zk with path version 13 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:31:30,608] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:31:30,610] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:31:30,610] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:31:30,693] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:31:30,725] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-27 17:31:30,742] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:31:30,742] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:31:30,742] INFO Kafka startTimeMs: 1574904690728 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:31:30,750] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-27 17:31:30,801] INFO Got user-level KeeperException when processing sessionid:0x100035483d90000 type:multi cxid:0x6f zxid:0x246 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:31:30,845] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:31:30,900] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,903] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,922] INFO Replica loaded for partition temp-0 with initial high watermark 7 (kafka.cluster.Replica)
[2019-11-27 17:31:30,922] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,925] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,925] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,929] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,929] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,932] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,933] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,936] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,937] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,940] INFO Replica loaded for partition interactions-0 with initial high watermark 31 (kafka.cluster.Replica)
[2019-11-27 17:31:30,940] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 31. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,943] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,943] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,946] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,947] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,951] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:31:30,951] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,955] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,955] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,959] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,959] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,962] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,963] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,966] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,966] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,970] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:31:30,970] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,973] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,973] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,976] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,977] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,980] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,980] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,984] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:31:30,984] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,987] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,988] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,991] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,991] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,995] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:31:30,995] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:30,997] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:30,998] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,001] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,001] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,004] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-27 17:31:31,005] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,008] INFO Replica loaded for partition changes-0 with initial high watermark 246 (kafka.cluster.Replica)
[2019-11-27 17:31:31,008] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 246. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,012] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,012] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,016] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,016] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,022] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,023] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,028] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,028] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,032] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,032] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,036] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,036] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,039] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,040] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,043] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,043] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,046] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,046] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,050] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:31:31,050] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:31:31,053] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:32:33,747] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:32:33,753] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:32:33,753] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:32:33,753] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:32:33,753] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:32:33,789] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:32:33,790] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:32:33,828] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,829] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,830] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,836] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,837] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,837] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,865] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,866] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,867] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,899] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,903] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,905] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:33,953] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:32:33,980] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:32:39,373] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:32:40,173] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:32:40,174] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:32:40,176] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:32:40,221] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:32:40,275] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,276] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,297] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,298] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,301] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,301] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,422] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,422] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,422] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,422] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,422] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,423] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,423] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,423] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,423] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,425] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:40,480] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:32:40,481] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:32:40,513] INFO Accepted socket connection from /127.0.0.1:52124 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:32:40,518] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:32:40,532] INFO Client attempting to establish new session at /127.0.0.1:52124 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:40,533] INFO Creating new log file: log.247 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:32:40,542] INFO Established session 0x100035592dd0000 with negotiated timeout 6000 for client /127.0.0.1:52124 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:40,545] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100035592dd0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:32:40,550] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:32:40,701] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x1 zxid:0x248 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,720] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x2 zxid:0x249 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,722] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x3 zxid:0x24a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,725] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x4 zxid:0x24b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,728] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x5 zxid:0x24c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,730] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x6 zxid:0x24d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,732] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x7 zxid:0x24e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,734] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x8 zxid:0x24f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,741] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0x9 zxid:0x250 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,743] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0xa zxid:0x251 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,745] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0xb zxid:0x252 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,747] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0xc zxid:0x253 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:40,755] INFO Got user-level KeeperException when processing sessionid:0x100035592dd0000 type:create cxid:0xd zxid:0x254 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:41,059] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:32:41,292] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:32:41,331] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:32:41,382] INFO Expiring session 0x100035483d90000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:32:41,383] INFO Processed session termination for sessionid: 0x100035483d90000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:41,437] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:41,438] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:41,440] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:41,530] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-27 17:32:41,544] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:32:41,582] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:32:41,584] INFO Processed session termination for sessionid: 0x100035592dd0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:32:41,586] INFO Closed socket connection for client /127.0.0.1:52124 which had sessionid 0x100035592dd0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-27 17:32:41,597] INFO EventThread shut down for session: 0x100035592dd0000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:32:41,598] INFO Session: 0x100035592dd0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:32:41,626] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:32:41,651] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:42,443] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:42,443] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:42,443] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:43,443] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:43,443] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:43,444] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:44,445] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:44,445] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:32:44,456] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:32:44,457] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-27 17:32:44,464] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:33:10,630] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:33:10,637] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:33:10,638] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:33:10,638] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:33:10,638] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:33:10,671] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:33:10,675] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:33:10,715] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,715] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,715] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,715] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,715] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,715] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,731] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,732] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,747] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,747] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,747] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:10,777] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:33:10,804] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:33:15,609] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-27 17:33:16,252] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:33:16,255] INFO starting (kafka.server.KafkaServer)
[2019-11-27 17:33:16,256] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-27 17:33:16,285] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:33:16,299] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,299] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,300] INFO Client environment:java.version=1.8.0_121 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,300] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,300] INFO Client environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,300] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,305] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,306] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,309] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1ddf84b8 (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:33:16,339] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:33:16,342] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:33:16,384] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:33:16,385] INFO Accepted socket connection from /127.0.0.1:52161 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:33:16,397] INFO Client attempting to establish new session at /127.0.0.1:52161 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:16,402] INFO Creating new log file: log.257 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:33:16,415] INFO Established session 0x1000356229c0000 with negotiated timeout 6000 for client /127.0.0.1:52161 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:33:16,421] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000356229c0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:33:16,437] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:33:16,553] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x1 zxid:0x258 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,575] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x2 zxid:0x259 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,579] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x3 zxid:0x25a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,584] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x4 zxid:0x25b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,586] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x5 zxid:0x25c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,588] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x6 zxid:0x25d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,600] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x7 zxid:0x25e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,605] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x8 zxid:0x25f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,608] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0x9 zxid:0x260 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,610] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0xa zxid:0x261 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,612] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0xb zxid:0x262 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,617] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0xc zxid:0x263 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,620] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:create cxid:0xd zxid:0x264 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:16,854] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-11-27 17:33:16,965] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:33:16,991] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-27 17:33:17,056] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:33:17,056] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:33:17,066] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:33:17,142] INFO Loading logs. (kafka.log.LogManager)
[2019-11-27 17:33:17,223] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,226] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,288] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,291] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-11-27 17:33:17,316] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,316] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,338] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,340] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-27 17:33:17,356] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,357] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,376] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,378] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:33:17,401] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,401] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,414] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,415] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-27 17:33:17,422] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,422] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,450] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,451] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-27 17:33:17,467] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,468] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,521] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,538] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,547] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,577] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 120 ms (kafka.log.Log)
[2019-11-27 17:33:17,591] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,591] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,607] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,610] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-27 17:33:17,619] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,619] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,631] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,635] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-27 17:33:17,660] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,662] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,709] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,712] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,713] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-8/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,717] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 70 ms (kafka.log.Log)
[2019-11-27 17:33:17,754] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,756] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,762] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,765] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,766] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-39/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,767] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-11-27 17:33:17,804] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,804] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,812] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,812] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-11-27 17:33:17,844] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,845] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,858] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,862] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,863] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:17,864] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 49 ms (kafka.log.Log)
[2019-11-27 17:33:17,890] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,890] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,907] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,908] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:33:17,916] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,916] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,922] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,923] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-27 17:33:17,955] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:17,965] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,987] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:17,988] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-11-27 17:33:18,026] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,026] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,045] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,046] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-11-27 17:33:18,071] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,071] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,089] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,091] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:33:18,146] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,146] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,156] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,157] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-11-27 17:33:18,172] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,172] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,199] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,201] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:33:18,241] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,241] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,261] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,267] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-27 17:33:18,279] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,280] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,335] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,339] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,340] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,341] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 71 ms (kafka.log.Log)
[2019-11-27 17:33:18,376] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,376] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,395] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,395] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2019-11-27 17:33:18,432] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,432] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,476] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,479] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,480] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000031.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,481] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 31 in 84 ms (kafka.log.Log)
[2019-11-27 17:33:18,510] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,510] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,538] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,539] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-11-27 17:33:18,555] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,556] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,563] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,564] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-27 17:33:18,578] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,580] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,596] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,597] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-27 17:33:18,635] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,636] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,643] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,645] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-27 17:33:18,671] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,671] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,690] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,691] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:33:18,702] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,702] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,716] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,717] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-27 17:33:18,735] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,736] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,771] INFO [ProducerStateManager partition=temp-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,774] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,775] INFO [ProducerStateManager partition=temp-0] Loading producer state from snapshot file '/tmp/kafka-logs/temp-0/00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,776] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 53 ms (kafka.log.Log)
[2019-11-27 17:33:18,823] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,823] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,830] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,831] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-11-27 17:33:18,873] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,873] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,880] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,883] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,884] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-3/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,886] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 54 ms (kafka.log.Log)
[2019-11-27 17:33:18,921] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,921] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,928] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,934] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,935] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-33/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:18,938] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 50 ms (kafka.log.Log)
[2019-11-27 17:33:18,973] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:18,975] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,989] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:18,990] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-11-27 17:33:19,011] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,011] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,031] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,032] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-11-27 17:33:19,052] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,053] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,074] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,075] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:33:19,133] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,133] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,231] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 246 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:19,236] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 246 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,236] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000246.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:19,237] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 246 in 158 ms (kafka.log.Log)
[2019-11-27 17:33:19,284] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,285] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,298] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,300] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-27 17:33:19,327] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,327] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,344] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:19,351] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,352] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:19,353] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-11-27 17:33:19,390] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,390] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,414] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,415] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-27 17:33:19,435] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,436] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,457] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-27 17:33:19,471] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,474] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-16/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-27 17:33:19,476] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 54 ms (kafka.log.Log)
[2019-11-27 17:33:19,502] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,502] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,515] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,515] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-27 17:33:19,539] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,539] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,550] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,551] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-27 17:33:19,586] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,586] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,599] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,602] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-11-27 17:33:19,653] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,653] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,662] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,663] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-27 17:33:19,668] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,668] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,713] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,714] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-11-27 17:33:19,758] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,758] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,764] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,765] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-11-27 17:33:19,769] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,769] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,777] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,779] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-27 17:33:19,808] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,809] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,819] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,821] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:33:19,836] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,837] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,864] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,869] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-11-27 17:33:19,887] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,887] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,902] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,903] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-27 17:33:19,926] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,926] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,945] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,945] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-27 17:33:19,957] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-27 17:33:19,957] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,979] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-27 17:33:19,980] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-27 17:33:19,983] INFO Logs loading complete in 2841 ms. (kafka.log.LogManager)
[2019-11-27 17:33:20,006] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-27 17:33:20,007] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-27 17:33:20,370] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-27 17:33:20,420] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-27 17:33:20,430] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-27 17:33:20,483] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,486] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,495] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,497] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,535] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:33:20,626] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-27 17:33:20,655] INFO Stat of the created znode at /brokers/ids/0 is: 613,613,1574904800644,1574904800644,1,0,0,72061262520647680,186,0,613
 (kafka.zk.KafkaZkClient)
[2019-11-27 17:33:20,657] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(10.0.0.4,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 613 (kafka.zk.KafkaZkClient)
[2019-11-27 17:33:20,736] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,748] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,751] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:33:20,831] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:33:20,846] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:33:20,857] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:20,934] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:13000,blockEndProducerId:13999) by writing to Zk with path version 14 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:33:20,973] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:33:20,979] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:33:20,980] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:33:21,043] INFO Got user-level KeeperException when processing sessionid:0x1000356229c0000 type:multi cxid:0x65 zxid:0x268 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:33:21,110] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:33:21,162] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-27 17:33:21,168] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:33:21,169] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:33:21,169] INFO Kafka startTimeMs: 1574904801163 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-27 17:33:21,193] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-27 17:33:21,273] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:33:21,291] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,296] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,347] INFO Replica loaded for partition temp-0 with initial high watermark 7 (kafka.cluster.Replica)
[2019-11-27 17:33:21,349] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,357] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,357] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,366] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,367] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,371] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,371] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,378] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,378] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,385] INFO Replica loaded for partition interactions-0 with initial high watermark 31 (kafka.cluster.Replica)
[2019-11-27 17:33:21,385] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 31. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,390] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,390] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,396] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,397] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,406] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,407] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,410] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,410] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,417] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,417] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,423] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,423] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,427] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,428] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,440] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,441] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,467] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,467] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,563] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,569] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,577] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,577] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,582] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,582] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,585] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,586] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,589] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,590] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,594] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,595] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,598] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,599] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,604] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,604] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,608] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-27 17:33:21,608] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,613] INFO Replica loaded for partition changes-0 with initial high watermark 246 (kafka.cluster.Replica)
[2019-11-27 17:33:21,615] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 246. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,622] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,622] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,629] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,629] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,634] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,635] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,638] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,638] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,642] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,643] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,654] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,654] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,659] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,659] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,663] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,663] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,669] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,670] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,673] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,673] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,680] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,681] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,693] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,693] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,697] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,697] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,709] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,734] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,744] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,745] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,757] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,765] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,777] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,778] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,783] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,784] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,787] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,787] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,794] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,794] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,802] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,802] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,813] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,814] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,817] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-27 17:33:21,817] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,820] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,821] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,824] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,825] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,836] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-27 17:33:21,837] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,849] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-27 17:33:21,849] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-27 17:33:21,885] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,889] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,898] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,903] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,905] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,905] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,905] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,906] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,906] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,908] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,914] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,915] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,915] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,915] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,916] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,918] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,919] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,919] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,919] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,919] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,920] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,922] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,922] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,923] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,968] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30602 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:33:21,971] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 83 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,975] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,975] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,981] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,981] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,983] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,992] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:21,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,002] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15597 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:33:22,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,005] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,005] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,010] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,010] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,010] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,019] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,019] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,019] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,021] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,025] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,038] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,039] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,046] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,056] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,057] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:33:22,057] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-27 17:37:37,656] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:37:37,659] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-27 17:37:37,660] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-11-27 17:37:37,693] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-11-27 17:37:37,701] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:37:37,702] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:37:37,703] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-27 17:37:37,703] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:37:37,724] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-27 17:37:37,725] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:37:37,729] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-11-27 17:37:37,732] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-11-27 17:37:37,734] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:37,895] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:37,895] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:37,900] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:37:37,901] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 13000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-27 17:37:37,902] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-11-27 17:37:37,902] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:37:37,903] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:37:37,903] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-27 17:37:37,903] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-27 17:37:37,904] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:37:37,939] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,107] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,107] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,108] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,308] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,308] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,309] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-27 17:37:38,311] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-27 17:37:38,311] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:37:38,312] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:37:38,312] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-27 17:37:38,313] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:37:38,316] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-27 17:37:38,317] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:37:38,318] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-27 17:37:38,318] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,420] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,420] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,420] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,500] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,501] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,501] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,703] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,703] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,703] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,908] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,908] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-27 17:37:38,911] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-27 17:37:38,912] INFO Shutting down. (kafka.log.LogManager)
[2019-11-27 17:37:39,007] INFO [ProducerStateManager partition=temp-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-11-27 17:37:39,029] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 33 (kafka.log.ProducerStateManager)
[2019-11-27 17:37:39,092] INFO Unable to read additional data from server sessionid 0x1000356229c0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:37:39,267] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 278 (kafka.log.ProducerStateManager)
[2019-11-27 17:37:39,453] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-27 17:37:39,469] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:37:40,458] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:37:40,560] INFO Session: 0x1000356229c0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-27 17:37:40,560] INFO EventThread shut down for session: 0x1000356229c0000 (org.apache.zookeeper.ClientCnxn)
[2019-11-27 17:37:40,561] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-27 17:37:40,562] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:40,746] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:40,746] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:40,747] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:41,751] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:41,751] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:41,751] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:41,807] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:41,807] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-27 17:37:41,809] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-27 17:37:41,812] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-11-27 17:37:41,877] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-27 17:37:41,881] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-27 17:45:06,984] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:45:06,991] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:45:06,991] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:45:06,991] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:45:06,991] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:45:07,017] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:45:07,020] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:45:07,055] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,055] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,055] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,056] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,056] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,056] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,057] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,057] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,057] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,057] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,058] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,058] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,058] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,058] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,058] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,074] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,074] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,074] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:07,110] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:45:07,136] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-27 17:45:14,407] INFO Expiring session 0x1000356229c0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:45:14,409] INFO Processed session termination for sessionid: 0x1000356229c0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-27 17:45:14,410] INFO Creating new log file: log.269 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-27 17:48:34,012] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:48:34,018] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:48:34,019] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:48:34,019] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-27 17:48:34,019] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-27 17:48:34,056] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-27 17:48:34,066] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-27 17:48:34,117] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,117] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,118] INFO Server environment:java.version=1.8.0_121 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,118] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,118] INFO Server environment:java.home=/anaconda/envs/py36/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,119] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,160] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,160] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,160] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,161] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,161] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,162] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,162] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,162] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,162] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,208] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,208] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,208] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-27 17:48:34,254] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-27 17:48:34,313] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
