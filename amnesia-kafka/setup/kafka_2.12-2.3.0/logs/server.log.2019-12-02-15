[2019-12-02 15:06:35,401] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:16:35,418] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:23:11,276] INFO [GroupCoordinator 0]: Member consumer-1-9e4a86f1-bd68-4c0a-bffc-4c34f46b9739 in group console-consumer-42573 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:23:11,281] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-42573 in state PreparingRebalance with old generation 1 (__consumer_offsets-32) (reason: removing member consumer-1-9e4a86f1-bd68-4c0a-bffc-4c34f46b9739 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:23:11,284] INFO [GroupCoordinator 0]: Group console-consumer-42573 with generation 2 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:23:13,683] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:23:13,691] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 15:23:13,694] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 15:23:13,779] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 15:23:13,785] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:23:13,794] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:23:13,819] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:23:13,821] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 15:23:13,838] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 15:23:13,840] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 15:23:13,847] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 15:23:13,863] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 15:23:13,866] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,061] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,061] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,065] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:23:14,066] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 20000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 15:23:14,067] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 15:23:14,067] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:23:14,067] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:23:14,067] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:23:14,068] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:23:14,069] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:23:14,070] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,227] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,227] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,227] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,265] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,265] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,267] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:23:14,268] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 15:23:14,269] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:23:14,270] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:23:14,270] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:23:14,271] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:23:14,274] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:23:14,275] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 15:23:14,275] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 15:23:14,275] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,458] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,458] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,458] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,644] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,644] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,645] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,669] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,669] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,669] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,848] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,848] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:23:14,851] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 15:23:14,852] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 15:23:15,164] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-12-02 15:23:15,209] INFO Unable to read additional data from server sessionid 0x1000699efe70000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:23:15,360] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 61 (kafka.log.ProducerStateManager)
[2019-12-02 15:23:15,817] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 15:23:15,921] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 15:23:15,951] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:23:16,127] INFO Session: 0x1000699efe70000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:23:16,127] INFO EventThread shut down for session: 0x1000699efe70000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:23:16,129] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:23:16,130] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:17,028] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:17,028] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:17,029] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:18,030] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:18,030] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:18,030] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:19,033] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:19,033] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:23:19,035] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 15:23:19,061] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 15:23:19,067] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 15:25:21,764] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:25:21,773] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:25:21,774] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:25:21,775] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:25:21,775] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 15:25:21,953] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:25:21,954] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 15:25:22,054] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,054] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,054] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,054] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,054] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,054] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,123] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,123] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,123] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,123] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,123] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,123] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,124] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,124] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,124] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,140] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,140] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,140] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:22,181] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 15:25:22,231] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:25:33,843] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 15:25:37,513] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:25:37,516] INFO starting (kafka.server.KafkaServer)
[2019-12-02 15:25:37,518] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 15:25:37,572] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:25:37,789] INFO Expiring session 0x1000699efe70000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:37,793] INFO Processed session termination for sessionid: 0x1000699efe70000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:37,794] INFO Creating new log file: log.302 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 15:25:37,807] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,807] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,807] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,807] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,811] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,811] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,820] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,820] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,821] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,824] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:25:37,905] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:25:37,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:25:37,962] INFO Accepted socket connection from /127.0.0.1:57925 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:25:37,973] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:25:38,161] INFO Client attempting to establish new session at /127.0.0.1:57925 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:38,171] INFO Established session 0x10006c6e38a0000 with negotiated timeout 6000 for client /127.0.0.1:57925 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:25:38,173] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10006c6e38a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:25:38,181] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:25:38,441] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x1 zxid:0x304 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,573] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x2 zxid:0x305 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,575] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x3 zxid:0x306 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,581] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x4 zxid:0x307 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,584] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x5 zxid:0x308 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,589] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x6 zxid:0x309 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,592] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x7 zxid:0x30a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,594] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x8 zxid:0x30b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,596] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0x9 zxid:0x30c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,599] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0xa zxid:0x30d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,602] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0xb zxid:0x30e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,606] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0xc zxid:0x30f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:38,608] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:create cxid:0xd zxid:0x310 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:39,688] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 15:25:40,821] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:25:40,894] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:25:41,036] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:25:41,052] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:25:41,068] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:25:41,396] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 15:25:42,711] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:42,850] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 503 ms (kafka.log.Log)
[2019-12-02 15:25:42,929] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:42,930] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-02 15:25:43,003] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,003] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-12-02 15:25:43,196] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,202] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 185 ms (kafka.log.Log)
[2019-12-02 15:25:43,262] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,263] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-12-02 15:25:43,305] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,305] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-12-02 15:25:43,390] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,391] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-12-02 15:25:43,463] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,464] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-12-02 15:25:43,511] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,512] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 15:25:43,548] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,550] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 15:25:43,608] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,608] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-12-02 15:25:43,780] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,781] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 166 ms (kafka.log.Log)
[2019-12-02 15:25:43,845] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,846] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-12-02 15:25:43,880] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,881] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 15:25:43,955] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:43,956] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-12-02 15:25:44,007] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,008] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-12-02 15:25:44,078] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,079] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-12-02 15:25:44,177] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,178] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 97 ms (kafka.log.Log)
[2019-12-02 15:25:44,296] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,297] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 117 ms (kafka.log.Log)
[2019-12-02 15:25:44,347] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,348] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-12-02 15:25:44,387] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,388] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 15:25:44,490] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,491] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2019-12-02 15:25:44,782] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:44,795] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:25:45,053] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 559 ms (kafka.log.Log)
[2019-12-02 15:25:45,159] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,159] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 96 ms (kafka.log.Log)
[2019-12-02 15:25:45,252] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,253] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-12-02 15:25:45,297] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,298] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 15:25:45,479] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,480] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 180 ms (kafka.log.Log)
[2019-12-02 15:25:45,535] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,536] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-12-02 15:25:45,590] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,591] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:25:45,622] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 84 ms (kafka.log.Log)
[2019-12-02 15:25:45,644] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,645] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-12-02 15:25:45,737] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,738] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-12-02 15:25:45,768] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,769] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-12-02 15:25:45,809] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,810] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 15:25:45,929] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:45,929] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 116 ms (kafka.log.Log)
[2019-12-02 15:25:46,122] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,123] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 192 ms (kafka.log.Log)
[2019-12-02 15:25:46,286] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,287] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 162 ms (kafka.log.Log)
[2019-12-02 15:25:46,411] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 61 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,412] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000061.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:25:46,442] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 61 in 153 ms (kafka.log.Log)
[2019-12-02 15:25:46,462] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,462] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-12-02 15:25:46,546] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,547] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-12-02 15:25:46,598] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,598] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-12-02 15:25:46,663] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,663] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-12-02 15:25:46,701] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,702] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 15:25:46,750] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,750] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:25:46,953] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:46,955] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 200 ms (kafka.log.Log)
[2019-12-02 15:25:47,106] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,107] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 151 ms (kafka.log.Log)
[2019-12-02 15:25:47,127] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,128] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-12-02 15:25:47,173] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,174] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-12-02 15:25:47,206] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,207] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-12-02 15:25:47,261] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,261] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-12-02 15:25:47,406] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,407] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 144 ms (kafka.log.Log)
[2019-12-02 15:25:47,505] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,505] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 97 ms (kafka.log.Log)
[2019-12-02 15:25:47,588] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,589] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-12-02 15:25:47,797] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:25:47,797] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 205 ms (kafka.log.Log)
[2019-12-02 15:25:47,802] INFO Logs loading complete in 6404 ms. (kafka.log.LogManager)
[2019-12-02 15:25:47,822] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 15:25:47,823] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 15:25:49,554] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 15:25:49,799] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 15:25:49,802] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 15:25:49,906] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:49,926] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:49,931] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:49,961] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:50,147] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:25:50,304] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 15:25:50,340] INFO Stat of the created znode at /brokers/ids/0 is: 785,785,1575329150331,1575329150331,1,0,0,72065045328691200,188,0,785
 (kafka.zk.KafkaZkClient)
[2019-12-02 15:25:50,351] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 785 (kafka.zk.KafkaZkClient)
[2019-12-02 15:25:50,599] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:50,719] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:50,722] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:25:50,841] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:25:50,888] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:25:50,894] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:50,939] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:21000,blockEndProducerId:21999) by writing to Zk with path version 22 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 15:25:50,975] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:25:51,104] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:25:51,105] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:25:51,225] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0000 type:multi cxid:0x65 zxid:0x314 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:25:51,266] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:25:51,337] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 15:25:51,439] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:25:51,545] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:25:51,546] INFO Kafka startTimeMs: 1575329151344 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:25:51,549] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 15:25:51,676] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:25:51,978] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:51,981] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,187] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,187] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,192] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,192] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,200] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,200] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,206] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,206] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,297] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,297] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,322] INFO Replica loaded for partition interactions-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-12-02 15:25:52,323] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,335] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,336] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,351] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,351] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,435] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,436] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,472] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,473] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,480] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,481] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,544] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,544] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,551] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,551] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,559] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,559] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,566] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,567] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,573] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,574] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,580] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,580] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,587] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,588] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,593] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,593] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,598] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,598] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,607] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,608] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,705] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,705] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,711] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,712] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,717] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,717] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,721] INFO Replica loaded for partition changes-0 with initial high watermark 61 (kafka.cluster.Replica)
[2019-12-02 15:25:52,722] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 61. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,724] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,725] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,732] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,732] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,758] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,758] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,811] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,813] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,818] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,818] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,830] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,830] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,837] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,837] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,855] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,855] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,951] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,952] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,963] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,963] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:52,971] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:52,972] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,071] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,071] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,077] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,078] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,085] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,086] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,090] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,090] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,096] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,098] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,105] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,105] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,187] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,188] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,195] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,196] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,207] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,208] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,318] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,319] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,359] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,359] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,365] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,366] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,377] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,378] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,384] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 15:25:53,384] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,389] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,390] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,395] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:25:53,396] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:25:53,413] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,415] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 33 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,454] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,454] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,454] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,454] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,455] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,455] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,456] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,456] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,457] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,458] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,458] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,459] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,459] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,459] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,460] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,460] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,461] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,461] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,462] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,462] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,463] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,464] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,464] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,465] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,465] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,466] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,738] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-42573 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:25:53,739] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 273 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,742] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,742] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,742] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,743] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,743] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,743] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,744] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,744] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,745] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,746] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,746] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:53,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:25:54,493] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-57141 in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member consumer-1-0129500e-313e-42ad-a394-a654f0e51acb with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:25:54,505] INFO [GroupCoordinator 0]: Stabilized group console-consumer-57141 generation 1 (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:25:54,603] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-57141 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:33:15,800] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:33:15,821] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:33:15,822] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:33:15,822] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:33:15,822] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 15:33:15,848] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:33:15,849] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 15:33:15,880] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,880] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,880] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,880] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,880] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,880] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,881] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,882] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,883] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,893] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,893] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,893] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:15,908] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 15:33:15,951] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:33:15,954] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 15:33:21,323] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 15:33:22,714] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:33:22,715] INFO starting (kafka.server.KafkaServer)
[2019-12-02 15:33:22,716] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 15:33:22,750] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:33:22,764] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,764] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,764] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,764] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,764] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,765] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,766] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,766] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,766] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,766] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,767] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,767] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,767] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,767] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,767] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,768] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:22,791] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:33:22,797] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:33:22,825] INFO Accepted socket connection from /127.0.0.1:58472 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:33:22,829] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:33:22,835] INFO Client attempting to establish new session at /127.0.0.1:58472 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:22,842] INFO Established session 0x10006c6e38a0001 with negotiated timeout 6000 for client /127.0.0.1:58472 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:33:22,845] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10006c6e38a0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:33:22,855] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:33:22,939] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x1 zxid:0x316 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,953] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x2 zxid:0x317 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,955] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x3 zxid:0x318 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,956] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x4 zxid:0x319 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,960] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x5 zxid:0x31a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,963] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x6 zxid:0x31b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,965] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x7 zxid:0x31c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,966] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x8 zxid:0x31d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,967] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0x9 zxid:0x31e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,969] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0xa zxid:0x31f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,970] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0xb zxid:0x320 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,971] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0xc zxid:0x321 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:22,972] INFO Got user-level KeeperException when processing sessionid:0x10006c6e38a0001 type:create cxid:0xd zxid:0x322 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:23,233] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 15:33:23,385] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:33:23,401] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:33:23,438] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:23,438] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:23,440] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:23,495] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 15:33:23,498] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 15:33:23,503] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:33:23,504] INFO Processed session termination for sessionid: 0x10006c6e38a0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:33:23,507] INFO Closed socket connection for client /127.0.0.1:58472 which had sessionid 0x10006c6e38a0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 15:33:23,507] INFO Session: 0x10006c6e38a0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:33:23,508] INFO EventThread shut down for session: 0x10006c6e38a0001 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:33:23,513] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:33:23,515] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:24,444] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:24,444] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:24,445] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:25,449] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:25,450] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:25,450] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:26,450] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:26,450] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:33:26,458] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 15:33:26,459] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-02 15:33:26,472] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 15:33:37,210] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-92198 in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member consumer-1-bcf5f6e4-6f25-4ca4-8716-e76610dcbed9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:33:37,212] INFO [GroupCoordinator 0]: Stabilized group console-consumer-92198 generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:33:37,218] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-92198 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:23,301] INFO [GroupCoordinator 0]: Member consumer-1-0129500e-313e-42ad-a394-a654f0e51acb in group console-consumer-57141 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:23,304] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-57141 in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member consumer-1-0129500e-313e-42ad-a394-a654f0e51acb on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:23,307] INFO [GroupCoordinator 0]: Group console-consumer-57141 with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:23,348] INFO Unable to read additional data from server sessionid 0x10006c6e38a0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:23,637] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:34:23,640] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 15:34:23,642] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 15:34:23,927] INFO [GroupCoordinator 0]: Member consumer-1-bcf5f6e4-6f25-4ca4-8716-e76610dcbed9 in group console-consumer-92198 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:23,928] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-92198 in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member consumer-1-bcf5f6e4-6f25-4ca4-8716-e76610dcbed9 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:23,928] INFO [GroupCoordinator 0]: Group console-consumer-92198 with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:34:24,467] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:24,469] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:24,577] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:34:26,583] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:26,584] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:28,363] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:28,364] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:29,554] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:29,555] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:31,459] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:31,459] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:33,286] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:33,288] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:34,407] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:34,408] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:36,164] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:36,165] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:37,699] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:37,700] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:39,258] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:39,259] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:40,520] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:40,521] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:41,795] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:41,796] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:43,100] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:43,102] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:44,906] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:44,907] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:46,311] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:46,312] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:47,518] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:47,519] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:48,685] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:48,686] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:50,453] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:50,456] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:51,868] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:51,868] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:53,900] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:53,901] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:55,682] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:55,684] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:57,546] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:57,547] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:59,160] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:34:59,162] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:00,512] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:00,513] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:02,044] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:02,046] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:03,393] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:03,395] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:04,640] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:04,642] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:06,127] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:06,128] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:07,731] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:07,732] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:09,830] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:09,831] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:11,072] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:11,073] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:13,179] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:13,179] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:14,448] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:14,449] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:16,303] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:16,304] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:18,213] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:18,214] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:20,172] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:20,173] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:21,964] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:21,965] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:23,602] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:23,603] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:25,436] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:25,438] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:27,502] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:27,503] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:28,860] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:28,861] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:29,989] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:29,990] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:31,325] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:31,326] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:32,467] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:32,468] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:34,358] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:34,359] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:36,220] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:36,221] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:37,744] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:37,745] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:39,612] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:39,614] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:41,469] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:41,470] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:43,130] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:43,131] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:44,456] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:44,456] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:46,544] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:46,545] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:48,142] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:48,143] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:49,531] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:49,531] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:50,907] INFO [GroupMetadataManager brokerId=0] Group console-consumer-92198 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:35:50,919] INFO [GroupMetadataManager brokerId=0] Group console-consumer-57141 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:35:50,920] INFO [GroupMetadataManager brokerId=0] Group console-consumer-42573 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:35:50,922] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:35:50,935] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:50,936] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:52,822] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:52,823] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:54,215] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:54,216] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:56,068] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:56,069] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:57,732] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:57,733] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:59,477] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:35:59,478] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:00,888] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:00,888] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:02,392] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:02,393] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:03,707] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:03,708] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:05,090] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:05,091] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:06,429] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:06,430] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:08,443] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:08,444] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:10,160] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:10,162] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:11,710] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:11,711] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:12,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:12,876] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:14,887] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:14,887] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:16,457] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:16,458] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:18,345] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:18,346] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:20,041] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:20,041] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:22,133] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:22,133] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:24,050] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:24,051] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:25,882] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:25,883] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:27,159] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:27,164] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:28,652] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:28,653] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:30,133] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:30,135] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:31,500] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:31,500] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:33,554] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:33,555] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:34,990] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:34,990] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:36,821] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:36,822] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:38,718] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:38,719] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:40,620] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:40,621] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:42,577] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:42,579] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:44,255] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:44,256] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:45,901] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:45,901] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:47,148] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:47,149] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:48,679] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:48,680] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:50,096] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:50,097] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:51,561] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:51,562] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:52,956] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:52,957] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:54,546] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:54,548] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:55,709] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:55,710] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:57,656] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:57,657] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:59,359] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:36:59,361] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:00,971] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:00,971] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:02,982] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:02,983] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:04,373] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:04,374] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:05,746] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:05,747] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:07,442] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:07,443] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:08,998] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:08,999] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:10,194] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:10,195] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:11,429] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:11,430] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:13,214] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:13,216] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:15,204] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:15,205] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:16,736] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:16,737] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:18,036] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:18,037] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:20,021] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:20,023] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:21,312] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:21,313] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:22,426] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:22,427] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:23,739] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:23,740] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:25,139] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:25,140] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:26,637] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:26,638] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:28,169] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:28,169] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:29,427] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:29,428] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:31,166] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:31,167] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:32,580] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:32,581] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:33,987] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:33,988] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:36,036] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:36,037] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:37,560] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:37,561] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:39,298] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:39,299] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:40,509] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:40,510] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:41,647] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:41,648] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:43,321] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:43,322] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:44,625] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:44,626] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:46,184] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:46,185] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:47,979] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:47,982] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:50,072] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:50,072] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:51,367] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:51,367] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:52,856] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:52,856] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:54,024] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:54,025] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:55,791] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:55,792] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:57,658] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:57,660] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:59,026] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:37:59,027] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:00,325] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:00,327] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:01,844] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:01,846] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:03,379] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:03,380] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:04,868] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:04,871] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:06,068] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:06,069] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:07,480] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:38:07,482] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:38:07,482] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:38:07,482] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:38:07,483] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 15:38:07,508] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:38:07,509] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 15:38:07,538] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,539] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,539] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,539] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,540] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,540] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,542] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,542] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,542] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,542] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,542] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,543] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,543] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,543] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,543] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,557] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,557] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,558] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:07,582] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 15:38:07,604] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:07,604] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:07,602] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:38:09,687] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:09,688] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:09,694] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:59045 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:38:09,860] INFO Client attempting to renew session 0x10006c6e38a0000 at /0:0:0:0:0:0:0:1:59045 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:09,866] INFO Established session 0x10006c6e38a0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:59045 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:09,866] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10006c6e38a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:09,867] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:38:09,912] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 15:38:09,942] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:38:09,944] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:38:09,945] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:38:09,945] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 15:38:09,962] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 15:38:09,964] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 15:38:09,969] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 15:38:09,974] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 15:38:09,975] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,041] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,041] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,045] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:38:10,048] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 21000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 15:38:10,049] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 15:38:10,049] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:38:10,049] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:38:10,050] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:38:10,050] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:38:10,053] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:38:10,054] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,137] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,139] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,139] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,241] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,241] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,242] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:38:10,243] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 15:38:10,243] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:38:10,244] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:38:10,244] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:38:10,245] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:38:10,247] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:38:10,248] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 15:38:10,248] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 15:38:10,249] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,442] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,442] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,442] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,645] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,645] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,646] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,707] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,707] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,707] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,846] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,846] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:10,849] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 15:38:10,850] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 15:38:11,387] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-12-02 15:38:11,467] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-12-02 15:38:11,580] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 80 (kafka.log.ProducerStateManager)
[2019-12-02 15:38:11,664] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-12-02 15:38:11,717] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-12-02 15:38:11,784] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 15:38:11,804] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:38:11,809] INFO Processed session termination for sessionid: 0x10006c6e38a0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:11,811] INFO Creating new log file: log.324 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 15:38:11,821] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:59045 which had sessionid 0x10006c6e38a0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 15:38:11,821] INFO Session: 0x10006c6e38a0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:11,823] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:38:11,825] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:11,824] INFO EventThread shut down for session: 0x10006c6e38a0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:12,138] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:12,138] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:12,139] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:12,240] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:12,240] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:12,240] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:13,030] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 15:38:13,240] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:13,240] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:13,243] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 15:38:13,290] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 15:38:13,299] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 15:38:14,110] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:38:14,113] INFO starting (kafka.server.KafkaServer)
[2019-12-02 15:38:14,115] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 15:38:14,155] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:38:14,170] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,206] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,239] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,239] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,240] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,245] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,250] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,250] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,251] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,251] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,251] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,252] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,252] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,252] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,252] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,254] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:38:14,277] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:14,277] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:38:14,304] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:59054 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:38:14,310] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:14,317] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:59054 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:14,318] INFO Established session 0x10006d275f70000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:59054 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:38:14,335] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10006d275f70000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:38:14,342] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:38:14,423] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x1 zxid:0x326 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,439] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x2 zxid:0x327 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,444] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x3 zxid:0x328 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,446] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x4 zxid:0x329 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,448] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x5 zxid:0x32a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,450] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x6 zxid:0x32b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,451] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x7 zxid:0x32c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,453] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x8 zxid:0x32d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,454] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0x9 zxid:0x32e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,457] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0xa zxid:0x32f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,463] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0xb zxid:0x330 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,466] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0xc zxid:0x331 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,467] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:create cxid:0xd zxid:0x332 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:14,717] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 15:38:14,833] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:38:14,847] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:38:14,904] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:14,904] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:14,910] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:38:15,045] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 15:38:15,269] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,284] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 181 ms (kafka.log.Log)
[2019-12-02 15:38:15,300] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,300] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 15:38:15,349] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,350] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 15:38:15,385] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,386] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 15:38:15,432] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,433] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 15:38:15,470] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,470] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-12-02 15:38:15,519] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,520] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:38:15,549] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,549] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-12-02 15:38:15,612] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,613] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-12-02 15:38:15,635] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,636] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-12-02 15:38:15,670] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,670] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 15:38:15,749] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,749] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-12-02 15:38:15,829] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,829] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-12-02 15:38:15,871] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,872] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 15:38:15,912] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,913] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 15:38:15,954] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,955] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:38:15,992] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:15,993] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 15:38:16,071] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,071] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-12-02 15:38:16,154] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,154] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-12-02 15:38:16,197] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,198] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 15:38:16,284] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,284] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 84 ms (kafka.log.Log)
[2019-12-02 15:38:16,418] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,419] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 132 ms (kafka.log.Log)
[2019-12-02 15:38:16,482] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,500] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:38:16,532] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 111 ms (kafka.log.Log)
[2019-12-02 15:38:16,620] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,620] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2019-12-02 15:38:16,653] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,653] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-12-02 15:38:16,780] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,780] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 123 ms (kafka.log.Log)
[2019-12-02 15:38:16,818] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,819] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 15:38:16,866] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,866] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:38:16,914] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,915] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:38:16,917] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 49 ms (kafka.log.Log)
[2019-12-02 15:38:16,955] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,955] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 15:38:16,997] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:16,998] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 15:38:17,037] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,037] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:38:17,079] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,080] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 15:38:17,119] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,119] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:38:17,158] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,158] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 15:38:17,199] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,199] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 15:38:17,245] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 80 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,246] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000080.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:38:17,247] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 80 in 46 ms (kafka.log.Log)
[2019-12-02 15:38:17,283] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,283] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 15:38:17,323] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,323] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:38:17,365] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,365] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:38:17,404] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,405] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 15:38:17,450] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,451] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:38:17,492] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,492] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:38:17,542] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,543] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-12-02 15:38:17,582] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,583] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:38:17,630] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,630] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-12-02 15:38:17,671] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,671] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:38:17,715] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,715] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 15:38:17,755] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,755] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:38:17,756] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 15:38:17,803] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,803] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:38:17,853] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,854] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:38:17,855] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 51 ms (kafka.log.Log)
[2019-12-02 15:38:17,904] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,905] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-12-02 15:38:17,949] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:38:17,949] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 15:38:17,952] INFO Logs loading complete in 2905 ms. (kafka.log.LogManager)
[2019-12-02 15:38:17,964] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 15:38:17,965] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 15:38:18,400] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 15:38:18,438] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 15:38:18,446] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 15:38:18,484] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,485] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,486] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,487] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,505] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:38:18,583] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 15:38:18,610] INFO Stat of the created znode at /brokers/ids/0 is: 819,819,1575329898597,1575329898597,1,0,0,72065095029948416,188,0,819
 (kafka.zk.KafkaZkClient)
[2019-12-02 15:38:18,612] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 819 (kafka.zk.KafkaZkClient)
[2019-12-02 15:38:18,683] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,688] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,688] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:38:18,731] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:38:18,733] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:38:18,745] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:18,758] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:22000,blockEndProducerId:22999) by writing to Zk with path version 23 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 15:38:18,832] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:38:18,835] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:38:18,835] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:38:18,936] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:38:19,029] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 15:38:19,049] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:38:19,049] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:38:19,049] INFO Kafka startTimeMs: 1575329899030 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:38:19,051] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 15:38:19,206] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:38:19,207] INFO Got user-level KeeperException when processing sessionid:0x10006d275f70000 type:multi cxid:0x6f zxid:0x336 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:38:19,280] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,285] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,312] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,312] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,319] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,319] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,324] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,324] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,332] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 15:38:19,333] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,337] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,337] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,345] INFO Replica loaded for partition interactions-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 15:38:19,346] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,350] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,350] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,354] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,355] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,363] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,364] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,367] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,367] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,371] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,371] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,375] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,375] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,381] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,382] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,385] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,385] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,390] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,390] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,396] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,396] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,401] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,401] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,405] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,405] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,408] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,409] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,417] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,417] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,421] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,421] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,425] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,425] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,433] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,434] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,439] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,439] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,446] INFO Replica loaded for partition changes-0 with initial high watermark 80 (kafka.cluster.Replica)
[2019-12-02 15:38:19,446] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 80. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,449] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,449] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,452] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,453] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,456] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,456] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,463] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,464] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,469] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,469] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,477] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,477] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,481] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,482] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,485] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,486] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,490] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,490] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,495] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,495] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,500] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,500] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,505] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,505] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,513] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,513] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,517] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,517] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,521] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 15:38:19,521] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,523] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,524] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,529] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,529] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,532] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,532] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,535] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,536] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,539] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,539] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,546] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,546] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,552] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,552] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,555] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,556] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,561] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,562] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,566] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 15:38:19,566] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,568] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,568] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,571] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:38:19,571] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:38:19,591] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,601] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,602] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,602] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,636] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 44 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,642] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,642] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,642] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,642] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,644] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,644] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,644] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,645] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,645] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,645] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,645] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,645] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,646] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,716] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 70 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,717] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,717] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,722] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,735] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,735] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,735] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,736] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,736] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,736] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,736] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,737] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,737] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:19,737] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:38:29,432] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-10619 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member consumer-1-caf207ea-7b36-4d08-bab8-bb5cc497544f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:38:29,445] INFO [GroupCoordinator 0]: Stabilized group console-consumer-10619 generation 1 (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:38:29,469] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-10619 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:01,114] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:46:01,120] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 15:46:01,125] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 15:46:01,186] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 15:46:01,194] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:46:01,197] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:46:01,198] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:46:01,199] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 15:46:01,229] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 15:46:01,231] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 15:46:01,241] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 15:46:01,247] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 15:46:01,249] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,314] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,322] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,327] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:46:01,329] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 22000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 15:46:01,331] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 15:46:01,331] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:46:01,332] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:46:01,332] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:46:01,333] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:46:01,334] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:01,335] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,470] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,470] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,471] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,549] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,549] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,550] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:01,551] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 15:46:01,552] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:46:01,553] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:46:01,553] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:46:01,554] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:46:01,556] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:46:01,557] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 15:46:01,557] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 15:46:01,557] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,688] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,688] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,689] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,754] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,754] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,754] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,920] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,920] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,921] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,956] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,959] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:01,967] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 15:46:01,969] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 15:46:02,231] INFO Unable to read additional data from server sessionid 0x10006d275f70000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:46:02,420] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-12-02 15:46:02,504] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-12-02 15:46:02,643] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 112 (kafka.log.ProducerStateManager)
[2019-12-02 15:46:02,697] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 15:46:02,718] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:46:03,716] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:46:03,820] INFO Session: 0x10006d275f70000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:03,820] INFO EventThread shut down for session: 0x10006d275f70000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:46:03,822] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:46:03,822] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:04,203] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:04,203] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:04,203] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:05,203] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:05,203] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:05,204] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:05,262] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:05,263] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:05,265] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 15:46:05,299] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 15:46:05,306] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 15:46:28,556] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:46:28,558] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:46:28,558] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:46:28,559] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 15:46:28,559] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 15:46:28,610] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 15:46:28,611] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 15:46:28,640] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,641] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,641] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,641] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,641] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,641] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,642] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,642] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,642] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,642] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,643] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,643] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,643] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,643] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,643] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,660] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,660] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,661] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:28,677] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 15:46:28,698] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:46:35,611] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 15:46:36,616] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 15:46:36,618] INFO starting (kafka.server.KafkaServer)
[2019-12-02 15:46:36,619] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 15:46:36,656] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:46:36,666] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,666] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,666] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,666] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,666] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,666] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,667] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,667] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,668] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,669] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 15:46:36,688] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:46:36,690] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:46:36,719] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:46:36,719] INFO Accepted socket connection from /127.0.0.1:59486 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 15:46:36,792] INFO Client attempting to establish new session at /127.0.0.1:59486 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:36,795] INFO Creating new log file: log.337 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 15:46:36,806] INFO Established session 0x10006da1afa0000 with negotiated timeout 6000 for client /127.0.0.1:59486 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:36,811] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10006da1afa0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 15:46:36,815] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 15:46:36,939] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x1 zxid:0x338 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,956] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x2 zxid:0x339 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,960] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x3 zxid:0x33a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,961] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x4 zxid:0x33b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,963] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x5 zxid:0x33c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,966] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x6 zxid:0x33d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,968] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x7 zxid:0x33e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,970] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x8 zxid:0x33f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,979] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0x9 zxid:0x340 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,981] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0xa zxid:0x341 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,982] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0xb zxid:0x342 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,985] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0xc zxid:0x343 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:36,987] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:create cxid:0xd zxid:0x344 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:37,328] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 15:46:37,443] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:46:37,454] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 15:46:37,524] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:37,527] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:37,530] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 15:46:37,632] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 15:46:37,799] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:37,812] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 120 ms (kafka.log.Log)
[2019-12-02 15:46:37,828] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:37,829] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-02 15:46:37,836] INFO Expiring session 0x10006d275f70000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 15:46:37,836] INFO Processed session termination for sessionid: 0x10006d275f70000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:37,870] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:37,870] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 15:46:37,914] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:37,915] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 15:46:37,947] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:37,947] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-12-02 15:46:37,992] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:37,993] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 15:46:38,032] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,033] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:46:38,071] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,072] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 15:46:38,115] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,115] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 15:46:38,153] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,154] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 15:46:38,206] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,210] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-12-02 15:46:38,280] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,281] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-12-02 15:46:38,296] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,296] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-02 15:46:38,336] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,336] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:46:38,399] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,399] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-12-02 15:46:38,421] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,421] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-12-02 15:46:38,459] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,459] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 15:46:38,516] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,517] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-12-02 15:46:38,539] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,539] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-12-02 15:46:38,580] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,581] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 15:46:38,619] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,620] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:46:38,681] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,681] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-12-02 15:46:38,733] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,738] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:46:38,805] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 122 ms (kafka.log.Log)
[2019-12-02 15:46:38,813] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,814] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 15:46:38,854] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,855] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:46:38,902] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,903] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 15:46:38,945] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,945] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 15:46:38,984] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:38,985] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 15:46:39,033] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,035] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:46:39,063] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 77 ms (kafka.log.Log)
[2019-12-02 15:46:39,106] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,106] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 15:46:39,163] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,164] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-12-02 15:46:39,196] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,197] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 15:46:39,248] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,248] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-12-02 15:46:39,255] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,255] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 15:46:39,301] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,301] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:46:39,349] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,350] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 15:46:39,387] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 112 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,387] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000112.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:46:39,418] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 112 in 67 ms (kafka.log.Log)
[2019-12-02 15:46:39,435] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,436] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-12-02 15:46:39,465] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,465] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-12-02 15:46:39,507] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,507] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:46:39,551] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,552] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 15:46:39,592] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,593] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 15:46:39,632] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,633] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:46:39,668] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 74 ms (kafka.log.Log)
[2019-12-02 15:46:39,680] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,680] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-02 15:46:39,716] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,716] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 15:46:39,761] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,762] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:46:39,799] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,800] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 15:46:39,846] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,846] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 15:46:39,898] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,899] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:46:39,935] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 87 ms (kafka.log.Log)
[2019-12-02 15:46:39,943] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,944] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-02 15:46:39,985] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:39,986] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 15:46:40,028] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 83 ms (kafka.log.Log)
[2019-12-02 15:46:40,035] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:40,035] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 15:46:40,075] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 15:46:40,075] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 15:46:40,082] INFO Logs loading complete in 2449 ms. (kafka.log.LogManager)
[2019-12-02 15:46:40,101] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 15:46:40,103] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 15:46:40,849] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 15:46:40,900] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 15:46:40,904] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 15:46:41,022] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,023] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,024] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,028] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,050] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 15:46:41,212] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 15:46:41,238] INFO Stat of the created znode at /brokers/ids/0 is: 838,838,1575330401228,1575330401228,1,0,0,72065127863156736,188,0,838
 (kafka.zk.KafkaZkClient)
[2019-12-02 15:46:41,244] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 838 (kafka.zk.KafkaZkClient)
[2019-12-02 15:46:41,407] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,416] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,417] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 15:46:41,518] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:41,521] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:41,525] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:41,546] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:23000,blockEndProducerId:23999) by writing to Zk with path version 24 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 15:46:41,581] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:46:41,594] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 15:46:41,598] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 15:46:41,725] INFO Got user-level KeeperException when processing sessionid:0x10006da1afa0000 type:multi cxid:0x65 zxid:0x349 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 15:46:41,755] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 15:46:41,832] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 15:46:41,974] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:46:41,974] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:46:41,975] INFO Kafka startTimeMs: 1575330401841 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 15:46:41,979] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 15:46:41,986] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 15:46:42,014] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,020] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,077] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,079] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,088] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,088] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,099] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,099] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,104] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 15:46:42,104] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,111] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,111] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,119] INFO Replica loaded for partition interactions-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-12-02 15:46:42,119] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,123] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,124] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,131] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,131] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,137] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,137] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,144] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,144] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,150] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,151] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,156] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,156] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,187] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,187] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,195] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,199] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,206] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,206] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,215] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,215] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,222] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,223] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,237] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,238] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,249] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,249] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,255] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,256] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,266] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,266] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,270] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,271] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,302] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,303] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,308] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,309] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,321] INFO Replica loaded for partition changes-0 with initial high watermark 112 (kafka.cluster.Replica)
[2019-12-02 15:46:42,321] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 112. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,325] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,329] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,335] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,336] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,348] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,348] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,355] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,355] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,364] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,365] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,369] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,369] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,379] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,380] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,387] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 1 (kafka.cluster.Replica)
[2019-12-02 15:46:42,388] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,401] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,401] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,408] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,413] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,419] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,419] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,424] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,425] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,438] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,439] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,447] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,447] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,453] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 15:46:42,453] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,456] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,456] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,508] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,508] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,517] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,517] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,523] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,524] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,532] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,532] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,536] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,537] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,548] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,549] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,554] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,554] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,564] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,564] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,568] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 15:46:42,568] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,574] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,578] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,582] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 15:46:42,583] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 15:46:42,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,800] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,800] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,800] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,800] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,802] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,803] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,803] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,804] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 39 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,835] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,836] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,836] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,836] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,836] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,837] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,838] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,838] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,904] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 65 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,905] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,906] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,922] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,922] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,923] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,923] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,923] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,924] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,924] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,931] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,932] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,933] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,933] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,933] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,933] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,934] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,947] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,948] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,948] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,949] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,949] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,949] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,949] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:42,959] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-10619 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:43,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 51 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:43,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:46:52,753] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-62227 in state PreparingRebalance with old generation 0 (__consumer_offsets-40) (reason: Adding new member consumer-1-ee981e64-b572-490c-ac99-cd5d80468dd6 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:52,759] INFO [GroupCoordinator 0]: Stabilized group console-consumer-62227 generation 1 (__consumer_offsets-40) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:52,771] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-62227 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:53,005] INFO [GroupCoordinator 0]: Member consumer-1-caf207ea-7b36-4d08-bab8-bb5cc497544f in group console-consumer-10619 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:53,006] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-10619 in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: removing member consumer-1-caf207ea-7b36-4d08-bab8-bb5cc497544f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:46:53,007] INFO [GroupCoordinator 0]: Group console-consumer-10619 with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 15:56:41,552] INFO [GroupMetadataManager brokerId=0] Group console-consumer-10619 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 15:56:41,555] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
