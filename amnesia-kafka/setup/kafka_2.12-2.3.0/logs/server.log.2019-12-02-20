[2019-12-02 20:32:30,944] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:32:31,012] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:32:31,012] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:32:31,012] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:32:31,012] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:32:31,035] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:32:31,036] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:32:31,068] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,068] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,068] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,068] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,069] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,069] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,070] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,083] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,084] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,084] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:31,106] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:32:31,129] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:32:34,646] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:32:35,581] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:32:35,582] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:32:35,583] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:32:35,614] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:35,623] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,624] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,624] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,624] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,624] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,624] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,625] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,627] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:35,647] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:35,649] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:35,674] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:35,675] INFO Accepted socket connection from /127.0.0.1:60724 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:32:35,734] INFO Client attempting to establish new session at /127.0.0.1:60724 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:35,737] INFO Creating new log file: log.3bc (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:32:35,747] INFO Established session 0x10007dfdd740000 with negotiated timeout 6000 for client /127.0.0.1:60724 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:35,751] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007dfdd740000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:35,759] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:35,860] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x1 zxid:0x3bd txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,879] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x2 zxid:0x3be txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,881] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x3 zxid:0x3bf txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,882] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x4 zxid:0x3c0 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,883] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x5 zxid:0x3c1 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,887] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x6 zxid:0x3c2 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,889] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x7 zxid:0x3c3 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,890] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x8 zxid:0x3c4 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,891] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0x9 zxid:0x3c5 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,893] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0xa zxid:0x3c6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,895] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0xb zxid:0x3c7 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,896] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0xc zxid:0x3c8 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:35,897] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:create cxid:0xd zxid:0x3c9 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:36,169] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:32:36,318] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:32:36,328] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:32:36,365] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:36,365] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:36,369] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:36,427] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:32:36,648] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:36,661] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 122 ms (kafka.log.Log)
[2019-12-02 20:32:36,677] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:36,678] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-02 20:32:36,719] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:36,720] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:32:36,761] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:36,762] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:32:36,885] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:36,892] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:36,940] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 176 ms (kafka.log.Log)
[2019-12-02 20:32:36,965] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:36,965] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-12-02 20:32:37,047] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,048] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:37,086] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 119 ms (kafka.log.Log)
[2019-12-02 20:32:37,093] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,093] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:32:37,130] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,130] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:32:37,175] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,175] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:32:37,217] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,217] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:37,257] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,257] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:32:37,298] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,298] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:37,338] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,338] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:32:37,385] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,386] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-12-02 20:32:37,426] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,426] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:37,507] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,508] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:37,545] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 117 ms (kafka.log.Log)
[2019-12-02 20:32:37,552] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,553] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:32:37,592] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,592] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:32:37,660] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,661] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:37,689] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 95 ms (kafka.log.Log)
[2019-12-02 20:32:37,696] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,696] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:32:37,743] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,743] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 20:32:37,826] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,827] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:37,865] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 120 ms (kafka.log.Log)
[2019-12-02 20:32:37,909] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,909] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:32:37,950] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:37,950] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:38,032] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,033] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:38,068] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 116 ms (kafka.log.Log)
[2019-12-02 20:32:38,082] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,084] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:38,121] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 50 ms (kafka.log.Log)
[2019-12-02 20:32:38,127] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,128] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:32:38,168] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,169] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:38,206] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-12-02 20:32:38,253] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,253] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 20:32:38,292] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,292] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:32:38,332] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,333] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:38,372] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,373] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:38,412] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,413] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:38,452] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,453] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:32:38,493] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,494] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:32:38,618] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 557 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,620] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000557.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:38,656] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 557 in 161 ms (kafka.log.Log)
[2019-12-02 20:32:38,663] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,663] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:32:38,703] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,703] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:32:38,745] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,745] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:32:38,786] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,786] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:32:38,826] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,827] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:32:38,871] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,871] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:38,910] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-12-02 20:32:38,919] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,919] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:32:38,952] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,953] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-12-02 20:32:38,998] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:38,999] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 20:32:39,040] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,040] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:39,081] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,081] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:32:39,163] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,163] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:39,199] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 117 ms (kafka.log.Log)
[2019-12-02 20:32:39,207] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,207] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:32:39,249] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,251] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:32:39,288] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-12-02 20:32:39,293] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,294] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:32:39,334] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:32:39,334] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:32:39,337] INFO Logs loading complete in 2909 ms. (kafka.log.LogManager)
[2019-12-02 20:32:39,352] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:32:39,353] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:32:39,867] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:32:39,921] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:32:39,924] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:32:39,999] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,002] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,004] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,004] INFO Expiring session 0x100074979700000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:40,005] INFO Processed session termination for sessionid: 0x100074979700000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:40,005] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,032] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:32:40,110] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:32:40,175] INFO Stat of the created znode at /brokers/ids/0 is: 971,971,1575347560150,1575347560150,1,0,0,72066252112396288,188,0,971
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:32:40,181] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 971 (kafka.zk.KafkaZkClient)
[2019-12-02 20:32:40,263] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,269] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,269] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:32:40,301] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:32:40,305] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:32:40,310] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:40,355] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:30000,blockEndProducerId:30999) by writing to Zk with path version 31 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:32:40,383] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:32:40,403] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:32:40,403] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:32:40,480] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:32:40,505] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:32:40,514] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740000 type:multi cxid:0x6f zxid:0x3ce txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:40,634] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:32:40,634] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:32:40,635] INFO Kafka startTimeMs: 1575347560508 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:32:40,637] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:32:40,648] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:32:40,713] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,717] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,776] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,777] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,781] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,782] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,787] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:32:40,788] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,790] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,791] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,793] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,793] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,797] INFO Replica loaded for partition interactions-0 with initial high watermark 23 (kafka.cluster.Replica)
[2019-12-02 20:32:40,797] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,799] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,799] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,802] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,802] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,806] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,806] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,809] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,809] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,813] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,813] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,817] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,818] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,821] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,821] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,824] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,824] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,827] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,828] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,832] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,832] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,837] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,837] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,841] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,841] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,845] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,845] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,848] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,848] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,858] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,858] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,862] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,862] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,870] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,870] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,873] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,874] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,877] INFO Replica loaded for partition changes-0 with initial high watermark 557 (kafka.cluster.Replica)
[2019-12-02 20:32:40,877] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 557. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,880] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,880] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,884] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,884] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,888] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,888] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,892] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,892] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,896] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,897] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,900] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,900] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,903] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,903] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,906] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,906] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,909] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,909] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,912] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,912] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,918] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,919] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,922] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,922] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,925] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,925] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,929] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,929] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,934] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,935] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,938] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,938] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,941] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,942] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,944] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,945] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,947] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,947] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,949] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,949] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,953] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,953] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,955] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,956] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,959] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,960] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,963] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,963] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,969] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:32:40,970] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,972] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,972] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:40,975] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:32:40,975] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:32:41,002] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,003] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,003] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,005] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,005] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,013] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,013] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,013] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,013] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,014] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,014] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,014] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,014] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,017] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,017] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,018] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,019] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,019] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,039] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 36 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,080] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 40 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,080] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,080] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,081] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,081] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,090] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,090] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,095] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,100] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,104] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,104] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,108] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,108] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,108] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,117] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:41,127] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:32:51,263] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-87448 in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-1-08ec3b12-5331-4442-8f2e-7f2f36dff8e8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:32:51,273] INFO [GroupCoordinator 0]: Stabilized group console-consumer-87448 generation 1 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:32:51,291] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-87448 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:32:51,819] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:32:51,822] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:32:51,822] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:32:51,822] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:32:51,822] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:32:51,839] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:32:51,839] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:32:51,849] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,850] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,850] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,850] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,850] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,850] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,851] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,851] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,851] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,851] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,851] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,851] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,852] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,852] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,852] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,863] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,864] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,864] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:51,880] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:32:51,895] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:32:51,897] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 20:32:56,331] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:32:57,015] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:32:57,017] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:32:57,019] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:32:57,040] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:57,046] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,046] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,046] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,046] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,047] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,047] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,048] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,050] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,068] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:57,069] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:57,090] INFO Accepted socket connection from /127.0.0.1:60751 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:32:57,093] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:57,097] INFO Client attempting to establish new session at /127.0.0.1:60751 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:57,099] INFO Established session 0x10007dfdd740001 with negotiated timeout 6000 for client /127.0.0.1:60751 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:32:57,100] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007dfdd740001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:57,104] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:57,168] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x1 zxid:0x3d0 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,179] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x2 zxid:0x3d1 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,180] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x3 zxid:0x3d2 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,182] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x4 zxid:0x3d3 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,184] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x5 zxid:0x3d4 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,185] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x6 zxid:0x3d5 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,186] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x7 zxid:0x3d6 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,188] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x8 zxid:0x3d7 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,189] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0x9 zxid:0x3d8 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,190] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0xa zxid:0x3d9 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,191] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0xb zxid:0x3da txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,193] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0xc zxid:0x3db txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,194] INFO Got user-level KeeperException when processing sessionid:0x10007dfdd740001 type:create cxid:0xd zxid:0x3dc txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,407] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:32:57,507] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:32:57,519] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:32:57,549] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:57,550] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:57,551] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:57,598] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 20:32:57,600] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:32:57,604] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:57,607] INFO Processed session termination for sessionid: 0x10007dfdd740001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:32:57,610] INFO Session: 0x10007dfdd740001 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:32:57,614] INFO EventThread shut down for session: 0x10007dfdd740001 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:32:57,614] INFO Closed socket connection for client /127.0.0.1:60751 which had sessionid 0x10007dfdd740001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:32:57,615] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:32:57,616] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:58,556] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:58,556] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:58,556] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:59,559] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:59,559] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:32:59,560] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:33:00,561] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:33:00,561] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:33:00,571] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:33:00,572] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-02 20:33:00,575] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:33:09,986] INFO [GroupCoordinator 0]: Member consumer-1-08ec3b12-5331-4442-8f2e-7f2f36dff8e8 in group console-consumer-87448 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:33:09,987] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-87448 in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-1-08ec3b12-5331-4442-8f2e-7f2f36dff8e8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:33:09,989] INFO [GroupCoordinator 0]: Group console-consumer-87448 with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:33:10,697] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:33:10,698] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:33:10,699] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:33:10,887] WARN Session 0x10007dfdd740000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2019-12-02 20:33:11,000] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:33:11,000] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:33:12,132] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:12,132] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:12,233] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:33:13,323] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:13,324] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:14,620] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:14,621] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:15,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:15,921] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:17,435] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:17,435] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:18,682] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:18,683] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:19,931] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:19,932] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:21,525] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:21,525] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:23,264] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:23,265] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:25,185] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:25,187] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:27,121] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:27,124] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:29,117] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:29,118] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:31,117] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:31,117] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:32,267] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:32,272] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:34,174] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:34,179] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:35,535] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:35,536] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:36,918] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:36,918] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:38,520] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:38,522] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:39,997] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:39,998] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:41,670] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:41,672] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:43,375] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:43,375] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:45,324] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:45,328] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:46,729] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:46,729] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:47,948] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:47,951] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:49,299] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:49,299] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:50,853] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:50,854] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:51,976] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:51,977] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:53,420] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:53,421] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:55,184] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:55,184] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:56,310] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:56,310] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:57,925] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:57,925] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:59,936] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:33:59,938] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:01,790] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:01,790] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:03,746] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:34:03,749] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:34:03,749] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:34:03,750] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:34:03,750] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:34:03,767] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:34:03,768] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:34:03,793] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,793] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,793] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,793] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,794] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,794] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,795] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,796] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,797] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,805] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,805] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,805] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:03,817] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:34:03,834] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:34:03,839] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:03,840] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:03,843] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60813 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:34:03,912] WARN Exception causing close of session 0x0: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:34:03,912] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60813 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:34:03,914] INFO Unable to read additional data from server sessionid 0x10007dfdd740000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:05,748] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:05,748] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:05,748] INFO Accepted socket connection from /127.0.0.1:60814 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:34:05,752] INFO Client attempting to renew session 0x10007dfdd740000 at /127.0.0.1:60814 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:05,756] INFO Established session 0x10007dfdd740000 with negotiated timeout 6000 for client /127.0.0.1:60814 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:05,756] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007dfdd740000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:05,756] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:05,773] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:34:05,779] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:34:05,780] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:34:05,781] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:34:05,783] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:34:05,798] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:34:05,799] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:34:05,801] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:34:05,803] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:34:05,804] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:05,820] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:05,820] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:05,822] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:34:05,823] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 30000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:34:05,824] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:34:05,824] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:34:05,824] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:34:05,824] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:34:05,825] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:34:05,825] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:05,826] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,021] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,021] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,022] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,130] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,130] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,132] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:06,133] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:34:06,133] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:34:06,134] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:34:06,134] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:34:06,134] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:34:06,136] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:34:06,137] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:34:06,137] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:34:06,137] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,303] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,303] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,303] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,369] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,369] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,370] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,570] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,570] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,571] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,773] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,773] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:06,775] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:34:06,776] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:34:06,797] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:34:07,125] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:34:07,141] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:07,143] INFO Processed session termination for sessionid: 0x10007dfdd740000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:07,144] INFO Creating new log file: log.3de (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:34:07,152] INFO Closed socket connection for client /127.0.0.1:60814 which had sessionid 0x10007dfdd740000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:34:07,154] INFO Session: 0x10007dfdd740000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:07,155] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:07,156] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:07,156] INFO EventThread shut down for session: 0x10007dfdd740000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:07,557] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:07,557] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:07,557] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:08,558] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:08,558] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:08,559] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:09,121] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:34:09,562] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:09,562] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:09,564] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:34:09,593] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:34:09,602] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:34:09,833] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:34:09,834] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:34:09,835] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:34:09,856] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:09,863] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,863] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,863] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,863] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,863] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,863] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,864] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,864] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,864] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,864] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,865] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,865] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,865] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,865] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,865] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,866] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:09,885] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:09,887] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:09,905] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60827 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:34:09,908] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:09,911] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60827 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:09,915] INFO Established session 0x10007e1460e0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60827 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:09,917] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007e1460e0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:09,922] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:09,996] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x1 zxid:0x3e0 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,007] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x2 zxid:0x3e1 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,008] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x3 zxid:0x3e2 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,010] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x4 zxid:0x3e3 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,011] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x5 zxid:0x3e4 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,013] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x6 zxid:0x3e5 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,014] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x7 zxid:0x3e6 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,015] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x8 zxid:0x3e7 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,017] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0x9 zxid:0x3e8 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,018] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0xa zxid:0x3e9 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,019] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0xb zxid:0x3ea txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,021] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0xc zxid:0x3eb txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,022] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:create cxid:0xd zxid:0x3ec txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:10,170] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:34:10,265] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:34:10,274] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:34:10,307] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:10,307] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:10,310] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:10,357] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:34:10,451] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,461] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-12-02 20:34:10,503] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,504] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:34:10,546] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,547] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:34:10,587] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,588] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:34:10,640] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,649] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:10,720] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 130 ms (kafka.log.Log)
[2019-12-02 20:34:10,727] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,728] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:34:10,759] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,760] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:10,786] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 56 ms (kafka.log.Log)
[2019-12-02 20:34:10,793] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,793] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:34:10,838] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,838] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:34:10,878] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,878] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:34:10,922] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,922] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:34:10,963] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:10,963] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:11,004] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,004] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:11,045] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,045] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:11,085] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,086] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:34:11,126] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,127] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:34:11,169] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,170] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,203] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 75 ms (kafka.log.Log)
[2019-12-02 20:34:11,211] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,212] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:34:11,251] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,251] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:34:11,295] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,296] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,331] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-12-02 20:34:11,350] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,351] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,352] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 13 ms (kafka.log.Log)
[2019-12-02 20:34:11,381] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,382] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-12-02 20:34:11,441] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,442] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,466] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 81 ms (kafka.log.Log)
[2019-12-02 20:34:11,473] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,474] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:34:11,515] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,515] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:34:11,641] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,642] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,673] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 156 ms (kafka.log.Log)
[2019-12-02 20:34:11,686] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,686] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,725] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 48 ms (kafka.log.Log)
[2019-12-02 20:34:11,734] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,734] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:34:11,766] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,767] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:11,768] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 32 ms (kafka.log.Log)
[2019-12-02 20:34:11,815] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,816] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:34:11,854] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,855] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:34:11,895] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,895] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:11,936] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,937] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:34:11,976] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:11,976] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:34:12,020] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,020] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:34:12,062] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,062] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:34:12,108] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 557 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,109] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000557.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:12,140] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 557 in 75 ms (kafka.log.Log)
[2019-12-02 20:34:12,148] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,148] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:34:12,188] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,188] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:12,228] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,228] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:12,269] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,270] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:34:12,310] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,310] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:12,352] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,353] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:12,387] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-12-02 20:34:12,395] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,395] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:34:12,432] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,432] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:34:12,476] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,476] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:34:12,518] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,518] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:34:12,558] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,558] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:12,602] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,602] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:12,603] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-12-02 20:34:12,639] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,639] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:34:12,726] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,727] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:34:12,728] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 87 ms (kafka.log.Log)
[2019-12-02 20:34:12,767] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,768] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:34:12,809] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:34:12,809] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:34:12,812] INFO Logs loading complete in 2455 ms. (kafka.log.LogManager)
[2019-12-02 20:34:12,825] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:34:12,826] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:34:13,110] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:34:13,148] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:34:13,150] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:34:13,205] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,206] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,207] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,208] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,227] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:34:13,296] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:34:13,330] INFO Stat of the created znode at /brokers/ids/0 is: 1005,1005,1575347653320,1575347653320,1,0,0,72066258162286592,188,0,1005
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:34:13,332] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1005 (kafka.zk.KafkaZkClient)
[2019-12-02 20:34:13,397] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,403] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,404] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:34:13,455] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:13,459] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:13,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:13,494] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:31000,blockEndProducerId:31999) by writing to Zk with path version 32 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:34:13,529] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:34:13,532] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:34:13,538] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:34:13,608] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:34:13,656] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:34:13,673] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:34:13,675] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:34:13,675] INFO Kafka startTimeMs: 1575347653659 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:34:13,706] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0000 type:multi cxid:0x6f zxid:0x3f0 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:13,748] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:34:13,820] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:34:13,842] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,846] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,875] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,875] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,881] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,881] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,886] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:34:13,887] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,891] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:13,891] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,896] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,897] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,901] INFO Replica loaded for partition interactions-0 with initial high watermark 23 (kafka.cluster.Replica)
[2019-12-02 20:34:13,901] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,903] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,904] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,907] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,907] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,911] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,912] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,915] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,916] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,919] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,919] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,923] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,923] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,926] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,927] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,930] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,930] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,937] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,938] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,941] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:13,941] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,944] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,945] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,949] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,949] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,955] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:13,956] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,958] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,959] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,962] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,962] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,967] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,968] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,972] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,972] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,975] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,975] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,978] INFO Replica loaded for partition changes-0 with initial high watermark 557 (kafka.cluster.Replica)
[2019-12-02 20:34:13,979] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 557. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,981] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,982] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,985] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,985] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,988] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,989] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:13,995] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:13,996] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,004] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,004] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,008] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:14,008] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,011] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,011] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,014] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:14,014] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,017] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,017] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,020] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,020] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,024] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,025] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,029] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,029] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,033] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,033] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,036] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,036] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,040] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:14,040] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,043] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,043] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,046] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,046] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,053] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,054] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,056] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:14,057] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,059] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,059] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,062] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:14,063] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,065] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,065] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,070] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:34:14,070] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,073] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,074] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,077] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:34:14,077] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,079] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,079] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,087] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:34:14,087] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:34:14,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,148] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,148] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,148] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,148] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,148] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,148] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,157] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,157] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,157] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,157] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,157] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,206] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:14,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 73 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,214] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,214] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,214] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,228] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,231] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,231] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,232] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,232] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,232] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,232] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,232] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,243] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,247] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,252] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,252] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,252] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,252] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:14,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:34:25,633] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:34:25,650] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:34:25,650] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:34:25,650] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:34:25,650] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:34:25,691] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:34:25,693] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:34:25,706] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,706] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,707] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,707] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,707] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,707] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,709] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,710] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,710] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,718] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-29475 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member consumer-1-26ce9cbe-34e1-4710-9ed3-66a644316910 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:25,727] INFO [GroupCoordinator 0]: Stabilized group console-consumer-29475 generation 1 (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:25,732] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,733] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,733] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:25,756] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-29475 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:25,781] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:34:25,828] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:34:25,833] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 20:34:30,738] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:34:31,477] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:34:31,479] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:34:31,481] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:34:31,502] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:31,508] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,509] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,509] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,509] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,509] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,509] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,510] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,510] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,510] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,510] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,511] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,511] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,511] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,511] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,511] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,512] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,529] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:31,531] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:31,548] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60849 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:34:31,551] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:31,554] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60849 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:31,556] INFO Established session 0x10007e1460e0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60849 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:34:31,557] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007e1460e0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:31,561] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:31,606] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x1 zxid:0x3f2 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,616] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x2 zxid:0x3f3 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,618] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x3 zxid:0x3f4 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,619] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x4 zxid:0x3f5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,620] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x5 zxid:0x3f6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,622] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x6 zxid:0x3f7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,623] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x7 zxid:0x3f8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,624] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x8 zxid:0x3f9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,625] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0x9 zxid:0x3fa txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,627] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0xa zxid:0x3fb txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,628] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0xb zxid:0x3fc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,629] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0xc zxid:0x3fd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,630] INFO Got user-level KeeperException when processing sessionid:0x10007e1460e0001 type:create cxid:0xd zxid:0x3fe txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,781] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:34:31,877] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:34:31,889] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:34:31,917] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:31,917] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:31,918] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:31,960] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 20:34:31,963] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:34:31,968] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:31,969] INFO Processed session termination for sessionid: 0x10007e1460e0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:34:31,970] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60849 which had sessionid 0x10007e1460e0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:34:31,971] INFO Session: 0x10007e1460e0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:34:31,972] INFO EventThread shut down for session: 0x10007e1460e0001 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:31,974] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:31,975] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:32,874] INFO [GroupCoordinator 0]: Member consumer-1-26ce9cbe-34e1-4710-9ed3-66a644316910 in group console-consumer-29475 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:32,875] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-29475 in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: removing member consumer-1-26ce9cbe-34e1-4710-9ed3-66a644316910 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:32,877] INFO [GroupCoordinator 0]: Group console-consumer-29475 with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:32,922] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:32,922] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:32,922] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:34:32,963] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:34:32,964] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:34:32,966] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:34:33,117] WARN Session 0x10007e1460e0000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2019-12-02 20:34:33,224] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:33,225] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:33,264] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:34:33,265] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:34:34,766] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:34,768] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:34,869] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:34:36,371] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:36,371] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:38,083] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:38,083] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:40,178] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:40,178] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:41,663] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:41,663] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:43,683] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:43,684] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:44,985] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:44,986] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:46,345] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:46,345] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:47,672] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:47,673] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:48,675] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-30254 in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-81aef5d4-bc0e-4b0f-b3d9-449961194844 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:48,676] INFO [GroupCoordinator 0]: Stabilized group console-consumer-30254 generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:48,681] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-30254 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:34:49,170] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:49,171] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:50,999] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:51,000] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:52,359] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:52,360] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:53,628] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:53,628] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:55,555] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:55,555] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:57,002] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:57,003] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:58,402] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:58,403] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:59,928] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:34:59,929] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:01,170] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:01,171] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:03,150] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:03,151] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:04,675] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:04,676] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:05,944] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:05,948] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:07,692] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:07,708] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:09,799] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:09,799] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:11,204] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:11,204] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:12,347] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:12,359] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:14,133] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:14,134] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:15,641] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:15,642] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:17,741] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:17,741] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:19,158] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:19,158] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:20,366] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:20,367] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:22,211] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:22,213] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:23,600] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:23,601] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:25,410] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:25,411] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:27,108] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:27,109] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:29,185] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:29,187] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:31,193] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:31,194] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:33,174] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:33,175] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:34,301] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:34,302] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:36,384] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:36,385] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:37,968] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:37,969] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:39,944] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:39,945] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:41,292] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:41,293] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:43,179] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:43,180] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:45,149] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:45,152] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:47,248] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:47,250] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:49,322] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:49,322] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:51,357] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:51,358] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:52,880] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:52,882] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:54,231] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:54,232] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:56,254] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:56,255] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:57,833] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:57,833] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:59,367] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:35:59,368] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:01,409] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:01,410] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:02,630] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:02,631] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:04,606] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:04,607] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:06,512] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:06,512] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:08,601] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:08,605] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:10,459] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:10,459] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:12,494] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:12,497] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:14,187] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:14,187] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:15,578] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:15,579] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:16,803] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:16,804] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:18,374] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:18,375] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:19,701] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:19,701] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:21,014] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:21,017] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:22,676] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:22,677] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:24,301] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:24,302] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:26,359] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:26,359] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:27,939] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:27,940] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:29,730] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:29,731] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:31,466] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:31,466] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:33,278] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:33,280] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:34,504] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:34,505] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:36,270] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:36,271] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:37,652] INFO [GroupCoordinator 0]: Member consumer-1-81aef5d4-bc0e-4b0f-b3d9-449961194844 in group console-consumer-30254 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:37,652] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-30254 in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-81aef5d4-bc0e-4b0f-b3d9-449961194844 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:37,652] INFO [GroupCoordinator 0]: Group console-consumer-30254 with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:38,375] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:38,376] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:39,798] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:39,799] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:40,957] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:40,958] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:42,343] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:42,344] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:44,032] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:44,033] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:46,088] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:46,089] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:46,238] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:36:46,241] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:36:46,241] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:36:46,241] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:36:46,241] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:36:46,257] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:36:46,258] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:36:46,285] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,285] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,285] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,286] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,286] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,286] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,287] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,288] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,299] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,299] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,299] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:46,312] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:36:46,325] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:36:47,448] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:47,449] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:47,455] INFO Accepted socket connection from /127.0.0.1:60986 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:36:47,507] INFO Client attempting to renew session 0x10007e1460e0000 at /127.0.0.1:60986 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:47,513] INFO Established session 0x10007e1460e0000 with negotiated timeout 6000 for client /127.0.0.1:60986 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:47,513] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007e1460e0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:47,514] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:36:47,530] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:36:47,537] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:36:47,538] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:36:47,539] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:36:47,539] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:36:47,561] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:36:47,563] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:36:47,565] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:36:47,568] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:36:47,569] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:47,741] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:47,741] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:47,744] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:36:47,745] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 31000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:36:47,746] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:36:47,746] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:36:47,746] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:36:47,746] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:36:47,747] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:36:47,748] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:47,748] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:47,901] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:47,901] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:47,902] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,068] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,068] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,069] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:48,070] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:36:48,070] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:36:48,071] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:36:48,071] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:36:48,071] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:36:48,073] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:36:48,073] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:36:48,074] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:36:48,074] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,168] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,169] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,169] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,239] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,239] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,239] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,443] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,443] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,444] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,543] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,543] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:48,546] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:36:48,547] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:36:48,724] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:36:48,993] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-12-02 20:36:49,126] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:36:49,137] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:36:49,139] INFO Processed session termination for sessionid: 0x10007e1460e0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:49,139] INFO Creating new log file: log.400 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:36:49,150] INFO Closed socket connection for client /127.0.0.1:60986 which had sessionid 0x10007e1460e0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:36:49,150] INFO Session: 0x10007e1460e0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:49,150] INFO EventThread shut down for session: 0x10007e1460e0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:49,152] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:36:49,152] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:49,720] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:49,720] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:49,720] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:50,725] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:50,725] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:50,738] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:51,417] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:36:51,725] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:51,725] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:51,730] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:36:51,775] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:36:51,780] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:36:52,503] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:36:52,505] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:36:52,506] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:36:52,526] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:36:52,532] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,532] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,532] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,532] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,533] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,533] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,534] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,536] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:36:52,552] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:36:52,553] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:52,570] INFO Accepted socket connection from /127.0.0.1:61002 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:36:52,572] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:52,575] INFO Client attempting to establish new session at /127.0.0.1:61002 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:52,577] INFO Established session 0x10007e3c08d0000 with negotiated timeout 6000 for client /127.0.0.1:61002 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:36:52,578] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007e3c08d0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:36:52,582] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:36:52,631] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x1 zxid:0x402 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,644] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x2 zxid:0x403 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,645] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x3 zxid:0x404 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,646] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x4 zxid:0x405 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,648] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x5 zxid:0x406 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,649] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x6 zxid:0x407 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,650] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x7 zxid:0x408 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,652] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x8 zxid:0x409 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,653] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0x9 zxid:0x40a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,655] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0xa zxid:0x40b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,656] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0xb zxid:0x40c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,657] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0xc zxid:0x40d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,659] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:create cxid:0xd zxid:0x40e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:52,808] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:36:52,892] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:36:52,903] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:36:52,931] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:52,931] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:52,932] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:36:52,977] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:36:53,207] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,286] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 266 ms (kafka.log.Log)
[2019-12-02 20:36:53,326] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,329] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-12-02 20:36:53,367] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,368] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-12-02 20:36:53,404] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,407] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-12-02 20:36:53,476] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,483] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:53,515] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 103 ms (kafka.log.Log)
[2019-12-02 20:36:53,524] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,524] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:36:53,574] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,575] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:53,575] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 48 ms (kafka.log.Log)
[2019-12-02 20:36:53,682] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,683] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 105 ms (kafka.log.Log)
[2019-12-02 20:36:53,725] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,726] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:36:53,775] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,775] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-12-02 20:36:53,818] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,818] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:36:53,858] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,858] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:36:53,897] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,898] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:36:53,945] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,945] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 20:36:53,986] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:53,986] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:54,027] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,028] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:36:54,070] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,070] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,071] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 41 ms (kafka.log.Log)
[2019-12-02 20:36:54,107] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,107] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:36:54,149] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,149] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:54,190] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,190] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,193] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:36:54,233] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,234] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,267] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 72 ms (kafka.log.Log)
[2019-12-02 20:36:54,275] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,276] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:36:54,316] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,317] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,319] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 42 ms (kafka.log.Log)
[2019-12-02 20:36:54,356] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,357] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:36:54,398] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,398] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:54,441] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,442] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,443] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-12-02 20:36:54,482] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,482] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,483] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-12-02 20:36:54,525] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,526] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,527] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:36:54,565] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,566] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,567] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:54,607] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,607] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:54,646] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,646] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:36:54,687] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,688] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:36:54,727] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,728] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:54,774] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,775] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-12-02 20:36:54,822] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,822] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-12-02 20:36:54,829] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,830] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:36:54,878] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 557 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,879] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000557.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:54,880] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 557 in 49 ms (kafka.log.Log)
[2019-12-02 20:36:54,911] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,912] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-12-02 20:36:54,952] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,953] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:36:54,993] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:54,993] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:55,033] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,033] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:55,113] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,114] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-12-02 20:36:55,156] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,157] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:55,158] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 43 ms (kafka.log.Log)
[2019-12-02 20:36:55,195] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,195] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:36:55,235] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,236] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:36:55,275] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,275] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:36:55,316] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,316] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:36:55,357] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,357] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:36:55,399] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,400] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:55,400] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:36:55,438] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,439] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:36:55,480] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,481] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:36:55,482] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:36:55,519] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,520] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:36:55,563] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:36:55,564] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:36:55,566] INFO Logs loading complete in 2589 ms. (kafka.log.LogManager)
[2019-12-02 20:36:55,579] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:36:55,580] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:36:55,905] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:36:55,934] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:36:55,936] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:36:55,971] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:55,972] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:55,973] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:55,974] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:55,989] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:36:56,062] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:36:56,085] INFO Stat of the created znode at /brokers/ids/0 is: 1039,1039,1575347816076,1575347816076,1,0,0,72066268807364608,188,0,1039
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:36:56,086] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1039 (kafka.zk.KafkaZkClient)
[2019-12-02 20:36:56,155] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:56,159] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:56,161] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:36:56,200] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:56,209] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,210] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:56,243] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:32000,blockEndProducerId:32999) by writing to Zk with path version 33 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:36:56,279] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:36:56,295] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:36:56,295] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:36:56,358] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:36:56,389] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:36:56,397] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:36:56,397] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:36:56,397] INFO Kafka startTimeMs: 1575347816390 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:36:56,421] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:36:56,511] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:36:56,520] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0000 type:multi cxid:0x6f zxid:0x412 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:36:56,532] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,543] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,574] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,574] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,579] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,580] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,585] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:36:56,587] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,593] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,593] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,597] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,597] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,601] INFO Replica loaded for partition interactions-0 with initial high watermark 23 (kafka.cluster.Replica)
[2019-12-02 20:36:56,601] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,604] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,605] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,609] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,609] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,616] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,616] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,623] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,624] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,627] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,627] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,630] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,630] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,635] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,635] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,639] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,639] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,643] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,643] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,647] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,648] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,651] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,652] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,657] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,657] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,661] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,661] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,664] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,664] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,667] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,668] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,675] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,675] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,679] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,679] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,683] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,683] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,687] INFO Replica loaded for partition changes-0 with initial high watermark 557 (kafka.cluster.Replica)
[2019-12-02 20:36:56,688] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 557. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,691] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,692] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,696] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,697] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,700] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,701] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,708] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,708] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,712] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,712] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,716] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,717] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,720] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,720] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,723] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:36:56,724] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,726] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,726] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,730] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,732] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,736] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,737] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,741] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,741] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,745] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,745] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,748] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,748] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,753] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,753] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,758] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,758] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,762] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,762] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,765] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:36:56,765] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,768] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,768] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,772] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,772] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,779] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,779] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,782] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,782] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,789] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:36:56,790] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,792] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,793] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,797] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:36:56,797] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,800] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,800] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,804] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:36:56,804] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:36:56,815] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,816] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,817] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,818] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,818] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,818] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,820] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,821] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,830] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,830] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,830] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,831] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,831] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,832] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,833] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,834] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,834] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,834] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,834] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,834] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,914] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:56,916] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 100 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,928] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,928] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,929] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,929] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,929] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,934] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,940] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,940] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,940] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,941] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,941] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,941] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,946] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,946] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,946] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,953] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,954] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,954] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,954] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,954] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,956] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,956] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,960] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:56,960] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,961] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,966] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,973] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,974] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,979] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:36:56,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,979] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,980] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,984] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,984] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,984] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,985] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:36:56,992] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:37:07,413] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-53782 in state PreparingRebalance with old generation 0 (__consumer_offsets-46) (reason: Adding new member consumer-1-4ba4943c-b18d-450c-a57e-52c53ff1d23c with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:07,421] INFO [GroupCoordinator 0]: Stabilized group console-consumer-53782 generation 1 (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:07,439] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-53782 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:07,706] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:37:07,709] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:37:07,709] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:37:07,709] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:37:07,709] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:37:07,726] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:37:07,726] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:37:07,734] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,734] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,734] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,734] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,734] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,734] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,735] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,736] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,744] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,744] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,744] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:07,757] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:37:07,772] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:37:07,773] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 20:37:12,404] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:37:13,115] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:37:13,116] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:37:13,117] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:37:13,138] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:37:13,144] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,144] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,144] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,144] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,144] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,144] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,145] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,145] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,146] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,147] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,173] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:37:13,175] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:37:13,193] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61025 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:37:13,196] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:37:13,199] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61025 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:13,201] INFO Established session 0x10007e3c08d0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61025 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:37:13,203] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007e3c08d0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:37:13,206] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:37:13,266] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x1 zxid:0x414 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,276] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x2 zxid:0x415 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,277] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x3 zxid:0x416 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,278] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x4 zxid:0x417 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,280] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x5 zxid:0x418 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,281] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x6 zxid:0x419 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,283] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x7 zxid:0x41a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,284] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x8 zxid:0x41b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,285] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0x9 zxid:0x41c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,286] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0xa zxid:0x41d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,288] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0xb zxid:0x41e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,289] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0xc zxid:0x41f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,291] INFO Got user-level KeeperException when processing sessionid:0x10007e3c08d0001 type:create cxid:0xd zxid:0x420 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,445] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:37:13,544] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:37:13,553] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:37:13,578] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:13,579] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:13,580] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:13,633] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 20:37:13,637] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:37:13,641] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:37:13,642] INFO Processed session termination for sessionid: 0x10007e3c08d0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:37:13,643] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61025 which had sessionid 0x10007e3c08d0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:37:13,645] INFO Session: 0x10007e3c08d0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:37:13,646] INFO EventThread shut down for session: 0x10007e3c08d0001 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:37:13,648] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:37:13,649] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:14,583] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:14,583] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:14,584] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:15,584] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:15,584] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:15,584] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:16,589] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:16,589] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:37:16,599] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:37:16,600] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-02 20:37:16,603] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:37:28,416] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-97714 in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member consumer-1-f9113552-c783-40d0-8358-afadbfe638ee with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:28,417] INFO [GroupCoordinator 0]: Stabilized group console-consumer-97714 generation 1 (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:28,421] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-97714 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:59,513] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:37:59,517] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:37:59,519] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:37:59,550] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:37:59,557] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:37:59,558] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:37:59,558] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:37:59,559] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:37:59,584] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:37:59,586] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:37:59,605] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:37:59,608] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:37:59,609] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,727] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,728] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,731] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:37:59,732] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 32000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:37:59,733] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:37:59,733] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:37:59,734] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:37:59,734] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:37:59,734] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:37:59,735] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:59,736] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,818] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,818] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,818] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,842] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,842] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,843] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:37:59,845] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:37:59,845] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:37:59,846] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:37:59,846] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:37:59,846] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:37:59,849] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:37:59,849] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:37:59,850] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:37:59,850] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,878] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,878] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,878] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,983] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,983] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:37:59,984] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:38:00,105] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:38:00,105] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:38:00,105] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:38:00,128] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:38:00,128] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:38:00,129] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:38:00,130] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:38:00,304] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-12-02 20:38:00,595] INFO Unable to read additional data from server sessionid 0x10007e3c08d0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:38:00,854] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2019-12-02 20:38:01,198] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 621 (kafka.log.ProducerStateManager)
[2019-12-02 20:38:01,336] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-12-02 20:38:01,484] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:38:01,497] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:38:01,691] INFO Session: 0x10007e3c08d0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:38:01,693] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:38:01,693] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:01,693] INFO EventThread shut down for session: 0x10007e3c08d0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:38:02,086] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:02,086] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:02,086] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:03,090] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:03,090] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:03,091] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:04,092] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:04,092] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:38:04,094] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:38:04,114] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:38:04,118] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:43:30,279] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:43:30,284] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:43:30,284] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:43:30,284] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:43:30,284] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:43:30,306] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:43:30,306] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:43:30,350] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,350] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,350] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,350] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,351] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,351] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,353] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,354] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,367] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,367] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,367] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:30,390] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:43:30,411] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:43:34,427] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:43:35,289] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:43:35,290] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:43:35,291] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:43:35,322] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:35,330] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,330] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,330] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,330] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,330] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,331] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,332] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,334] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:35,355] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:35,357] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:35,382] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:35,382] INFO Accepted socket connection from /127.0.0.1:61526 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:43:35,435] INFO Client attempting to establish new session at /127.0.0.1:61526 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:35,436] INFO Creating new log file: log.422 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:43:35,450] INFO Established session 0x10007e9ed7b0000 with negotiated timeout 6000 for client /127.0.0.1:61526 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:35,452] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007e9ed7b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:35,456] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:35,548] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x1 zxid:0x423 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,566] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x2 zxid:0x424 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,567] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x3 zxid:0x425 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,569] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x4 zxid:0x426 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,570] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x5 zxid:0x427 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,573] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x6 zxid:0x428 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,575] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x7 zxid:0x429 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,576] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x8 zxid:0x42a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,578] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0x9 zxid:0x42b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,579] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0xa zxid:0x42c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,581] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0xb zxid:0x42d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,582] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0xc zxid:0x42e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,584] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:create cxid:0xd zxid:0x42f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:35,854] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:43:35,966] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:43:35,977] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:43:36,012] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:36,012] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:36,013] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:36,078] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:43:36,267] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,280] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 122 ms (kafka.log.Log)
[2019-12-02 20:43:36,297] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,297] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-02 20:43:36,337] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,338] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:36,379] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,379] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:36,504] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,511] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:36,555] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 174 ms (kafka.log.Log)
[2019-12-02 20:43:36,581] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,581] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-12-02 20:43:36,702] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,702] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:36,740] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 156 ms (kafka.log.Log)
[2019-12-02 20:43:36,748] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,749] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:36,785] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,785] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:43:36,830] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,830] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:43:36,871] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,872] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:43:36,912] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,912] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:36,952] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,952] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:36,993] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:36,993] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:37,034] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,034] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:37,074] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,075] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:37,119] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,120] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,157] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 81 ms (kafka.log.Log)
[2019-12-02 20:43:37,163] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,164] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:37,204] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,205] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,243] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-12-02 20:43:37,289] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,290] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,367] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 122 ms (kafka.log.Log)
[2019-12-02 20:43:37,378] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,378] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,408] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:37,414] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,415] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:37,502] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,503] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,537] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 121 ms (kafka.log.Log)
[2019-12-02 20:43:37,545] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,546] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:37,585] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,586] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:37,624] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,625] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,663] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-12-02 20:43:37,674] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,676] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,707] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-12-02 20:43:37,717] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,717] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,754] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 45 ms (kafka.log.Log)
[2019-12-02 20:43:37,768] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,769] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:37,799] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-12-02 20:43:37,808] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,808] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:37,855] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,856] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:43:37,894] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,894] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:43:37,935] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,935] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:37,977] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:37,977] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:43:38,016] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,016] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:38,057] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,057] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:38,144] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 621 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,145] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000621.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:38,179] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 621 in 120 ms (kafka.log.Log)
[2019-12-02 20:43:38,186] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,187] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:43:38,227] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,227] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:43:38,274] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,275] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:38,306] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-12-02 20:43:38,312] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,312] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:38,353] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,354] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:43:38,398] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,399] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:38,433] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 78 ms (kafka.log.Log)
[2019-12-02 20:43:38,443] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,443] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:43:38,482] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,483] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:43:38,524] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,525] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:43:38,568] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,568] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:43:38,611] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,612] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:43:38,657] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,658] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:38,697] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 84 ms (kafka.log.Log)
[2019-12-02 20:43:38,705] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,706] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:38,743] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,744] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:38,769] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 63 ms (kafka.log.Log)
[2019-12-02 20:43:38,775] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,776] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:43:38,805] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:38,805] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-12-02 20:43:38,808] INFO Logs loading complete in 2730 ms. (kafka.log.LogManager)
[2019-12-02 20:43:38,822] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:43:38,823] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:43:39,367] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:43:39,413] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:43:39,415] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:43:39,459] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,459] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,460] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,461] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,484] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:43:39,568] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:43:39,605] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0000 type:multi cxid:0x18 zxid:0x430 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/0 Error:KeeperErrorCode = NodeExists for /brokers/ids/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:39,618] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72066268807364608' does not match current session '72066295330963456' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2019-12-02 20:43:39,632] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:122)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1784)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1722)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1689)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:97)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:262)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 20:43:39,635] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:43:39,638] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:43:39,657] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:43:39,667] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:43:39,668] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:43:39,669] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:43:39,670] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:43:39,673] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:43:39,676] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:43:39,677] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:43:39,677] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:43:39,677] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,861] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,861] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:39,861] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,029] INFO Expiring session 0x10007e3c08d0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:40,029] INFO Processed session termination for sessionid: 0x10007e3c08d0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:40,064] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,064] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,064] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,265] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,265] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,265] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,271] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,271] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:40,279] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:43:40,280] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:43:40,594] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:43:40,595] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:40,596] INFO Processed session termination for sessionid: 0x10007e9ed7b0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:40,597] INFO Session: 0x10007e9ed7b0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:40,598] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:40,598] INFO Closed socket connection for client /127.0.0.1:61526 which had sessionid 0x10007e9ed7b0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:43:40,599] INFO EventThread shut down for session: 0x10007e9ed7b0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:40,599] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:41,019] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:41,019] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:41,020] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:42,022] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:42,022] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:42,023] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:42,030] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:42,030] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:42,032] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:43:42,061] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:43:42,069] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:43:42,070] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-02 20:43:42,078] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:43:50,839] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:43:50,842] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:43:50,842] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:43:50,842] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:43:50,842] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:43:50,859] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:43:50,860] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:43:50,868] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,868] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,868] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,868] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,868] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,869] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,870] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,879] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,879] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,880] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:50,896] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:43:50,909] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:43:50,911] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 20:43:55,751] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:43:56,403] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:43:56,404] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:43:56,406] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:43:56,427] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:56,433] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,433] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,433] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,434] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,434] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,434] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,435] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,437] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:43:56,459] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:56,461] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:56,479] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61588 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:43:56,482] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:56,485] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61588 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:56,486] INFO Established session 0x10007e9ed7b0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61588 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:43:56,487] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007e9ed7b0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:43:56,491] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:43:56,558] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x1 zxid:0x434 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,568] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x2 zxid:0x435 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,569] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x3 zxid:0x436 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,571] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x4 zxid:0x437 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,572] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x5 zxid:0x438 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,573] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x6 zxid:0x439 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,575] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x7 zxid:0x43a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,576] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x8 zxid:0x43b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,578] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0x9 zxid:0x43c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,579] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0xa zxid:0x43d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,581] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0xb zxid:0x43e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,582] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0xc zxid:0x43f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,583] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:create cxid:0xd zxid:0x440 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:56,736] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:43:56,825] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:43:56,834] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:43:56,863] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:56,863] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:56,865] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:43:56,913] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:43:57,032] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,045] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2019-12-02 20:43:57,063] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,063] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,072] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,072] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:57,082] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,083] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:57,118] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,131] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,153] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 66 ms (kafka.log.Log)
[2019-12-02 20:43:57,161] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,162] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:57,182] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,183] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,183] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-12-02 20:43:57,191] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,191] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,200] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,200] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:43:57,211] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,212] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:43:57,218] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,218] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,225] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,225] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:57,232] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,232] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:57,238] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,239] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:57,243] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,244] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,249] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,249] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,262] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,263] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,263] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-12-02 20:43:57,268] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,268] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,278] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,278] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,279] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 9 ms (kafka.log.Log)
[2019-12-02 20:43:57,291] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,293] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,293] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-12-02 20:43:57,301] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,301] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,302] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:57,306] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,307] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,318] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,319] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,321] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 13 ms (kafka.log.Log)
[2019-12-02 20:43:57,326] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,326] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,330] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,331] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,342] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,343] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,343] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-12-02 20:43:57,350] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,351] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,351] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 6 ms (kafka.log.Log)
[2019-12-02 20:43:57,365] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,366] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,366] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 13 ms (kafka.log.Log)
[2019-12-02 20:43:57,380] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,380] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,381] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-12-02 20:43:57,385] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,385] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,390] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,390] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,395] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,395] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,399] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,400] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,410] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,410] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-02 20:43:57,415] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,415] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,424] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,425] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-02 20:43:57,433] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 621 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,435] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000621.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,436] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 621 in 10 ms (kafka.log.Log)
[2019-12-02 20:43:57,440] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,441] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,446] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,447] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:43:57,460] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,460] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,461] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 13 ms (kafka.log.Log)
[2019-12-02 20:43:57,467] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,467] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,474] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,474] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,481] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,482] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,483] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 8 ms (kafka.log.Log)
[2019-12-02 20:43:57,493] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,493] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-02 20:43:57,497] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,497] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,501] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,501] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,505] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,505] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,509] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,509] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,517] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,518] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,518] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:57,523] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,523] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:43:57,529] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,530] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:43:57,531] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:57,534] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,535] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-12-02 20:43:57,543] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:43:57,544] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:43:57,546] INFO Logs loading complete in 633 ms. (kafka.log.LogManager)
[2019-12-02 20:43:57,558] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:43:57,559] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:43:57,868] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:43:57,898] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:43:57,899] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:43:57,936] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:57,937] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:57,938] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:57,939] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:57,956] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:43:58,017] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:43:58,032] INFO Stat of the created znode at /brokers/ids/0 is: 1089,1089,1575348238025,1575348238025,1,0,0,72066295330963457,188,0,1089
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:43:58,032] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1089 (kafka.zk.KafkaZkClient)
[2019-12-02 20:43:58,111] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:58,115] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:58,116] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:43:58,168] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:58,169] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:58,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,219] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:33000,blockEndProducerId:33999) by writing to Zk with path version 34 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:43:58,302] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:43:58,304] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:43:58,305] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:43:58,369] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:43:58,369] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0001 type:multi cxid:0x65 zxid:0x444 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:43:58,399] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:43:58,468] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:43:58,469] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:43:58,471] INFO Kafka startTimeMs: 1575348238404 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:43:58,473] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:43:58,514] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:43:58,537] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,542] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,586] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,587] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,610] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 1 (kafka.cluster.Replica)
[2019-12-02 20:43:58,612] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,633] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:43:58,633] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,637] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,637] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,650] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,651] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,656] INFO Replica loaded for partition interactions-0 with initial high watermark 24 (kafka.cluster.Replica)
[2019-12-02 20:43:58,656] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 24. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,664] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,665] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,671] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,671] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,682] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,683] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,687] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,687] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,691] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,691] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,695] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,695] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,698] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,698] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,702] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,703] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,708] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,709] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,713] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,713] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,716] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,717] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,732] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,732] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,736] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,736] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,738] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,739] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,744] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,745] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,755] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 1 (kafka.cluster.Replica)
[2019-12-02 20:43:58,755] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,758] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,758] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,767] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,767] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,785] INFO Replica loaded for partition changes-0 with initial high watermark 621 (kafka.cluster.Replica)
[2019-12-02 20:43:58,785] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 621. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,804] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,805] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,840] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,841] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,855] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,856] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,861] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,861] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,864] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,864] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,868] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,868] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,871] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,871] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,883] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:43:58,883] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,887] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,887] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,896] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,900] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,905] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,905] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,908] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,909] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,912] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,913] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,916] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,917] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,920] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,921] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,926] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,926] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,929] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,929] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,932] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:43:58,933] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,935] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,935] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,937] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,938] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,942] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,944] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,950] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,950] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,953] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:43:58,953] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,956] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,956] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,969] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:43:58,969] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,972] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,972] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,978] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:43:58,979] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:43:58,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,993] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,994] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,994] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,994] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,994] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,994] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,995] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,995] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,996] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,996] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,996] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,996] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,996] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,997] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:58,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,054] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,057] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 65 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,062] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,062] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,062] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,067] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,067] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,071] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,081] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,087] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,087] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,097] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,097] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,097] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,097] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,097] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,098] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,098] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,098] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,101] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,105] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,105] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,106] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,118] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,123] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,125] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,130] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,130] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,130] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,130] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,136] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:43:59,187] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-16156 in state PreparingRebalance with old generation 0 (__consumer_offsets-30) (reason: Adding new member consumer-1-fc617e69-34c2-488f-94ea-5af7edfae1a1 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,194] INFO [GroupCoordinator 0]: Stabilized group console-consumer-16156 generation 1 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:43:59,205] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-16156 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:09,084] INFO [GroupCoordinator 0]: Member consumer-1-4ba4943c-b18d-450c-a57e-52c53ff1d23c in group console-consumer-53782 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:09,086] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-53782 in state PreparingRebalance with old generation 1 (__consumer_offsets-46) (reason: removing member consumer-1-4ba4943c-b18d-450c-a57e-52c53ff1d23c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:09,088] INFO [GroupCoordinator 0]: Group console-consumer-53782 with generation 2 is now empty (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:09,102] INFO [GroupCoordinator 0]: Member consumer-1-f9113552-c783-40d0-8358-afadbfe638ee in group console-consumer-97714 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:09,102] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-97714 in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: removing member consumer-1-f9113552-c783-40d0-8358-afadbfe638ee on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:09,102] INFO [GroupCoordinator 0]: Group console-consumer-97714 with generation 2 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:12,604] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-72578 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-1-ed54d64a-bc5e-4672-a1b8-75feb34597e9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:12,605] INFO [GroupCoordinator 0]: Stabilized group console-consumer-72578 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:44:12,611] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-72578 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:02,386] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:46:02,389] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:46:02,389] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:46:02,389] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:46:02,390] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:46:02,407] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:46:02,408] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:46:02,434] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,435] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,435] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,435] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,435] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,435] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,437] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,449] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,449] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,449] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:02,467] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:46:02,483] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:46:02,485] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 20:46:07,150] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:46:07,957] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:46:07,958] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:46:07,959] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:46:07,982] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:46:07,988] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,988] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,988] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,988] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,988] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,988] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,989] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,989] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,989] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,989] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,989] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,990] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,990] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,990] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,990] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:07,991] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:08,007] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:46:08,009] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:08,027] INFO Accepted socket connection from /127.0.0.1:61668 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:46:08,029] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:08,034] INFO Client attempting to establish new session at /127.0.0.1:61668 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:08,039] INFO Established session 0x10007e9ed7b0002 with negotiated timeout 6000 for client /127.0.0.1:61668 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:46:08,041] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007e9ed7b0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:08,045] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:46:08,098] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x1 zxid:0x446 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,109] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x2 zxid:0x447 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,110] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x3 zxid:0x448 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,111] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x4 zxid:0x449 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,113] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x5 zxid:0x44a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,114] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x6 zxid:0x44b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,116] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x7 zxid:0x44c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,117] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x8 zxid:0x44d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,118] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0x9 zxid:0x44e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,119] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0xa zxid:0x44f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,120] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0xb zxid:0x450 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,122] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0xc zxid:0x451 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,123] INFO Got user-level KeeperException when processing sessionid:0x10007e9ed7b0002 type:create cxid:0xd zxid:0x452 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,302] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:46:08,404] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:46:08,415] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:46:08,445] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:08,445] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:08,447] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:08,492] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 20:46:08,495] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:46:08,499] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:46:08,500] INFO Processed session termination for sessionid: 0x10007e9ed7b0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:46:08,504] INFO EventThread shut down for session: 0x10007e9ed7b0002 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:08,504] INFO Session: 0x10007e9ed7b0002 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:46:08,505] WARN Unable to read additional data from client sessionid 0x10007e9ed7b0002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:46:08,505] INFO Closed socket connection for client /127.0.0.1:61668 which had sessionid 0x10007e9ed7b0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:46:08,507] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:46:08,508] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:09,449] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:09,449] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:09,449] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:10,451] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:10,451] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:10,452] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:11,456] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:11,456] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:46:11,468] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:46:11,469] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-02 20:46:11,471] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:46:49,496] WARN Session 0x10007e9ed7b0001 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2019-12-02 20:46:49,845] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:46:49,848] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:46:49,850] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:46:49,959] INFO [GroupCoordinator 0]: Member consumer-1-ed54d64a-bc5e-4672-a1b8-75feb34597e9 in group console-consumer-72578 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:49,960] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-72578 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-1-ed54d64a-bc5e-4672-a1b8-75feb34597e9 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:49,960] INFO [GroupCoordinator 0]: Group console-consumer-72578 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:50,270] INFO [GroupCoordinator 0]: Member consumer-1-fc617e69-34c2-488f-94ea-5af7edfae1a1 in group console-consumer-16156 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:50,270] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-16156 in state PreparingRebalance with old generation 1 (__consumer_offsets-30) (reason: removing member consumer-1-fc617e69-34c2-488f-94ea-5af7edfae1a1 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:50,271] INFO [GroupCoordinator 0]: Group console-consumer-16156 with generation 2 is now empty (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:46:51,005] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:51,006] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:51,110] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:46:52,286] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:52,287] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:54,056] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:54,057] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:55,535] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:55,536] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:56,719] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:56,721] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:58,086] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:58,087] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:59,400] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:46:59,400] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:01,108] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:01,109] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:03,164] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:03,167] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:04,762] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:04,763] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:06,098] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:06,099] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:08,148] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:08,149] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:09,575] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:09,575] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:10,800] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:10,800] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:12,098] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:12,099] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:13,412] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:13,412] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:14,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:14,921] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:17,004] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:17,005] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:19,094] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:19,095] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:21,028] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:21,028] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:22,145] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:22,148] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:24,007] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:24,008] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:25,288] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:25,288] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:26,437] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:26,438] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:28,203] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:28,204] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:29,499] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:29,499] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:31,528] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:31,531] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:32,918] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:32,920] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:34,179] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:34,179] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:36,007] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:36,008] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:37,202] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:37,203] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:38,470] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:38,470] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:40,026] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:40,026] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:41,247] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:47:41,250] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:47:41,250] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:47:41,250] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:47:41,250] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:47:41,265] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:47:41,266] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:47:41,291] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,291] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,292] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,292] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,292] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,293] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,294] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,295] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,304] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,304] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,304] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,318] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:47:41,333] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:47:41,817] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:41,820] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:41,824] INFO Accepted socket connection from /127.0.0.1:61743 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:47:41,881] INFO Client attempting to renew session 0x10007e9ed7b0001 at /127.0.0.1:61743 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,884] INFO Established session 0x10007e9ed7b0001 with negotiated timeout 6000 for client /127.0.0.1:61743 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:41,885] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007e9ed7b0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:41,885] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:47:41,907] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:47:41,924] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:47:41,925] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:47:41,927] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:47:41,930] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:47:41,945] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:47:41,946] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:47:41,949] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:47:41,951] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:47:41,952] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,120] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,120] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,124] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:47:42,125] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 33000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:47:42,125] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:47:42,125] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:47:42,126] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:47:42,126] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:47:42,126] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:47:42,127] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:42,127] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,222] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,222] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,223] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,321] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,321] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,322] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:42,323] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:47:42,324] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:47:42,324] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:47:42,324] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:47:42,325] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:47:42,327] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:47:42,327] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:47:42,328] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:47:42,328] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,522] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,523] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,524] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,726] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,726] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,726] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,931] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,931] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:42,931] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:43,136] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:43,136] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:43,139] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:47:43,140] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:47:43,179] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:47:43,419] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:47:43,620] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 26 (kafka.log.ProducerStateManager)
[2019-12-02 20:47:43,744] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 722 (kafka.log.ProducerStateManager)
[2019-12-02 20:47:43,754] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:47:43,844] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:47:43,879] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:47:43,894] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:47:43,897] INFO Processed session termination for sessionid: 0x10007e9ed7b0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:43,897] INFO Creating new log file: log.454 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:47:43,905] INFO Closed socket connection for client /127.0.0.1:61743 which had sessionid 0x10007e9ed7b0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:47:43,906] INFO EventThread shut down for session: 0x10007e9ed7b0001 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:43,906] INFO Session: 0x10007e9ed7b0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:43,910] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:47:43,911] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:44,397] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:44,397] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:44,398] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:45,398] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:45,398] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:45,398] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:45,409] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:47:46,096] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:47:46,097] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:47:46,098] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:47:46,121] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:47:46,127] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,127] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,128] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,128] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,128] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,128] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,129] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,129] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,129] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,129] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,130] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,130] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,130] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,130] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,130] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,132] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:47:46,155] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:47:46,156] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:46,175] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61760 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:47:46,181] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:46,184] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61760 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:46,185] INFO Established session 0x10007edbf2f0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61760 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:47:46,187] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007edbf2f0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:47:46,190] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:47:46,252] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x1 zxid:0x456 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,264] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x2 zxid:0x457 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,266] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x3 zxid:0x458 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,268] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x4 zxid:0x459 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,269] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x5 zxid:0x45a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,270] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x6 zxid:0x45b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,272] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x7 zxid:0x45c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,273] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x8 zxid:0x45d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,275] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0x9 zxid:0x45e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,276] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0xa zxid:0x45f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,278] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0xb zxid:0x460 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,280] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0xc zxid:0x461 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,281] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:create cxid:0xd zxid:0x462 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:46,401] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:46,401] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:46,402] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:47:46,438] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:47:46,443] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:47:46,471] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:47:46,566] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:47:46,576] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:47:46,601] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:46,601] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:46,603] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:47:46,651] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:47:46,749] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:46,763] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-12-02 20:47:46,872] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:46,879] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:46,894] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 117 ms (kafka.log.Log)
[2019-12-02 20:47:46,963] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:46,963] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-12-02 20:47:46,996] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:46,996] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-12-02 20:47:47,038] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,039] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,040] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 34 ms (kafka.log.Log)
[2019-12-02 20:47:47,091] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,092] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-12-02 20:47:47,120] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,121] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,122] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 26 ms (kafka.log.Log)
[2019-12-02 20:47:47,157] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,157] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-12-02 20:47:47,202] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,202] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:47:47,241] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,243] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:47:47,290] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,291] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-12-02 20:47:47,333] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,335] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,338] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:47:47,366] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,367] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-12-02 20:47:47,434] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,439] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-12-02 20:47:47,494] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,495] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-12-02 20:47:47,542] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,543] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-12-02 20:47:47,555] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,556] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,557] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 10 ms (kafka.log.Log)
[2019-12-02 20:47:47,597] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,597] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:47,639] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,640] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,641] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 42 ms (kafka.log.Log)
[2019-12-02 20:47:47,678] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,679] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,680] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 37 ms (kafka.log.Log)
[2019-12-02 20:47:47,719] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,720] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,721] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:47,759] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,760] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:47:47,802] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,803] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,805] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 44 ms (kafka.log.Log)
[2019-12-02 20:47:47,839] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,840] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:47:47,879] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,879] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:47:47,922] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,923] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,924] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-12-02 20:47:47,963] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:47,964] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:47,964] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-12-02 20:47:48,005] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,006] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,007] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:47:48,043] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,044] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,045] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 37 ms (kafka.log.Log)
[2019-12-02 20:47:48,084] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,084] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:47:48,127] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,127] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:47:48,169] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,169] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:47:48,208] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,208] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:47:48,258] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,258] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:47:48,298] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,298] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:48,349] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,349] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-12-02 20:47:48,397] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,398] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,399] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 49 ms (kafka.log.Log)
[2019-12-02 20:47:48,434] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,435] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:47:48,476] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,476] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:48,519] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,520] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,521] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:47:48,556] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,556] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 20:47:48,597] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,597] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:48,639] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,640] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,641] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 43 ms (kafka.log.Log)
[2019-12-02 20:47:48,676] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,677] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:47:48,718] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,718] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:47:48,758] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,758] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:48,798] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,799] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:47:48,842] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,843] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:47:48,885] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,886] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,886] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:47:48,925] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,925] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:47:48,968] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:48,969] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:47:48,969] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-12-02 20:47:49,006] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:49,007] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:47:49,047] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:47:49,047] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:47:49,050] INFO Logs loading complete in 2399 ms. (kafka.log.LogManager)
[2019-12-02 20:47:49,063] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:47:49,064] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:47:49,354] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:47:49,386] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:47:49,387] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:47:49,424] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,426] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,426] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,429] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,447] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:47:49,509] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:47:49,535] INFO Stat of the created znode at /brokers/ids/0 is: 1123,1123,1575348469528,1575348469528,1,0,0,72066311734099968,188,0,1123
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:47:49,536] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1123 (kafka.zk.KafkaZkClient)
[2019-12-02 20:47:49,604] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,605] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,606] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:47:49,645] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:49,653] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:49,663] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:49,685] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:34000,blockEndProducerId:34999) by writing to Zk with path version 35 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:47:49,729] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:47:49,731] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:47:49,731] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:47:49,791] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:47:49,835] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:47:49,853] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:47:49,853] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:47:49,853] INFO Kafka startTimeMs: 1575348469840 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:47:49,868] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:47:49,940] INFO Got user-level KeeperException when processing sessionid:0x10007edbf2f0000 type:multi cxid:0x6f zxid:0x466 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:47:49,957] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:47:49,972] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:47:49,977] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,001] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,001] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,012] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:47:50,012] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,017] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:47:50,017] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,021] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,022] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,026] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,026] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,032] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:47:50,033] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,037] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,037] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,042] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,042] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,047] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,047] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,051] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,051] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,057] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,058] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,063] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,063] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,067] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,067] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,071] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,072] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,077] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,077] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,083] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,083] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,086] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,087] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,094] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,094] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,098] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,099] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,102] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,102] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,106] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:47:50,106] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,109] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:47:50,110] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,112] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,113] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,118] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,118] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,122] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:47:50,123] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,127] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,127] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,131] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,131] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,134] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,134] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,138] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,140] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,145] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,146] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,150] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,150] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,156] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,156] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,164] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:47:50,165] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,168] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,168] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,176] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,177] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,181] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,182] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,185] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,186] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,189] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,190] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,194] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,194] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,198] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,200] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,202] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,202] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,210] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,210] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,213] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:47:50,213] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,216] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,216] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,219] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,220] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,223] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,224] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,226] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,226] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,229] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:47:50,230] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,232] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,233] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,238] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:47:50,238] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,240] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,241] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,244] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:47:50,244] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:47:50,253] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,254] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,262] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,262] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,262] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,264] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,264] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,265] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,265] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,267] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,267] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,267] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,267] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,267] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,270] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,270] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,270] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,356] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 107 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,374] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,374] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,381] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,381] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,388] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,389] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,389] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,389] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,390] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,390] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,400] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,400] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,401] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,409] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,410] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,410] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,411] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,411] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,411] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,412] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,412] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,412] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,412] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,413] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,419] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,419] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,426] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,427] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,427] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,432] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,440] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,440] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,440] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,444] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,444] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,445] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,445] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,451] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,461] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:47:50,462] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,462] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,468] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,468] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,469] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,469] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:47:50,474] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:48:01,282] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-15586 in state PreparingRebalance with old generation 0 (__consumer_offsets-26) (reason: Adding new member consumer-1-b75a0274-9259-444a-a206-156b44e55081 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:01,291] INFO [GroupCoordinator 0]: Stabilized group console-consumer-15586 generation 1 (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:01,303] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-15586 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:18,933] INFO [GroupCoordinator 0]: Member consumer-1-b75a0274-9259-444a-a206-156b44e55081 in group console-consumer-15586 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:18,935] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-15586 in state PreparingRebalance with old generation 1 (__consumer_offsets-26) (reason: removing member consumer-1-b75a0274-9259-444a-a206-156b44e55081 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:18,937] INFO [GroupCoordinator 0]: Group console-consumer-15586 with generation 2 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:19,133] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:48:19,134] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:48:19,135] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:48:19,168] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:48:19,174] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:48:19,177] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:48:19,177] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:48:19,177] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:48:19,192] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:48:19,194] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:48:19,197] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:48:19,204] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:48:19,206] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,384] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,384] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,387] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:48:19,388] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 34000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:48:19,389] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:48:19,389] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:48:19,393] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:48:19,393] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:48:19,394] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:48:19,395] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:19,396] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,470] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,470] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,471] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,522] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,522] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,523] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:48:19,524] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:48:19,524] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:48:19,525] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:48:19,525] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:48:19,525] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:48:19,527] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:48:19,528] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:48:19,528] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:48:19,528] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,668] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,668] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,671] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,716] INFO Unable to read additional data from server sessionid 0x10007edbf2f0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:48:19,802] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,802] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,802] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,833] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,833] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:19,834] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:20,037] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:20,037] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:48:20,040] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:48:20,041] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:48:20,306] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:48:20,458] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:48:20,478] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:48:21,021] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:48:21,128] INFO Session: 0x10007edbf2f0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:48:21,128] INFO EventThread shut down for session: 0x10007edbf2f0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:48:21,131] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:48:21,131] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:21,714] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:21,714] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:21,714] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:22,714] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:22,714] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:22,715] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:23,715] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:23,716] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:48:23,717] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:48:23,739] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:48:23,743] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:49:48,542] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:49:48,546] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:49:48,546] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:49:48,546] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:49:48,546] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:49:48,580] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:49:48,581] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:49:48,622] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,622] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,623] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,623] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,623] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,623] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,624] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,624] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,624] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,624] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,624] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,624] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,625] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,625] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,625] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,640] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,641] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,641] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:48,666] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:49:48,691] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:49:52,524] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:49:53,396] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:49:53,397] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:49:53,398] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:49:53,429] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:49:53,437] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,437] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,438] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,438] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,438] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,438] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,439] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,441] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:49:53,461] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:49:53,463] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:49:53,487] INFO Accepted socket connection from /127.0.0.1:61913 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:49:53,488] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:49:53,549] INFO Client attempting to establish new session at /127.0.0.1:61913 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:53,550] INFO Creating new log file: log.467 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:49:53,558] INFO Established session 0x10007efb0c20000 with negotiated timeout 6000 for client /127.0.0.1:61913 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:53,563] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007efb0c20000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:49:53,567] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:49:53,654] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x1 zxid:0x468 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,670] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x2 zxid:0x469 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,672] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x3 zxid:0x46a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,674] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x4 zxid:0x46b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,675] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x5 zxid:0x46c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,678] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x6 zxid:0x46d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,680] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x7 zxid:0x46e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,681] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x8 zxid:0x46f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,683] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0x9 zxid:0x470 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,684] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0xa zxid:0x471 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,686] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0xb zxid:0x472 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,687] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0xc zxid:0x473 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,688] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:create cxid:0xd zxid:0x474 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:53,953] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:49:54,065] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:49:54,075] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:49:54,111] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:49:54,111] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:49:54,112] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:49:54,173] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:49:54,322] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,335] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2019-12-02 20:49:54,407] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,414] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:54,447] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 103 ms (kafka.log.Log)
[2019-12-02 20:49:54,472] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,473] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-12-02 20:49:54,513] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,513] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:54,592] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,593] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:54,594] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-12-02 20:49:54,634] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,635] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:54,712] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,713] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:54,713] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-12-02 20:49:54,753] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,753] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:49:54,796] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,796] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:54,836] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,836] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:54,878] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,878] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:54,920] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,921] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:54,958] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 78 ms (kafka.log.Log)
[2019-12-02 20:49:54,965] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:54,965] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:49:55,005] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,006] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:55,042] INFO Expiring session 0x10007edbf2f0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:49:55,052] INFO Processed session termination for sessionid: 0x10007edbf2f0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:55,055] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,055] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-12-02 20:49:55,088] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,089] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 20:49:55,168] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,170] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,171] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 80 ms (kafka.log.Log)
[2019-12-02 20:49:55,210] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,211] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:55,254] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,255] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,290] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 78 ms (kafka.log.Log)
[2019-12-02 20:49:55,337] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,338] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,338] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 45 ms (kafka.log.Log)
[2019-12-02 20:49:55,381] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,382] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,383] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:49:55,421] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,422] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:55,465] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,466] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,498] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 75 ms (kafka.log.Log)
[2019-12-02 20:49:55,505] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,506] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:49:55,546] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,547] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:55,625] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,626] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,627] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-12-02 20:49:55,706] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,707] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,708] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-12-02 20:49:55,755] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,756] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,757] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 47 ms (kafka.log.Log)
[2019-12-02 20:49:55,828] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,829] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:55,830] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 72 ms (kafka.log.Log)
[2019-12-02 20:49:55,870] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,870] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:55,910] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,911] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:55,951] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,952] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:55,992] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:55,992] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:56,033] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,034] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:56,073] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,074] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:56,113] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,113] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:56,197] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,198] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:56,231] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 117 ms (kafka.log.Log)
[2019-12-02 20:49:56,238] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,239] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:49:56,279] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,279] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:56,323] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,324] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:56,362] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 81 ms (kafka.log.Log)
[2019-12-02 20:49:56,367] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,367] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:49:56,404] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,405] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:49:56,451] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,451] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:56,452] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 46 ms (kafka.log.Log)
[2019-12-02 20:49:56,490] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,491] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:49:56,530] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,530] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:49:56,571] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,571] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:49:56,612] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,613] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:49:56,653] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,654] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:56,732] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,733] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:56,733] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-12-02 20:49:56,776] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,778] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:56,811] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 77 ms (kafka.log.Log)
[2019-12-02 20:49:56,858] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,859] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:49:56,860] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-12-02 20:49:56,900] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,900] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:49:56,941] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:49:56,941] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:49:56,945] INFO Logs loading complete in 2771 ms. (kafka.log.LogManager)
[2019-12-02 20:49:56,961] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:49:56,962] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:49:57,368] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:49:57,413] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:49:57,414] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:49:57,452] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,453] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,454] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,455] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,478] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:49:57,549] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:49:57,574] INFO Stat of the created znode at /brokers/ids/0 is: 1142,1142,1575348597565,1575348597565,1,0,0,72066320082010112,188,0,1142
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:49:57,574] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1142 (kafka.zk.KafkaZkClient)
[2019-12-02 20:49:57,654] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,660] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,660] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:49:57,695] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:57,697] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:57,704] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:57,732] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:35000,blockEndProducerId:35999) by writing to Zk with path version 36 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:49:57,791] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:49:57,792] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:49:57,793] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:49:57,862] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:49:57,892] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:49:57,927] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:49:57,927] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:49:57,927] INFO Kafka startTimeMs: 1575348597894 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:49:57,983] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:49:58,041] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:49:58,046] INFO Got user-level KeeperException when processing sessionid:0x10007efb0c20000 type:multi cxid:0x72 zxid:0x479 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:49:58,123] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,127] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,148] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,148] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,155] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,155] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,163] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:49:58,163] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,166] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,167] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,170] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,171] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,176] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:49:58,176] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,183] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,183] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,187] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,187] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,193] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,193] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,202] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,203] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,208] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,209] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,217] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,218] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,222] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,222] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,227] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,227] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,233] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,233] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,237] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,237] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,241] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,243] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,247] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,247] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,252] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,252] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,255] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,255] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,259] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,259] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,265] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,266] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,269] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,269] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,273] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,274] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,278] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:49:58,278] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,281] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,282] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,285] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,286] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,289] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,289] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,293] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,293] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,299] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,299] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,302] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,303] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,306] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,306] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,309] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:49:58,309] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,312] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,313] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,317] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,318] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,321] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,322] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,325] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,326] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,336] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,336] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,340] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,340] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,343] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,343] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,345] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,346] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,350] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,350] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,354] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,354] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,356] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,356] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,359] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,359] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,365] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,366] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,368] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,369] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,374] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:49:58,374] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,377] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,377] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,383] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:49:58,384] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,386] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,386] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,389] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:49:58,390] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:49:58,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,419] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,420] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,425] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,512] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 97 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,521] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,523] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,528] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,529] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,534] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,534] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,539] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,540] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,540] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,540] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,540] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,541] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,546] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,546] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,547] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,555] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,556] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,559] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,560] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,570] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,570] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,574] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,574] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,579] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,584] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,589] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,596] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,597] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,598] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,603] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,609] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:49:58,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:49:58,620] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:08,329] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-95060 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-1-5c48cddd-a49f-4010-b8b7-e0a1aff8a3c9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:08,338] INFO [GroupCoordinator 0]: Stabilized group console-consumer-95060 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:08,351] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-95060 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:24,990] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:50:24,992] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:50:24,993] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:50:25,020] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:50:25,026] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:50:25,029] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:50:25,029] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:50:25,030] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:50:25,055] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:50:25,056] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:50:25,060] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:50:25,062] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:50:25,063] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,204] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,204] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,207] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:50:25,208] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 35000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:50:25,209] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:50:25,209] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:50:25,211] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:50:25,211] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:50:25,212] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:50:25,212] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:25,213] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,260] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,260] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,261] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,372] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,372] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,373] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:25,374] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:50:25,374] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:50:25,375] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:50:25,375] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:50:25,376] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:50:25,378] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:50:25,378] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:50:25,379] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:50:25,379] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,403] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,403] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,403] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,416] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,416] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,417] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,623] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,637] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,637] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,787] INFO Unable to read additional data from server sessionid 0x10007efb0c20000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:50:25,813] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,813] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:25,816] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:50:25,817] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:50:25,854] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-12-02 20:50:26,274] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:50:26,290] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:50:26,515] INFO Session: 0x10007efb0c20000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:26,515] INFO EventThread shut down for session: 0x10007efb0c20000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:50:26,518] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:50:26,519] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:27,213] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:27,213] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:27,214] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:28,218] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:28,218] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:28,219] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:29,223] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:29,223] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:29,225] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:50:29,248] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:50:29,252] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:50:47,606] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:50:47,609] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:50:47,609] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:50:47,609] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:50:47,609] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:50:47,625] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:50:47,625] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:50:47,633] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,633] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,634] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,634] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,634] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,634] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,635] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,644] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,644] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,644] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:47,657] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:50:47,676] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:50:52,553] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:50:53,204] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:50:53,205] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:50:53,206] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:50:53,226] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:50:53,232] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,232] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,232] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,233] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,233] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,233] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,234] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,235] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:50:53,251] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:50:53,252] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:50:53,274] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61983 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:50:53,275] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:50:53,341] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61983 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:53,342] INFO Creating new log file: log.47a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:50:53,350] INFO Established session 0x10007f096eb0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61983 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:53,351] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007f096eb0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:50:53,354] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:50:53,409] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x1 zxid:0x47b txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,422] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x2 zxid:0x47c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,424] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x3 zxid:0x47d txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,425] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x4 zxid:0x47e txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,427] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x5 zxid:0x47f txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,430] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x6 zxid:0x480 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,432] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x7 zxid:0x481 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,433] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x8 zxid:0x482 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,434] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0x9 zxid:0x483 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,436] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0xa zxid:0x484 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,437] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0xb zxid:0x485 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,438] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0xc zxid:0x486 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,440] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:create cxid:0xd zxid:0x487 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:53,590] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:50:53,680] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:50:53,690] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:50:53,716] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:53,717] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:53,718] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:50:53,768] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:50:53,863] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:53,874] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-12-02 20:50:53,897] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:53,905] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:53,921] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:53,929] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:53,929] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:50:53,971] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:53,971] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:54,012] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,013] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,014] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-12-02 20:50:54,052] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,053] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:54,094] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,094] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,095] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:54,132] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,132] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:50:54,173] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,173] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,214] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,214] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,255] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,255] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,296] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,296] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,297] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:54,337] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,337] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,376] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,377] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,427] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,427] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-12-02 20:50:54,457] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,457] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-12-02 20:50:54,500] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,501] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,501] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 42 ms (kafka.log.Log)
[2019-12-02 20:50:54,539] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,540] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:54,583] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,584] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,585] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:50:54,623] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,624] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,625] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:54,663] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,664] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,665] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,703] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,704] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:54,746] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,747] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,748] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 43 ms (kafka.log.Log)
[2019-12-02 20:50:54,783] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,783] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:50:54,823] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,824] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:54,866] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,867] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,868] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:50:54,906] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,907] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,907] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:54,953] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,955] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,956] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 47 ms (kafka.log.Log)
[2019-12-02 20:50:54,987] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:54,988] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:54,989] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 32 ms (kafka.log.Log)
[2019-12-02 20:50:55,026] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,026] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:50:55,043] INFO Expiring session 0x10007efb0c20000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:50:55,056] INFO Processed session termination for sessionid: 0x10007efb0c20000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:55,066] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,066] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:55,107] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,107] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:55,148] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,148] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:55,188] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,188] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:55,229] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,229] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:55,270] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,270] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:55,316] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,319] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,320] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 48 ms (kafka.log.Log)
[2019-12-02 20:50:55,358] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,359] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:55,396] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,396] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:50:55,439] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,439] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,440] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:50:55,478] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,478] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:50:55,518] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,518] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:50:55,561] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,561] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,562] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 43 ms (kafka.log.Log)
[2019-12-02 20:50:55,598] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,599] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:50:55,639] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,640] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:55,680] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,680] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:50:55,720] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,721] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:55,763] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,764] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-21/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,800] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-12-02 20:50:55,846] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,846] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,847] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-12-02 20:50:55,890] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,890] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,927] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 79 ms (kafka.log.Log)
[2019-12-02 20:50:55,972] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:55,972] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:50:55,973] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 44 ms (kafka.log.Log)
[2019-12-02 20:50:56,014] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:56,015] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:50:56,055] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:50:56,056] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:50:56,059] INFO Logs loading complete in 2290 ms. (kafka.log.LogManager)
[2019-12-02 20:50:56,073] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:50:56,074] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:50:56,537] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:50:56,563] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:50:56,565] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:50:56,604] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,605] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,606] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,607] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,625] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:50:56,700] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:50:56,720] INFO Stat of the created znode at /brokers/ids/0 is: 1161,1161,1575348656712,1575348656712,1,0,0,72066323943456768,188,0,1161
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:50:56,721] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1161 (kafka.zk.KafkaZkClient)
[2019-12-02 20:50:56,782] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,785] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,786] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:50:56,831] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:56,832] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:56,841] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:56,881] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:36000,blockEndProducerId:36999) by writing to Zk with path version 37 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:50:56,928] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:50:56,930] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:50:56,932] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:50:57,012] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:50:57,034] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0000 type:multi cxid:0x6b zxid:0x48c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:50:57,067] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:50:57,138] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:50:57,142] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:50:57,142] INFO Kafka startTimeMs: 1575348657114 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:50:57,151] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:50:57,193] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:50:57,209] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,214] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,232] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,232] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,239] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,240] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,244] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:50:57,244] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,247] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,247] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,251] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,252] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,259] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:50:57,260] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,263] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,264] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,268] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,269] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,277] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,277] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,282] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,282] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,287] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,287] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,293] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,293] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,298] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,298] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,302] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,302] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,306] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,307] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,312] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,312] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,316] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,316] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,322] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,323] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,327] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,327] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,330] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,331] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,334] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,335] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,338] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,338] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,341] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,341] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,345] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,345] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,350] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:50:57,351] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,356] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,356] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,360] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,360] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,364] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,364] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,374] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 1 (kafka.cluster.Replica)
[2019-12-02 20:50:57,375] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,377] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,378] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,381] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,382] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,385] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,385] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,392] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:50:57,392] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,395] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,395] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,398] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,398] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,404] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,404] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,409] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,409] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,413] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,413] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,417] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,417] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,420] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,421] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,423] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,423] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,426] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,426] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,430] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,431] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,434] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,434] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,440] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,440] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,443] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,444] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,446] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,446] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,450] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:50:57,450] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,453] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,453] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,457] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:50:57,457] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,460] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,461] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,465] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:50:57,465] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:50:57,504] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,509] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,509] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,509] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,510] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,511] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,511] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,586] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 83 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,598] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,599] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,603] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,623] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,625] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,627] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,627] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,628] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,628] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,628] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,633] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,633] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,641] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,642] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,646] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,646] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,647] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,656] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,656] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,656] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,662] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,669] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,669] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,674] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-95060 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,688] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:50:57,689] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,694] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,694] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,694] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,695] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:50:57,700] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:51:07,686] INFO [GroupCoordinator 0]: Member consumer-1-5c48cddd-a49f-4010-b8b7-e0a1aff8a3c9 in group console-consumer-95060 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:07,692] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-95060 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: removing member consumer-1-5c48cddd-a49f-4010-b8b7-e0a1aff8a3c9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:07,697] INFO [GroupCoordinator 0]: Group console-consumer-95060 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:09,226] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-91492 in state PreparingRebalance with old generation 0 (__consumer_offsets-46) (reason: Adding new member consumer-1-1b82cb15-586a-40a4-9fc2-3b16776da26d with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:09,236] INFO [GroupCoordinator 0]: Stabilized group console-consumer-91492 generation 1 (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:09,250] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-91492 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:09,672] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:51:09,674] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:51:09,674] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:51:09,674] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:51:09,675] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:51:09,691] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:51:09,691] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:51:09,714] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,714] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,715] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,715] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,715] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,715] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,717] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,730] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,730] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,730] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:09,745] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:51:09,759] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:51:09,761] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-12-02 20:51:14,634] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:51:15,354] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:51:15,355] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:51:15,357] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:51:15,377] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:15,383] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,383] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,383] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,383] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,383] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,383] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,384] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,386] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,402] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:15,403] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:51:15,420] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62005 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:51:15,424] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:51:15,428] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62005 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:15,429] INFO Established session 0x10007f096eb0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62005 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:51:15,431] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007f096eb0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:51:15,434] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:15,484] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x1 zxid:0x48e txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,495] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x2 zxid:0x48f txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,496] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x3 zxid:0x490 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,498] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x4 zxid:0x491 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,499] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x5 zxid:0x492 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,500] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x6 zxid:0x493 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,501] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x7 zxid:0x494 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,503] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x8 zxid:0x495 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,504] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0x9 zxid:0x496 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,505] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0xa zxid:0x497 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,507] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0xb zxid:0x498 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,508] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0xc zxid:0x499 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,509] INFO Got user-level KeeperException when processing sessionid:0x10007f096eb0001 type:create cxid:0xd zxid:0x49a txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,666] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:51:15,767] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:51:15,776] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:51:15,804] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:15,804] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:15,806] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:15,849] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-02 20:51:15,852] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:51:15,858] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:15,859] INFO Processed session termination for sessionid: 0x10007f096eb0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:51:15,860] INFO Session: 0x10007f096eb0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:15,861] INFO EventThread shut down for session: 0x10007f096eb0001 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:51:15,862] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:15,863] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62005 which had sessionid 0x10007f096eb0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:51:15,864] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:16,805] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:16,805] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:16,805] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:17,807] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:17,807] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:17,808] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:18,809] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:18,809] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:18,819] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:51:18,820] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-02 20:51:18,822] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:51:30,308] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-1633 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-1-da7424d6-cc3f-45e1-a748-386d2347ca53 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:30,310] INFO [GroupCoordinator 0]: Stabilized group console-consumer-1633 generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:30,320] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-1633 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:40,105] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:51:40,106] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:51:40,108] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:51:40,136] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:51:40,141] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:51:40,145] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:51:40,146] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:51:40,147] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:51:40,180] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:51:40,181] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:51:40,184] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:51:40,193] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:51:40,194] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,277] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,277] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,280] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:51:40,281] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 36000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:51:40,282] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:51:40,282] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:51:40,283] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:51:40,283] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:51:40,283] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:51:40,284] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:40,285] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,296] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,296] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,297] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,436] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,438] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,440] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:51:40,441] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:51:40,442] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:51:40,452] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:51:40,453] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:51:40,457] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:51:40,461] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:51:40,462] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:51:40,462] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:51:40,462] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,472] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,474] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,475] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,503] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,505] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,505] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,683] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,683] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,685] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,707] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,707] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:51:40,710] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:51:40,711] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:51:41,019] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:51:41,125] INFO Unable to read additional data from server sessionid 0x10007f096eb0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:51:41,239] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-12-02 20:51:41,657] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-12-02 20:51:41,793] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:51:41,804] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:42,207] INFO Session: 0x10007f096eb0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:51:42,207] INFO EventThread shut down for session: 0x10007f096eb0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:51:42,208] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:51:42,209] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:42,826] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:42,826] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:42,827] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:43,830] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:43,830] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:43,830] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:43,844] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:43,844] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:51:43,846] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:51:43,867] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:51:43,870] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:52:10,122] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:52:10,126] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:52:10,126] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:52:10,126] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:52:10,126] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:52:10,145] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:52:10,145] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:52:10,153] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,153] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,153] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,153] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,153] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,154] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,155] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,164] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,164] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,164] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:10,179] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:52:10,192] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:52:15,237] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:52:15,882] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:52:15,883] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:52:15,884] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:52:15,903] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:52:15,909] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,909] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,909] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,909] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,909] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,909] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,910] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,910] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,910] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,910] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,910] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,911] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,911] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,911] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,911] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,912] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:52:15,929] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:52:15,931] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:52:15,950] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:52:15,950] INFO Accepted socket connection from /127.0.0.1:62086 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:52:16,016] INFO Client attempting to establish new session at /127.0.0.1:62086 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:16,017] INFO Creating new log file: log.49c (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:52:16,029] INFO Established session 0x10007f1d94a0000 with negotiated timeout 6000 for client /127.0.0.1:62086 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:16,031] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007f1d94a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:52:16,037] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:52:16,106] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x1 zxid:0x49d txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,117] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x2 zxid:0x49e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,118] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x3 zxid:0x49f txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,119] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x4 zxid:0x4a0 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,121] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x5 zxid:0x4a1 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,124] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x6 zxid:0x4a2 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,126] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x7 zxid:0x4a3 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,127] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x8 zxid:0x4a4 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,128] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0x9 zxid:0x4a5 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,130] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0xa zxid:0x4a6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,131] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0xb zxid:0x4a7 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,132] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0xc zxid:0x4a8 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,133] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:create cxid:0xd zxid:0x4a9 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:16,286] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:52:16,374] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:52:16,384] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:52:16,408] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:52:16,408] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:52:16,412] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:52:16,466] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:52:16,561] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:16,571] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-12-02 20:52:16,595] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:16,604] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:16,620] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:52:16,628] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:16,629] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-02 20:52:16,670] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:16,670] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:16,712] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:16,713] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:16,714] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-12-02 20:52:16,962] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:16,962] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 245 ms (kafka.log.Log)
[2019-12-02 20:52:17,004] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,005] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,005] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:17,058] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,059] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:52:17,110] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,111] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-12-02 20:52:17,120] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,120] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:52:17,164] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,164] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:52:17,204] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,205] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,206] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:17,243] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,244] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:52:17,283] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,284] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:52:17,323] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,324] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:52:17,367] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,368] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-12-02 20:52:17,408] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,410] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,411] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 42 ms (kafka.log.Log)
[2019-12-02 20:52:17,446] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,447] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:52:17,491] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,492] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,495] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-12-02 20:52:17,529] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,530] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,530] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 33 ms (kafka.log.Log)
[2019-12-02 20:52:17,569] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,570] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,571] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:17,610] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,611] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:17,651] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,652] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,653] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 41 ms (kafka.log.Log)
[2019-12-02 20:52:17,689] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,689] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:52:17,729] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,730] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:17,772] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,773] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,774] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2019-12-02 20:52:17,811] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,812] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,813] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 35 ms (kafka.log.Log)
[2019-12-02 20:52:17,858] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,859] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,860] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 45 ms (kafka.log.Log)
[2019-12-02 20:52:17,891] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,892] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:17,893] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 30 ms (kafka.log.Log)
[2019-12-02 20:52:17,930] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,931] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:52:17,971] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:17,971] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:18,012] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,012] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:18,052] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,053] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:18,093] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,093] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:18,136] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,137] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-2/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,138] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 43 ms (kafka.log.Log)
[2019-12-02 20:52:18,176] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,177] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:52:18,223] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,224] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,225] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 47 ms (kafka.log.Log)
[2019-12-02 20:52:18,257] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,258] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-12-02 20:52:18,299] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,299] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:18,341] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,342] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,342] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:52:18,379] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,379] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:52:18,419] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,420] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:18,461] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,462] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,462] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 41 ms (kafka.log.Log)
[2019-12-02 20:52:18,500] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,500] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:52:18,540] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,540] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:18,580] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,581] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:18,621] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,622] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:18,665] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,665] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-21/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,666] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:52:18,705] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,706] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,707] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:18,747] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,747] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,748] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 40 ms (kafka.log.Log)
[2019-12-02 20:52:18,787] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,788] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:52:18,788] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:52:18,826] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,826] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:52:18,868] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:52:18,869] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:52:18,872] INFO Logs loading complete in 2406 ms. (kafka.log.LogManager)
[2019-12-02 20:52:18,888] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:52:18,889] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:52:19,047] INFO Expiring session 0x10007f096eb0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:52:19,048] INFO Processed session termination for sessionid: 0x10007f096eb0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:19,207] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:52:19,238] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:52:19,239] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:52:19,274] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,276] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,277] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,277] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,294] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:52:19,365] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:52:19,388] INFO Stat of the created znode at /brokers/ids/0 is: 1195,1195,1575348739379,1575348739379,1,0,0,72066329351946240,188,0,1195
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:52:19,389] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1195 (kafka.zk.KafkaZkClient)
[2019-12-02 20:52:19,453] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,455] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,457] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:52:19,492] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:19,496] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:19,502] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:19,518] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:37000,blockEndProducerId:37999) by writing to Zk with path version 38 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:52:19,558] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:52:19,561] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:52:19,565] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:52:19,626] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:52:19,656] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:52:19,668] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:52:19,668] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:52:19,668] INFO Kafka startTimeMs: 1575348739657 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:52:19,671] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:52:19,808] INFO Got user-level KeeperException when processing sessionid:0x10007f1d94a0000 type:multi cxid:0x6f zxid:0x4ae txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:52:19,812] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:52:19,870] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:19,873] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,897] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,898] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,905] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:19,905] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,913] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:52:19,913] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,916] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:19,917] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,920] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,921] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,925] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:52:19,925] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,933] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:19,933] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,936] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,937] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,941] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,941] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,950] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,951] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,955] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,955] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,959] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,959] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,966] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,966] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,971] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,971] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,975] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,975] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,979] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:19,980] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,983] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,983] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:19,991] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:19,995] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,001] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,002] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,005] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,005] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,012] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:20,012] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,015] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,016] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,019] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,019] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,024] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,025] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,032] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:52:20,033] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,037] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,038] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,042] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,043] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,052] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,052] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,056] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:20,057] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,065] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-12-02 20:52:20,065] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,069] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,070] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,075] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,076] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,083] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:52:20,083] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,086] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,086] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,090] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,091] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,094] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,094] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,098] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,099] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,102] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,102] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,106] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,106] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,111] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,112] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,115] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,115] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,119] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,119] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,123] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:20,123] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,127] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,128] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,133] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,134] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,138] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,138] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,141] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,141] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,148] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:52:20,148] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,153] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,153] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,156] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:52:20,156] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,158] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,159] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,163] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:52:20,164] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:52:20,192] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,197] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,200] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,202] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,280] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,281] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 88 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,286] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,286] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,287] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,287] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,287] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,291] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,291] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,295] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-91492 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,304] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,304] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,309] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,309] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,310] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,310] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,310] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,311] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,315] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,315] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,316] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,331] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,331] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,336] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-1633 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,338] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,338] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,339] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,339] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,339] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,345] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,346] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,351] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,351] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,357] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,357] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,357] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,384] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,384] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,385] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,389] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,389] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,391] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,391] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,404] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,405] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,415] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-95060 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,416] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,416] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,416] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,429] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:20,429] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,430] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,443] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,444] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,445] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,445] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:20,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:52:30,307] INFO [GroupCoordinator 0]: Member consumer-1-1b82cb15-586a-40a4-9fc2-3b16776da26d in group console-consumer-91492 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:30,312] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-91492 in state PreparingRebalance with old generation 1 (__consumer_offsets-46) (reason: removing member consumer-1-1b82cb15-586a-40a4-9fc2-3b16776da26d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:30,317] INFO [GroupCoordinator 0]: Group console-consumer-91492 with generation 2 is now empty (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:30,393] INFO [GroupCoordinator 0]: Member consumer-1-da7424d6-cc3f-45e1-a748-386d2347ca53 in group console-consumer-1633 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:30,393] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-1633 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member consumer-1-da7424d6-cc3f-45e1-a748-386d2347ca53 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:30,394] INFO [GroupCoordinator 0]: Group console-consumer-1633 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:31,528] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-96775 in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-1-a55e78b5-72e9-4a47-a7eb-28402bf99afd with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:31,531] INFO [GroupCoordinator 0]: Stabilized group console-consumer-96775 generation 1 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:52:31,542] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-96775 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:53:32,108] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:53:32,110] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:53:32,112] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:53:32,142] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:53:32,147] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:53:32,148] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:53:32,148] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:53:32,149] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:53:32,164] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:53:32,165] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:53:32,168] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:53:32,171] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:53:32,172] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,255] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,255] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,258] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:53:32,259] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 37000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:53:32,259] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:53:32,260] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:53:32,260] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:53:32,260] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:53:32,261] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:53:32,262] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:53:32,262] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,310] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,310] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,311] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,362] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,362] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,363] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:53:32,364] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:53:32,365] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:53:32,365] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:53:32,365] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:53:32,366] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:53:32,368] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:53:32,369] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:53:32,369] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:53:32,369] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,448] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,448] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,448] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,455] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,455] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,456] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,631] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,631] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,631] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,656] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,656] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:53:32,662] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:53:32,663] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:53:32,908] INFO Unable to read additional data from server sessionid 0x10007f1d94a0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:53:32,927] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-12-02 20:53:32,933] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-12-02 20:53:33,269] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:53:33,363] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:53:33,377] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:53:33,872] INFO Session: 0x10007f1d94a0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:53:33,872] INFO EventThread shut down for session: 0x10007f1d94a0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:53:33,874] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:53:33,875] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:34,613] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:34,613] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:34,614] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:35,615] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:35,616] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:35,616] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:36,616] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:36,616] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:53:36,619] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:53:36,668] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:53:36,676] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:53:56,755] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:53:56,757] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:53:56,758] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:53:56,758] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:53:56,758] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:53:56,774] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:53:56,774] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:53:56,800] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,800] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,800] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,800] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,801] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,801] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,802] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,803] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,803] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,804] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,804] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,804] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,804] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,805] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,805] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,813] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,813] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,813] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:53:56,825] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:53:56,839] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:54:01,430] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:54:02,071] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:54:02,072] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:54:02,073] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:54:02,094] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:54:02,100] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,100] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,101] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,101] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,101] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,101] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,102] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,102] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,102] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,103] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,103] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,103] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,103] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,103] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,103] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,104] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:02,120] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:54:02,121] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:54:02,147] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62182 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:54:02,147] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:54:02,209] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62182 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:54:02,210] INFO Creating new log file: log.4af (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:54:02,218] INFO Established session 0x10007f379da0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62182 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:54:02,220] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007f379da0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:54:02,224] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:54:02,280] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x1 zxid:0x4b0 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,295] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x2 zxid:0x4b1 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,297] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x3 zxid:0x4b2 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,298] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x4 zxid:0x4b3 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,299] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x5 zxid:0x4b4 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,303] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x6 zxid:0x4b5 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,305] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x7 zxid:0x4b6 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,306] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x8 zxid:0x4b7 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,308] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0x9 zxid:0x4b8 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,309] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0xa zxid:0x4b9 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,310] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0xb zxid:0x4ba txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,312] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0xc zxid:0x4bb txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,313] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:create cxid:0xd zxid:0x4bc txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:02,469] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:54:02,557] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:54:02,569] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:54:02,596] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:02,596] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:02,598] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:02,657] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:54:02,748] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:02,759] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-12-02 20:54:02,789] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:02,795] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:02,811] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 44 ms (kafka.log.Log)
[2019-12-02 20:54:02,831] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:02,832] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-12-02 20:54:02,874] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:02,875] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:54:02,917] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:02,918] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:02,919] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:54:02,958] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:02,959] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:02,999] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,000] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,001] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:03,037] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,037] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:54:03,077] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,078] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:03,117] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,117] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:54:03,159] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,159] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:54:03,200] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,200] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,201] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 40 ms (kafka.log.Log)
[2019-12-02 20:54:03,239] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,240] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:54:03,280] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,281] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:03,319] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,320] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:03,360] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,361] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:03,402] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,403] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,404] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 41 ms (kafka.log.Log)
[2019-12-02 20:54:03,441] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,441] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:54:03,486] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,487] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,488] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 45 ms (kafka.log.Log)
[2019-12-02 20:54:03,525] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,526] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,527] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:03,563] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,563] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,564] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 34 ms (kafka.log.Log)
[2019-12-02 20:54:03,603] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,604] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:03,648] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,650] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,651] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 46 ms (kafka.log.Log)
[2019-12-02 20:54:03,684] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,685] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-12-02 20:54:03,725] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,726] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:03,767] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,768] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,769] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-12-02 20:54:03,808] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,808] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,809] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:03,852] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,852] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,853] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 42 ms (kafka.log.Log)
[2019-12-02 20:54:03,889] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,890] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:03,891] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 37 ms (kafka.log.Log)
[2019-12-02 20:54:03,928] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,929] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:54:03,969] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:03,969] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:04,010] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,010] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:54:04,049] INFO Expiring session 0x10007f1d94a0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:54:04,050] INFO Processed session termination for sessionid: 0x10007f1d94a0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:04,052] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,053] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:54:04,091] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,092] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:04,132] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,133] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-2/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,134] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:54:04,172] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,172] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:54:04,219] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,220] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,222] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 48 ms (kafka.log.Log)
[2019-12-02 20:54:04,253] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,253] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-12-02 20:54:04,299] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,299] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-12-02 20:54:04,336] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,337] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,338] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 37 ms (kafka.log.Log)
[2019-12-02 20:54:04,375] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,376] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:54:04,416] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,417] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:54:04,458] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,459] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,460] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 42 ms (kafka.log.Log)
[2019-12-02 20:54:04,496] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,496] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:54:04,536] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,537] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:04,576] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,577] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:04,618] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,618] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:04,661] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,661] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-21/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,695] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 75 ms (kafka.log.Log)
[2019-12-02 20:54:04,703] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,704] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,705] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-12-02 20:54:04,744] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,744] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,745] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:54:04,787] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,788] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:54:04,790] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 44 ms (kafka.log.Log)
[2019-12-02 20:54:04,825] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,825] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:54:04,865] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:54:04,865] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:54:04,869] INFO Logs loading complete in 2212 ms. (kafka.log.LogManager)
[2019-12-02 20:54:04,880] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:54:04,881] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:54:05,168] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:54:05,197] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:54:05,199] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:54:05,233] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,235] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,235] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,236] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,255] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:54:05,322] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:54:05,345] INFO Stat of the created znode at /brokers/ids/0 is: 1214,1214,1575348845335,1575348845335,1,0,0,72066336340705280,188,0,1214
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:54:05,346] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1214 (kafka.zk.KafkaZkClient)
[2019-12-02 20:54:05,410] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,411] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,414] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:05,446] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:05,450] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:05,461] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:05,471] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:38000,blockEndProducerId:38999) by writing to Zk with path version 39 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:54:05,534] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:54:05,537] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:54:05,537] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:54:05,608] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:54:05,634] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:54:05,644] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:54:05,653] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:54:05,675] INFO Kafka startTimeMs: 1575348845636 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:54:05,719] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:54:05,763] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:54:05,780] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:05,784] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,784] INFO Got user-level KeeperException when processing sessionid:0x10007f379da0000 type:multi cxid:0x70 zxid:0x4c1 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:54:05,811] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,811] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,816] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:05,817] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,830] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:54:05,831] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,834] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:05,854] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,861] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,861] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,865] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:54:05,865] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,869] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:05,869] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,872] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,872] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,877] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,877] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,881] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,882] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,885] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,885] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,889] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,889] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,894] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,894] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,898] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,899] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,902] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,902] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,909] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:05,910] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,912] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,913] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,915] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,916] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,919] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:05,919] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,921] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,922] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,925] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:05,925] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,928] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 4 (kafka.cluster.Replica)
[2019-12-02 20:54:05,928] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,931] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,932] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,935] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,936] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,941] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:54:05,942] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,946] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,946] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,951] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,952] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,957] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,957] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,961] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:05,961] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,966] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:05,966] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,972] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:05,973] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,978] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,978] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,981] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:54:05,982] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,986] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,986] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,991] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,991] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,995] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:05,995] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:05,999] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,000] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,005] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,005] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,009] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,009] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,012] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:06,013] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,015] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,015] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,018] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,018] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,023] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:06,024] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,028] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:06,028] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,030] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,030] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,033] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 4 (kafka.cluster.Replica)
[2019-12-02 20:54:06,033] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,036] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,036] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,040] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:54:06,040] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,043] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,043] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,047] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:54:06,047] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,049] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,050] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,052] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:54:06,052] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:54:06,067] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,070] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,079] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,079] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,079] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,079] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,101] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,101] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,104] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,104] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,105] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,162] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,172] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 103 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,178] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-96775 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,189] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,190] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,190] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,190] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,191] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,194] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,195] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,199] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-91492 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,199] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,199] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,204] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,204] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,210] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,214] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,214] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,218] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-1633 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,226] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,231] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,231] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,234] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,235] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,244] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,244] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,244] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,249] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,249] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,254] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,261] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-95060 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,261] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,262] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,262] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,266] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:06,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:06,284] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:54:16,194] INFO [GroupCoordinator 0]: Member consumer-1-a55e78b5-72e9-4a47-a7eb-28402bf99afd in group console-consumer-96775 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:16,198] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-96775 in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: removing member consumer-1-a55e78b5-72e9-4a47-a7eb-28402bf99afd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:16,202] INFO [GroupCoordinator 0]: Group console-consumer-96775 with generation 2 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:17,640] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-42915 in state PreparingRebalance with old generation 0 (__consumer_offsets-42) (reason: Adding new member consumer-1-c49c16f2-47d0-4585-85d4-1d510f092dd7 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:17,644] INFO [GroupCoordinator 0]: Stabilized group console-consumer-42915 generation 1 (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:17,656] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-42915 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:36,534] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:54:36,535] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:54:36,537] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:54:36,558] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:54:36,564] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:54:36,565] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:54:36,566] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:54:36,567] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:54:36,583] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:54:36,585] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:54:36,587] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:54:36,590] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:54:36,591] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:36,784] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:36,784] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:36,788] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:54:36,789] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 38000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:54:36,790] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:54:36,790] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:54:36,791] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:54:36,791] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:54:36,792] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:54:36,793] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:36,794] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:36,897] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:36,897] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:36,897] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,100] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,100] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,101] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:54:37,101] INFO Unable to read additional data from server sessionid 0x10007f379da0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:54:37,102] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:54:37,102] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:54:37,102] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:54:37,102] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:54:37,103] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:54:37,105] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:54:37,106] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:54:37,107] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:54:37,107] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,165] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,165] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,166] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,229] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,230] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,230] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,248] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,250] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,250] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,453] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,453] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:54:37,456] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:54:37,457] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:54:37,601] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-12-02 20:54:37,636] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-12-02 20:54:38,037] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:54:38,072] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:54:38,825] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:54:38,931] INFO Session: 0x10007f379da0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:54:38,931] INFO EventThread shut down for session: 0x10007f379da0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:54:38,933] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:54:38,933] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:39,694] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:39,694] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:39,694] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:40,694] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:40,694] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:40,695] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:41,695] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:41,695] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:54:41,698] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:54:41,720] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:54:41,725] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:55:00,859] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:55:00,861] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:55:00,861] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:55:00,861] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:55:00,862] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:55:00,876] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:55:00,876] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:55:00,884] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,884] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,884] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,884] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,884] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,885] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,886] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,893] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,893] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,893] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:00,907] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:55:00,924] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:55:05,887] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:55:06,605] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:55:06,606] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:55:06,607] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:55:06,627] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:06,633] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,633] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,633] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,633] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,633] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,633] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,634] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,634] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,635] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,636] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:06,652] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:06,653] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:06,673] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:06,673] INFO Accepted socket connection from /127.0.0.1:62261 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:55:06,728] INFO Client attempting to establish new session at /127.0.0.1:62261 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:06,729] INFO Creating new log file: log.4c2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:55:06,737] INFO Established session 0x10007f4742b0000 with negotiated timeout 6000 for client /127.0.0.1:62261 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:06,738] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007f4742b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:06,742] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:06,805] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x1 zxid:0x4c3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,824] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x2 zxid:0x4c4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,827] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x3 zxid:0x4c5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,831] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x4 zxid:0x4c6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,835] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x5 zxid:0x4c7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,838] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x6 zxid:0x4c8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,840] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x7 zxid:0x4c9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,842] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x8 zxid:0x4ca txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,843] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0x9 zxid:0x4cb txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,845] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0xa zxid:0x4cc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,846] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0xb zxid:0x4cd txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,848] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0xc zxid:0x4ce txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,849] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:create cxid:0xd zxid:0x4cf txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:06,995] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:55:07,096] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:55:07,109] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:55:07,142] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:07,142] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:07,143] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:07,185] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:55:07,272] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,282] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-12-02 20:55:07,317] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,326] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:07,339] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 44 ms (kafka.log.Log)
[2019-12-02 20:55:07,347] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,347] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-02 20:55:07,390] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,390] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:07,433] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,434] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:07,435] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:55:07,474] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,474] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:07,514] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,515] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:07,516] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:07,552] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,553] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:55:07,592] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,593] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:07,631] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,631] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:55:07,675] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,676] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:07,713] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,714] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:07,715] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:07,753] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,754] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:07,793] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,793] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:07,838] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,838] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:55:07,872] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,872] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 20:55:07,914] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,915] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:07,916] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 42 ms (kafka.log.Log)
[2019-12-02 20:55:07,953] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,954] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:07,996] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:07,997] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,030] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 74 ms (kafka.log.Log)
[2019-12-02 20:55:08,042] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,042] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,043] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 10 ms (kafka.log.Log)
[2019-12-02 20:55:08,081] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,082] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,082] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:08,121] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,121] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:08,163] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,165] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,166] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 43 ms (kafka.log.Log)
[2019-12-02 20:55:08,216] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,218] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-12-02 20:55:08,269] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,270] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-12-02 20:55:08,406] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,407] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,408] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 136 ms (kafka.log.Log)
[2019-12-02 20:55:08,467] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,468] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,470] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 54 ms (kafka.log.Log)
[2019-12-02 20:55:08,519] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,521] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,522] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 50 ms (kafka.log.Log)
[2019-12-02 20:55:08,553] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,555] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,564] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:08,589] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,590] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-12-02 20:55:08,633] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,635] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-12-02 20:55:08,667] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,685] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:55:08,753] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,754] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-12-02 20:55:08,833] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,834] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-12-02 20:55:08,876] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,877] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-2/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,915] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 80 ms (kafka.log.Log)
[2019-12-02 20:55:08,921] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,921] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-02 20:55:08,970] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:08,971] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:08,972] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 49 ms (kafka.log.Log)
[2019-12-02 20:55:09,011] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,012] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:09,058] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,060] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,062] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 49 ms (kafka.log.Log)
[2019-12-02 20:55:09,101] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,102] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,102] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:09,142] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,142] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:09,180] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,180] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:09,223] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,223] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,224] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 42 ms (kafka.log.Log)
[2019-12-02 20:55:09,261] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,261] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-12-02 20:55:09,300] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,301] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:09,342] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,343] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2019-12-02 20:55:09,382] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,383] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:09,426] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,426] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-21/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,427] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:55:09,466] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,467] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,468] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:09,506] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,506] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,507] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:09,546] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,547] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:09,548] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:09,585] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,585] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:09,627] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:09,627] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:09,630] INFO Logs loading complete in 2444 ms. (kafka.log.LogManager)
[2019-12-02 20:55:09,644] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:55:09,646] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:55:09,944] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:55:09,973] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:55:09,975] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:55:10,010] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,011] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,012] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,015] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,031] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:55:10,052] INFO Expiring session 0x10007f379da0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:10,052] INFO Processed session termination for sessionid: 0x10007f379da0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:10,112] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:55:10,132] INFO Stat of the created znode at /brokers/ids/0 is: 1233,1233,1575348910124,1575348910124,1,0,0,72066340540317696,188,0,1233
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:55:10,133] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1233 (kafka.zk.KafkaZkClient)
[2019-12-02 20:55:10,203] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,206] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,206] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:10,239] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:10,240] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:10,249] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:10,263] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:39000,blockEndProducerId:39999) by writing to Zk with path version 40 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:55:10,322] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:55:10,326] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:55:10,328] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:55:10,472] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:55:10,615] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:55:10,690] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:55:10,690] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:55:10,690] INFO Kafka startTimeMs: 1575348910618 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:55:10,699] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:55:10,785] INFO Got user-level KeeperException when processing sessionid:0x10007f4742b0000 type:multi cxid:0x72 zxid:0x4d4 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:10,861] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:55:10,876] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:10,882] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,901] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:10,902] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,913] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:10,913] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,917] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:55:10,917] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,921] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:10,922] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,930] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:10,930] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,934] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:55:10,934] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,938] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:10,940] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,948] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:10,948] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,954] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 1 (kafka.cluster.Replica)
[2019-12-02 20:55:10,954] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:10,957] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:10,957] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,019] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,019] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,045] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,045] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,057] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,058] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,083] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,084] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,093] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,094] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,100] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:11,103] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,107] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,107] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,112] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,112] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,116] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:11,116] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,122] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,122] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,126] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:11,126] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,130] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 4 (kafka.cluster.Replica)
[2019-12-02 20:55:11,131] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,135] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,135] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,139] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,140] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,145] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:55:11,146] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,149] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,150] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,155] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,155] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,159] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,159] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,165] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:11,165] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,170] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:11,171] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,174] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:11,174] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,178] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,179] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,182] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:55:11,182] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,186] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,187] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,195] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,195] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,200] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,201] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,205] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,205] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,210] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,210] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,214] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,215] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,222] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:11,222] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,225] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,226] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,233] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,234] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,238] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:11,238] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,243] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:11,243] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,248] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,248] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,270] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:55:11,271] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,275] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,276] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,279] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:55:11,280] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,283] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,283] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,289] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:55:11,289] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,292] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,292] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,295] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:55:11,296] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:55:11,348] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,352] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,352] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,352] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,352] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,352] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,353] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,406] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,406] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,406] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,407] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,463] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,478] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 126 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,490] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-96775 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,491] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,491] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,491] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,492] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,492] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,498] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,498] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,507] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-91492 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,507] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,508] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,530] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 22 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,531] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,531] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,532] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,533] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,533] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,543] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,544] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,544] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,550] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,552] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,557] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-1633 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,559] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,560] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,565] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,566] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,572] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,572] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,589] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,613] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,620] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,631] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,631] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,647] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-95060 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,648] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,648] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,648] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,653] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,653] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,653] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,658] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,659] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,667] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-42915 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:11,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 23 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,683] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:11,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:55:21,676] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-84461 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-1-e21c0aca-1b44-4115-a501-cefed9f5cc58 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:21,683] INFO [GroupCoordinator 0]: Stabilized group console-consumer-84461 generation 1 (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:21,685] INFO [GroupCoordinator 0]: Member consumer-1-c49c16f2-47d0-4585-85d4-1d510f092dd7 in group console-consumer-42915 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:21,686] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-42915 in state PreparingRebalance with old generation 1 (__consumer_offsets-42) (reason: removing member consumer-1-c49c16f2-47d0-4585-85d4-1d510f092dd7 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:21,687] INFO [GroupCoordinator 0]: Group console-consumer-42915 with generation 2 is now empty (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:21,699] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-84461 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:39,782] INFO [GroupCoordinator 0]: Member consumer-1-e21c0aca-1b44-4115-a501-cefed9f5cc58 in group console-consumer-84461 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:39,782] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-84461 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: removing member consumer-1-e21c0aca-1b44-4115-a501-cefed9f5cc58 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:39,782] INFO [GroupCoordinator 0]: Group console-consumer-84461 with generation 2 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:39,829] INFO Unable to read additional data from server sessionid 0x10007f4742b0000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:39,972] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:55:39,974] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:55:39,975] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:55:41,804] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:41,805] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:41,913] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:43,026] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:43,027] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:44,438] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:44,439] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:45,766] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:45,767] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:47,016] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:47,016] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:48,579] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:48,579] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:49,729] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:49,729] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:51,009] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:55:51,014] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:55:51,014] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:55:51,014] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:55:51,014] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:55:51,036] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:55:51,037] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:55:51,061] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:51,061] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:51,073] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,073] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,073] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,073] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,073] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,073] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,075] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,075] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,075] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,075] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,076] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,076] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,076] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,076] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,076] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,084] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,084] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,084] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:51,097] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:55:51,110] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:55:52,787] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:52,788] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:52,793] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62299 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:55:52,846] INFO Client attempting to renew session 0x10007f4742b0000 at /0:0:0:0:0:0:0:1:62299 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:52,849] INFO Established session 0x10007f4742b0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62299 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:52,849] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007f4742b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:52,850] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:52,868] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:55:52,874] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:55:52,876] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:55:52,876] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:55:52,876] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:55:52,894] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:55:52,901] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:55:52,904] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:55:52,907] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:55:52,908] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,002] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,002] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,005] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:55:53,007] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 39000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:55:53,007] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:55:53,007] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:55:53,008] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:55:53,008] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:55:53,008] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:55:53,009] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:53,009] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,157] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,158] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,158] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,284] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,284] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,285] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:55:53,286] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:55:53,286] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:55:53,287] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:55:53,287] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:55:53,287] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:55:53,289] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:55:53,289] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:55:53,290] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:55:53,290] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,411] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,411] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,412] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,616] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,616] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,617] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,821] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,822] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:53,822] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:54,027] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:54,027] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:55:54,031] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:55:54,032] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:55:54,182] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:55:54,359] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-12-02 20:55:54,466] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:55:54,481] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:54,506] INFO Processed session termination for sessionid: 0x10007f4742b0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:54,506] INFO Creating new log file: log.4d5 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:55:54,515] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62299 which had sessionid 0x10007f4742b0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-02 20:55:54,515] INFO Session: 0x10007f4742b0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:54,516] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:54,517] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:54,517] INFO EventThread shut down for session: 0x10007f4742b0000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:55,235] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:55,235] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:55,236] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:56,216] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:55:56,237] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:56,237] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:56,238] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:57,151] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:55:57,152] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:55:57,153] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:55:57,172] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:57,178] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,179] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,179] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,179] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,179] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,179] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,180] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,181] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,182] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:55:57,199] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:57,200] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:57,221] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62316 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:55:57,224] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:57,228] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62316 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:57,229] INFO Established session 0x10007f538300000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62316 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:55:57,231] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10007f538300000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:55:57,234] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:55:57,238] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:57,238] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:57,239] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:55:57,313] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:55:57,318] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:55:57,330] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x1 zxid:0x4d7 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,343] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x2 zxid:0x4d8 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,344] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x3 zxid:0x4d9 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,345] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x4 zxid:0x4da txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,347] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x5 zxid:0x4db txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,348] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x6 zxid:0x4dc txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,349] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x7 zxid:0x4dd txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,351] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x8 zxid:0x4de txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,352] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0x9 zxid:0x4df txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,353] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0xa zxid:0x4e0 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,355] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0xb zxid:0x4e1 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,356] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0xc zxid:0x4e2 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,358] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:create cxid:0xd zxid:0x4e3 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:55:57,512] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:55:57,602] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:55:57,612] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:55:57,638] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:57,638] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:57,640] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:55:57,701] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:55:57,805] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:57,815] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-12-02 20:55:57,864] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:57,871] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:57,883] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 60 ms (kafka.log.Log)
[2019-12-02 20:55:57,893] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:57,893] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:55:57,935] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:57,935] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:57,976] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:57,977] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:57,978] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-12-02 20:55:58,018] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,019] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:58,058] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,058] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,059] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:58,096] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,096] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:55:58,138] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,138] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:58,177] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,178] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:58,220] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,220] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:58,261] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,262] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,263] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:58,300] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,300] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:55:58,339] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,340] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:58,379] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,379] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:58,420] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,420] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:58,462] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,463] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,464] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 41 ms (kafka.log.Log)
[2019-12-02 20:55:58,501] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,501] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:58,545] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,546] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,549] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 46 ms (kafka.log.Log)
[2019-12-02 20:55:58,587] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,588] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,620] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 69 ms (kafka.log.Log)
[2019-12-02 20:55:58,631] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,631] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,632] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 8 ms (kafka.log.Log)
[2019-12-02 20:55:58,671] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,671] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:58,714] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,715] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000026.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,716] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26 in 43 ms (kafka.log.Log)
[2019-12-02 20:55:58,752] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,753] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:55:58,793] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,793] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:58,836] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,836] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,837] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:55:58,875] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,876] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,877] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:58,918] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,919] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,920] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 42 ms (kafka.log.Log)
[2019-12-02 20:55:58,958] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,959] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:58,960] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:58,997] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:58,997] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:55:59,040] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,041] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-4/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,042] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:55:59,080] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,080] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:59,130] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,130] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:55:59,179] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,179] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-12-02 20:55:59,191] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,191] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-2/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,192] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 11 ms (kafka.log.Log)
[2019-12-02 20:55:59,229] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,229] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:55:59,277] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 722 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,278] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000722.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,279] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 722 in 48 ms (kafka.log.Log)
[2019-12-02 20:55:59,309] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,309] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-12-02 20:55:59,352] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,353] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,354] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 44 ms (kafka.log.Log)
[2019-12-02 20:55:59,395] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,396] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,397] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:55:59,435] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,435] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:59,475] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,475] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:59,518] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,519] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,520] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 43 ms (kafka.log.Log)
[2019-12-02 20:55:59,557] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,557] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:55:59,597] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,597] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:59,638] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,639] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:59,678] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,679] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:59,719] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,720] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-21/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,721] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 41 ms (kafka.log.Log)
[2019-12-02 20:55:59,760] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,761] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,762] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:59,800] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,800] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,801] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 38 ms (kafka.log.Log)
[2019-12-02 20:55:59,841] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,841] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:55:59,842] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:55:59,880] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,880] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:55:59,919] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:55:59,920] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:55:59,923] INFO Logs loading complete in 2222 ms. (kafka.log.LogManager)
[2019-12-02 20:55:59,934] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:55:59,935] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:56:00,242] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:56:00,272] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:56:00,274] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:56:00,308] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,309] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,310] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,312] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,329] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:56:00,399] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:56:00,421] INFO Stat of the created znode at /brokers/ids/0 is: 1252,1252,1575348960413,1575348960413,1,0,0,72066343828979712,188,0,1252
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:56:00,422] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1252 (kafka.zk.KafkaZkClient)
[2019-12-02 20:56:00,482] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,485] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,487] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:56:00,522] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:00,524] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:00,530] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:00,550] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:40000,blockEndProducerId:40999) by writing to Zk with path version 41 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:56:00,588] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:56:00,593] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:56:00,595] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:56:00,686] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:56:00,724] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:56:00,734] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:56:00,734] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:56:00,735] INFO Kafka startTimeMs: 1575348960725 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:56:00,743] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:56:00,842] INFO Got user-level KeeperException when processing sessionid:0x10007f538300000 type:multi cxid:0x6f zxid:0x4e7 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:56:00,851] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:56:00,867] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:00,870] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,894] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,895] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,901] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:00,901] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,905] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:56:00,905] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,913] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:00,913] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,917] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,917] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,922] INFO Replica loaded for partition interactions-0 with initial high watermark 26 (kafka.cluster.Replica)
[2019-12-02 20:56:00,923] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 26. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,926] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:00,926] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,929] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,930] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,935] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:00,936] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,939] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:00,940] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,943] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,943] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,947] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,947] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,951] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,951] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,959] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,960] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,964] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,964] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,968] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:00,968] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,972] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,973] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,979] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,979] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,983] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:00,983] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,987] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:00,987] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,995] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:00,995] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:00,997] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 4 (kafka.cluster.Replica)
[2019-12-02 20:56:00,998] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,004] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,004] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,008] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,008] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,012] INFO Replica loaded for partition changes-0 with initial high watermark 722 (kafka.cluster.Replica)
[2019-12-02 20:56:01,012] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 722. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,019] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,019] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,026] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,027] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,030] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,031] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,035] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:01,035] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,038] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:01,038] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,041] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:01,041] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,044] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,045] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,048] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:56:01,049] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,052] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,053] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,058] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,059] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,062] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,062] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,066] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,066] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,070] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,070] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,077] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,077] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,081] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:01,081] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,084] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,084] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,086] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,087] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,090] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:01,091] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,094] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:01,095] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,098] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,098] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,101] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:56:01,101] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,104] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,105] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,111] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:56:01,111] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,113] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,114] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,117] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:56:01,117] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,119] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,119] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,122] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:56:01,123] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:56:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,145] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,145] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,145] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,224] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 92 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,233] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-96775 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,235] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,235] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,240] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,245] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-91492 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,245] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,246] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,249] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,251] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,251] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,251] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,252] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,255] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-84461 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,259] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,259] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,260] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,265] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,265] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,269] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-1633 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,269] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,269] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,270] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,270] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,270] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,270] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,271] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,271] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,277] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,277] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,281] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,281] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,285] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,289] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,292] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,292] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,301] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,302] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,306] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-95060 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,306] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,307] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,307] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,312] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,312] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,312] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,316] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,316] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,319] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-42915 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:01,320] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,320] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:01,323] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:56:12,195] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-86858 in state PreparingRebalance with old generation 0 (__consumer_offsets-6) (reason: Adding new member consumer-1-7ba7bc96-3222-4476-a13e-2be646b3dabe with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:12,203] INFO [GroupCoordinator 0]: Stabilized group console-consumer-86858 generation 1 (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:56:12,213] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-86858 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:15,569] INFO [GroupCoordinator 0]: Member consumer-1-7ba7bc96-3222-4476-a13e-2be646b3dabe in group console-consumer-86858 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:15,570] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-86858 in state PreparingRebalance with old generation 1 (__consumer_offsets-6) (reason: removing member consumer-1-7ba7bc96-3222-4476-a13e-2be646b3dabe on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:15,571] INFO [GroupCoordinator 0]: Group console-consumer-86858 with generation 2 is now empty (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:16,068] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:57:16,069] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-12-02 20:57:16,070] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-12-02 20:57:16,098] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-12-02 20:57:16,104] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:57:16,105] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:57:16,105] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:57:16,106] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:57:16,119] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-12-02 20:57:16,120] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:57:16,122] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-12-02 20:57:16,126] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-12-02 20:57:16,127] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,274] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,274] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,277] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:57:16,278] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 40000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:57:16,279] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-12-02 20:57:16,279] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:57:16,279] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:57:16,279] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:57:16,280] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:57:16,281] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:16,281] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,308] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,308] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,309] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,384] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,384] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,385] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:16,386] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-12-02 20:57:16,386] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:57:16,387] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:57:16,387] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:57:16,387] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:57:16,389] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:57:16,389] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:57:16,389] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-02 20:57:16,390] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,538] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,538] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,539] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,643] INFO Unable to read additional data from server sessionid 0x10007f538300000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:57:16,702] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,702] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,702] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,904] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,904] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:16,905] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:17,108] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:17,108] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:17,111] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-12-02 20:57:17,112] INFO Shutting down. (kafka.log.LogManager)
[2019-12-02 20:57:17,188] INFO [ProducerStateManager partition=interactions-0] Writing producer snapshot at offset 27 (kafka.log.ProducerStateManager)
[2019-12-02 20:57:17,291] INFO [ProducerStateManager partition=__consumer_offsets-6] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-12-02 20:57:17,344] INFO [ProducerStateManager partition=changes-0] Writing producer snapshot at offset 754 (kafka.log.ProducerStateManager)
[2019-12-02 20:57:17,545] INFO Shutdown complete. (kafka.log.LogManager)
[2019-12-02 20:57:17,559] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:57:17,780] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:57:17,897] INFO Session: 0x10007f538300000 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:17,899] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:57:17,899] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:17,900] INFO EventThread shut down for session: 0x10007f538300000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:57:18,858] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:18,858] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:18,859] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:19,863] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:19,863] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:19,864] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:20,868] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:20,868] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:20,870] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-12-02 20:57:20,929] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-12-02 20:57:20,937] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-12-02 20:57:26,124] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:57:26,126] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:57:26,127] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:57:26,127] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-02 20:57:26,127] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-02 20:57:26,142] INFO Reading configuration from: setup/kafka_2.12-2.3.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-02 20:57:26,143] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-02 20:57:26,166] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,166] INFO Server environment:host.name=10.0.0.4 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,167] INFO Server environment:java.version=1.8.0_92 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,167] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,167] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,167] INFO Server environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,168] INFO Server environment:user.name=Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,169] INFO Server environment:user.home=/Users/Hengyu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,169] INFO Server environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,176] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,176] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,176] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:26,191] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-02 20:57:26,206] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:57:30,799] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-02 20:57:31,451] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-12-02 20:57:31,452] INFO starting (kafka.server.KafkaServer)
[2019-12-02 20:57:31,453] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-02 20:57:31,474] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:57:31,480] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,480] INFO Client environment:host.name=10.0.0.4 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,480] INFO Client environment:java.version=1.8.0_92 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,480] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,480] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,481] INFO Client environment:java.class.path=/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/guava-20.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/Hengyu/Desktop/Git/amnesia-demo/setup/kafka_2.12-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:java.library.path=/Users/Hengyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:java.io.tmpdir=/var/folders/kx/d7ppnzxn0svd57zjp1n3k1cr0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:user.name=Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:user.home=/Users/Hengyu (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,482] INFO Client environment:user.dir=/Users/Hengyu/Desktop/Git/amnesia-demo (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,483] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@654f0d9c (org.apache.zookeeper.ZooKeeper)
[2019-12-02 20:57:31,499] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:57:31,502] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:57:31,524] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:57:31,524] INFO Accepted socket connection from /127.0.0.1:62397 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-02 20:57:31,589] INFO Client attempting to establish new session at /127.0.0.1:62397 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:31,590] INFO Creating new log file: log.4e8 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-02 20:57:31,598] INFO Established session 0x10007f6abb70000 with negotiated timeout 6000 for client /127.0.0.1:62397 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:31,600] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10007f6abb70000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-02 20:57:31,603] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-02 20:57:31,666] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x1 zxid:0x4e9 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,677] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x2 zxid:0x4ea txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,678] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x3 zxid:0x4eb txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,680] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x4 zxid:0x4ec txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,681] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x5 zxid:0x4ed txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,685] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x6 zxid:0x4ee txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,686] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x7 zxid:0x4ef txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,688] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x8 zxid:0x4f0 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,689] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0x9 zxid:0x4f1 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,691] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0xa zxid:0x4f2 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,692] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0xb zxid:0x4f3 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,693] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0xc zxid:0x4f4 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,694] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:create cxid:0xd zxid:0x4f5 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:31,847] INFO Cluster ID = vQXeor8hTOOUU678jiUxWw (kafka.server.KafkaServer)
[2019-12-02 20:57:31,933] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:57:31,942] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-02 20:57:31,970] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:31,970] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:31,975] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-02 20:57:32,018] INFO Loading logs. (kafka.log.LogManager)
[2019-12-02 20:57:32,111] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,121] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-12-02 20:57:32,145] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,153] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-0/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,165] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 36 ms (kafka.log.Log)
[2019-12-02 20:57:32,178] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,178] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-02 20:57:32,220] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,220] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:57:32,262] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,263] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-36/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,264] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-12-02 20:57:32,303] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,304] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:57:32,346] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,346] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-6/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,347] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 41 ms (kafka.log.Log)
[2019-12-02 20:57:32,382] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,383] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-12-02 20:57:32,425] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,425] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:32,463] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,463] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:57:32,505] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,505] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:32,546] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,547] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-30/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,548] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 40 ms (kafka.log.Log)
[2019-12-02 20:57:32,585] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,586] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-12-02 20:57:32,625] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,626] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:57:32,667] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,667] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:32,708] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,708] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:57:32,749] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,750] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-48/00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,751] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 41 ms (kafka.log.Log)
[2019-12-02 20:57:32,789] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,789] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-12-02 20:57:32,833] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,834] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-46/00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,835] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 43 ms (kafka.log.Log)
[2019-12-02 20:57:32,870] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,871] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-25/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,872] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 33 ms (kafka.log.Log)
[2019-12-02 20:57:32,910] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,911] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-22/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,912] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:32,949] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,949] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:57:32,993] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Loading producer state till offset 27 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:32,994] INFO [ProducerStateManager partition=interactions-0] Loading producer state from snapshot file '/tmp/kafka-logs/interactions-0/00000000000000000027.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:32,996] INFO [Log partition=interactions-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 27 in 44 ms (kafka.log.Log)
[2019-12-02 20:57:33,029] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,030] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-12-02 20:57:33,070] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,071] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:33,112] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,113] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-40/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,114] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-12-02 20:57:33,154] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,155] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-49/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,156] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-12-02 20:57:33,195] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,196] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-35/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,197] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:33,235] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,236] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,237] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:33,273] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,274] INFO [Log partition=temp-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:57:33,316] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,316] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-4/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,351] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 76 ms (kafka.log.Log)
[2019-12-02 20:57:33,361] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,361] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-02 20:57:33,404] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,405] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-12-02 20:57:33,444] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,444] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:57:33,486] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,487] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-2/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,488] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 42 ms (kafka.log.Log)
[2019-12-02 20:57:33,525] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,525] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:57:33,577] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Loading producer state till offset 754 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,578] INFO [ProducerStateManager partition=changes-0] Loading producer state from snapshot file '/tmp/kafka-logs/changes-0/00000000000000000754.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,579] INFO [Log partition=changes-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 754 in 53 ms (kafka.log.Log)
[2019-12-02 20:57:33,615] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,616] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:57:33,657] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,658] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-42/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,692] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 75 ms (kafka.log.Log)
[2019-12-02 20:57:33,700] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,702] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-29/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,704] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 10 ms (kafka.log.Log)
[2019-12-02 20:57:33,739] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,740] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-12-02 20:57:33,780] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,780] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:33,824] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,824] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-18/00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:33,825] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 44 ms (kafka.log.Log)
[2019-12-02 20:57:33,862] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,862] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-12-02 20:57:33,903] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,903] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-12-02 20:57:33,943] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,944] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:33,984] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:33,984] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:34,027] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:34,028] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-21/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:34,029] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2019-12-02 20:57:34,055] INFO Expiring session 0x10007f538300000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-02 20:57:34,056] INFO Processed session termination for sessionid: 0x10007f538300000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:34,067] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:34,067] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-19/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:34,068] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-12-02 20:57:34,114] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:34,115] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-26/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:34,116] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 47 ms (kafka.log.Log)
[2019-12-02 20:57:34,147] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:34,147] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-10/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-12-02 20:57:34,148] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-12-02 20:57:34,186] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:34,187] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-12-02 20:57:34,226] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-02 20:57:34,227] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-12-02 20:57:34,230] INFO Logs loading complete in 2211 ms. (kafka.log.LogManager)
[2019-12-02 20:57:34,246] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-02 20:57:34,247] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-02 20:57:34,532] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-02 20:57:34,563] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-02 20:57:34,565] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-02 20:57:34,599] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,599] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,600] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,601] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,619] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-02 20:57:34,694] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-02 20:57:34,718] INFO Stat of the created znode at /brokers/ids/0 is: 1271,1271,1575349054709,1575349054709,1,0,0,72066350062174208,188,0,1271
 (kafka.zk.KafkaZkClient)
[2019-12-02 20:57:34,719] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 1271 (kafka.zk.KafkaZkClient)
[2019-12-02 20:57:34,776] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,780] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,782] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-02 20:57:34,822] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:34,830] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:34,833] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:34,883] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:41000,blockEndProducerId:41999) by writing to Zk with path version 42 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-02 20:57:34,903] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:57:34,909] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-02 20:57:34,910] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-02 20:57:34,974] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-02 20:57:35,020] INFO Got user-level KeeperException when processing sessionid:0x10007f6abb70000 type:multi cxid:0x6f zxid:0x4fa txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-02 20:57:35,021] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-02 20:57:35,112] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:57:35,113] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:57:35,113] INFO Kafka startTimeMs: 1575349055107 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-02 20:57:35,116] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-02 20:57:35,127] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, temp-0, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, interactions-0, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, changes-0, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-12-02 20:57:35,141] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,145] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,177] INFO Replica loaded for partition temp-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,178] INFO [Partition temp-0 broker=0] temp-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,184] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,184] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,188] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2019-12-02 20:57:35,188] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,192] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:57:35,192] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,195] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,196] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,200] INFO Replica loaded for partition interactions-0 with initial high watermark 27 (kafka.cluster.Replica)
[2019-12-02 20:57:35,200] INFO [Partition interactions-0 broker=0] interactions-0 starts at Leader Epoch 0 from offset 27. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,203] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,203] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,208] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,208] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,212] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,212] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,219] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,219] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,223] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,223] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,230] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,231] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,234] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,235] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,239] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,240] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,244] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,245] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,250] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:57:35,250] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,254] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,254] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,260] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,261] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,267] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:57:35,267] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,270] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,271] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,275] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,275] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,279] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 4 (kafka.cluster.Replica)
[2019-12-02 20:57:35,279] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,282] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,282] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,286] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,286] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,292] INFO Replica loaded for partition changes-0 with initial high watermark 754 (kafka.cluster.Replica)
[2019-12-02 20:57:35,292] INFO [Partition changes-0 broker=0] changes-0 starts at Leader Epoch 0 from offset 754. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,296] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,296] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,300] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,301] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,305] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,305] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,313] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,313] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,316] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,317] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,320] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:57:35,320] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,323] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,324] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,329] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:57:35,329] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,334] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,335] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,340] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,342] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,348] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,349] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,353] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,353] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,358] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,358] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,362] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,363] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,366] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:57:35,367] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,370] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,370] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,377] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,378] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,381] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,381] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,384] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:57:35,384] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,387] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,387] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,391] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 5 (kafka.cluster.Replica)
[2019-12-02 20:57:35,391] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,397] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,397] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,401] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 2 (kafka.cluster.Replica)
[2019-12-02 20:57:35,401] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,404] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,404] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,409] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-12-02 20:57:35,409] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,412] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,413] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,416] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-02 20:57:35,416] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-02 20:57:35,430] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,431] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,432] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,432] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,432] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,432] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,433] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,434] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,435] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,437] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,524] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-87448 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,528] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 96 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,533] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-96775 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,534] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,534] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,534] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,534] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,535] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,539] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,539] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,543] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-91492 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,543] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-53782 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,543] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,547] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,547] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,547] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,547] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,548] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,551] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-84461 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,551] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,555] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,555] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,555] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,559] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,559] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,564] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-1633 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,564] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,564] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,564] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,564] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,565] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,565] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,565] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,566] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,569] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-15586 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,569] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,573] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-97714 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,580] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-30254 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,584] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,588] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-72578 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,592] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-86858 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,597] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-29475 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,597] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,603] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-95060 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,611] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-16156 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,617] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,618] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,624] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-42915 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:35,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:35,639] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-02 20:57:46,983] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-3922 in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-e2ed7c7d-2685-47ba-b6e3-4ee89d7b3a43 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:46,989] INFO [GroupCoordinator 0]: Stabilized group console-consumer-3922 generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-12-02 20:57:46,998] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-3922 for generation 1 (kafka.coordinator.group.GroupCoordinator)
